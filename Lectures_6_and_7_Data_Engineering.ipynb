{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h1>Data Engineering</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2>Overview</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<ul>\n",
    "<li>The Machine Learning Process</li>\n",
    "<li>Connecting Spark with Postgres</li>\n",
    "    <li>Data Cleaning</li>      \n",
    "    <li>Feature Engineering<ul><li>Variable Types</li><li>Summary Statistics</li><li>Five-number Summary and Boxplots</li>\n",
    "    <li>Numeric Variables<ul>\n",
    "        <li>Identifying High Correlations</li>\n",
    "        <li>Handling Outliers</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>Categorical Variables and Categories' Encoding</li>\n",
    "    <li>Assembling Features into One Vector</li>\n",
    "    <li>Data Scaling</li>\n",
    "    <li>Data Pipelines</li>\n",
    "    </ul></li></ul>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>The Machine Learning Process</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's look at a real-life example of machine learning. Imagine you run a website where people sell their cars. You want your system to suggest fair starting prices for sellers when they post ads. Regression analysis can help in this case by using data from past sales, looking at car features and prices, and finding patterns between them. However, your database doesn't have enough ads, so you decide to gather car prices from public sources. You find many useful car sale records online, but much of the data is in CSV files, and a lot of it is in PDF and Word documents (with car sale listings)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "First, you go through the PDFs and Word documents to find and match similar details, like manufacturer, model, and make. Since a regression model can't work with text values (like 'automatic' or 'manual'), you create a method to turn these values into numbers. Then, you realize that some important details, like the year the car was made, are missing from certain records, so you choose to remove those incomplete records from your dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Once you've cleaned and stored the data, you begin to explore different aspects of it—like how the fields relate to each other and their patterns (this helps reveal underlying connections within the data). Next, you choose the right type of regression analysis to apply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Suppose you pick linear regression because the relationships in the data seem to be linear based on your earlier analysis. Before creating the model, you normalize and scale the data (I'll explain how and why this is important later) and divide it into training and validation sets. You then train your model using the training data, using past data to adjust the model's settings to predict future prices that are unknown. After training, you end up with a functional linear regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "However, when you test the model on your validation dataset, the performance is disappointing. You adjust some of the training parameters, test the model again, and continue this cycle until the model performs satisfactorily. Once it's working well, you integrate the model into your web application. Soon after, you start receiving emails from clients curious about how you achieved this or from those unhappy with inaccurate predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What this example illustrates is that a machine-learning project consists of multiple steps. Although typical steps are shown in the following figure:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><figure><img src=\"http://stat.cmu.edu/~mfarag/652/lectures/l16/machine_learning_model.png\"/><figcaption>Machine Learning Modeling</figcaption></figure></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The entire process can usually be broken down into the following:\n",
    "\n",
    "<b>Collecting data:</b> First the data needs to be gathered from various sources. The sources can be log files, database records, signals coming from sensors, and so on. Spark can help load the data from relational databases, CSV files, remote services, and distributed file systems like HDFS, or from real-time sources using Spark Streaming."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<b>Cleaning and preparing data:</b> Data isn’t always available in a structured format appropriate for machine learning (text, images, sounds, binary data, and so forth), so you need to devise and carry out a method of transforming this unstructured data into numerical features. Additionally, you need to handle missing data and the different forms in which the same values can be entered (for example, VW and Volkswagen are the same carmaker). Often, data also needs to be scaled so that all dimensions are of comparable ranges."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "<p style=\"page-break-after:always;\"></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<b>Analyzing data and extracting features:</b> Next you analyze the data, examine its correlations, and visualize them (using various tools) if necessary. (The number of dimensions may be reduced in this step if some of them don’t bring any extra information: for example, if they’re redundant.) You then choose the appropriate machine-learning algorithm (or set of algorithms) and split the data into training and validation subsets—this is important because you’d like to see how the model behaves on the data not seen during the training phase. Or you decide on a different cross-validation method, where you continuously split the dataset into different training and validation datasets and average the results over the rounds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<b>Training the model:</b> You train a model by running an algorithm that learns a set of algorithm-specific parameters from the input data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<b>Evaluating the model:</b> You then put the model to use on the validation dataset and evaluate its performance according to some criteria. At this point, you may decide that you need more input data or that you need to change the way features were extracted. You may also change the feature space or switch to a different model. In any of these cases, you go back to step 1 or step 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<b>Using the model:</b> Finally, you deploy the built model to the production environment of your website."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The mechanics of using an API (Spark or some other machine-learning library) to train and test the models is only the last and the shortest part of the process. Equally important are collection, preparation, and analysis of data, where knowledge about the problem domain is needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Process Flow for Big-Data Machine Learning Process</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><figure><img src=\"http://stat.cmu.edu/~mfarag/14810/l15/machine_learning_modeling_lifecycle_in_big_data.png\"/><figcaption>Process Flow for Big-Data Machine Learning Modeling</figcaption></figure></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3>Food for Thought: Why do you think a 2-phase process is necessary in big-data ML modeling?!</h3>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "<p style=\"page-break-after:always;\"></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Phase-I Ingest Data from CSV and Insert them into PostgreSQL</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2>1. Data Ingestion</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/reid/anaconda3/bin/python: No module named wget\n"
     ]
    }
   ],
   "source": [
    "!python -m wget https://www.andrew.cmu.edu/user/mfarag/14763/KDDTrain+.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2>Initialize the Application</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/29 11:38:26 WARN Utils: Your hostname, omen-20 resolves to a loopback address: 127.0.1.1; using 192.168.1.156 instead (on interface wlo1)\n",
      "24/09/29 11:38:26 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/09/29 11:38:26 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/09/29 11:38:27 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "/home/reid/anaconda3/envs/systems_and_toolchains/lib/python3.12/site-packages/pyspark/sql/context.py:112: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Uncomment the following lines if you are using Windows!\n",
    "#import findspark\n",
    "#findspark.init()\n",
    "#findspark.find()\n",
    "\n",
    "import pyspark\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext, SQLContext\n",
    "\n",
    "appName = \"Big Data Analytics\"\n",
    "master = \"local\"\n",
    "\n",
    "# Create Configuration object for Spark.\n",
    "conf = pyspark.SparkConf()\\\n",
    "    .set('spark.driver.host','127.0.0.1')\\\n",
    "    .setAppName(appName)\\\n",
    "    .setMaster(master)\n",
    "\n",
    "# Create Spark Context with the new configurations rather than relying on the default one\n",
    "sc = SparkContext.getOrCreate(conf=conf)\n",
    "\n",
    "# You need to create SQL Context to conduct some database operations like what we will see later.\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "# If you have SQL context, you create the session from the Spark Context\n",
    "spark = sqlContext.sparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2>Read-in the Dataset</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Load data from csv to a dataframe on a local machine. \n",
    "# header=False means the first row is not a header \n",
    "# sep=',' means the column are seperated using ','\n",
    "col_names = [\"duration\",\"protocol_type\",\"service\",\"flag\",\"src_bytes\",\n",
    "    \"dst_bytes\",\"land\",\"wrong_fragment\",\"urgent\",\"hot\",\"num_failed_logins\",\n",
    "    \"logged_in\",\"num_compromised\",\"root_shell\",\"su_attempted\",\"num_root\",\n",
    "    \"num_file_creations\",\"num_shells\",\"num_access_files\",\"num_outbound_cmds\",\n",
    "    \"is_host_login\",\"is_guest_login\",\"count\",\"srv_count\",\"serror_rate\",\n",
    "    \"srv_serror_rate\",\"rerror_rate\",\"srv_rerror_rate\",\"same_srv_rate\",\n",
    "    \"diff_srv_rate\",\"srv_diff_host_rate\",\"dst_host_count\",\"dst_host_srv_count\",\n",
    "    \"dst_host_same_srv_rate\",\"dst_host_diff_srv_rate\",\"dst_host_same_src_port_rate\",\n",
    "    \"dst_host_srv_diff_host_rate\",\"dst_host_serror_rate\",\"dst_host_srv_serror_rate\",\n",
    "    \"dst_host_rerror_rate\",\"dst_host_srv_rerror_rate\",\"classes\",\"difficulty_level\"]\n",
    "\n",
    "df = spark.read.csv(\"KDDTrain+.txt\",header=False, inferSchema= True).toDF(*col_names)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "<p style=\"page-break-after:always;\"></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3>For this lecture's purposes, We will insert the data into the table using the overwrite mode</h3>\n",
    "If the overwrite mode is not working for you, please populate the table by creating the SQL table and using the append mode to populate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/29 11:38:32 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "db_properties={}\n",
    "#update your db username\n",
    "db_properties['username']=\"postgres\"\n",
    "#update your db password\n",
    "db_properties['password']=\"bigdata\"\n",
    "#make sure you got the right port number here\n",
    "db_properties['url']= \"jdbc:postgresql://localhost:5432/postgres\"\n",
    "#make sure you had the Postgres JAR file in the right location\n",
    "db_properties['driver']=\"org.postgresql.Driver\"\n",
    "db_properties['table']= \"NSLKDD\"\n",
    "\n",
    "\n",
    "df.write.format(\"jdbc\")\\\n",
    ".mode(\"overwrite\")\\\n",
    ".option(\"url\", db_properties['url'])\\\n",
    ".option(\"dbtable\", db_properties['table'])\\\n",
    ".option(\"user\", db_properties['username'])\\\n",
    ".option(\"password\", db_properties['password'])\\\n",
    ".option(\"Driver\", db_properties['driver'])\\\n",
    ".save()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2>Now, read the data back!</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-------------------------------\n",
      " duration                    | 0        \n",
      " protocol_type               | tcp      \n",
      " service                     | ftp_data \n",
      " flag                        | SF       \n",
      " src_bytes                   | 491      \n",
      " dst_bytes                   | 0        \n",
      " land                        | 0        \n",
      " wrong_fragment              | 0        \n",
      " urgent                      | 0        \n",
      " hot                         | 0        \n",
      " num_failed_logins           | 0        \n",
      " logged_in                   | 0        \n",
      " num_compromised             | 0        \n",
      " root_shell                  | 0        \n",
      " su_attempted                | 0        \n",
      " num_root                    | 0        \n",
      " num_file_creations          | 0        \n",
      " num_shells                  | 0        \n",
      " num_access_files            | 0        \n",
      " num_outbound_cmds           | 0        \n",
      " is_host_login               | 0        \n",
      " is_guest_login              | 0        \n",
      " count                       | 2        \n",
      " srv_count                   | 2        \n",
      " serror_rate                 | 0.0      \n",
      " srv_serror_rate             | 0.0      \n",
      " rerror_rate                 | 0.0      \n",
      " srv_rerror_rate             | 0.0      \n",
      " same_srv_rate               | 1.0      \n",
      " diff_srv_rate               | 0.0      \n",
      " srv_diff_host_rate          | 0.0      \n",
      " dst_host_count              | 150      \n",
      " dst_host_srv_count          | 25       \n",
      " dst_host_same_srv_rate      | 0.17     \n",
      " dst_host_diff_srv_rate      | 0.03     \n",
      " dst_host_same_src_port_rate | 0.17     \n",
      " dst_host_srv_diff_host_rate | 0.0      \n",
      " dst_host_serror_rate        | 0.0      \n",
      " dst_host_srv_serror_rate    | 0.0      \n",
      " dst_host_rerror_rate        | 0.05     \n",
      " dst_host_srv_rerror_rate    | 0.0      \n",
      " classes                     | normal   \n",
      " difficulty_level            | 20       \n",
      "only showing top 1 row\n",
      "\n",
      "root\n",
      " |-- duration: integer (nullable = true)\n",
      " |-- protocol_type: string (nullable = true)\n",
      " |-- service: string (nullable = true)\n",
      " |-- flag: string (nullable = true)\n",
      " |-- src_bytes: integer (nullable = true)\n",
      " |-- dst_bytes: integer (nullable = true)\n",
      " |-- land: integer (nullable = true)\n",
      " |-- wrong_fragment: integer (nullable = true)\n",
      " |-- urgent: integer (nullable = true)\n",
      " |-- hot: integer (nullable = true)\n",
      " |-- num_failed_logins: integer (nullable = true)\n",
      " |-- logged_in: integer (nullable = true)\n",
      " |-- num_compromised: integer (nullable = true)\n",
      " |-- root_shell: integer (nullable = true)\n",
      " |-- su_attempted: integer (nullable = true)\n",
      " |-- num_root: integer (nullable = true)\n",
      " |-- num_file_creations: integer (nullable = true)\n",
      " |-- num_shells: integer (nullable = true)\n",
      " |-- num_access_files: integer (nullable = true)\n",
      " |-- num_outbound_cmds: integer (nullable = true)\n",
      " |-- is_host_login: integer (nullable = true)\n",
      " |-- is_guest_login: integer (nullable = true)\n",
      " |-- count: integer (nullable = true)\n",
      " |-- srv_count: integer (nullable = true)\n",
      " |-- serror_rate: double (nullable = true)\n",
      " |-- srv_serror_rate: double (nullable = true)\n",
      " |-- rerror_rate: double (nullable = true)\n",
      " |-- srv_rerror_rate: double (nullable = true)\n",
      " |-- same_srv_rate: double (nullable = true)\n",
      " |-- diff_srv_rate: double (nullable = true)\n",
      " |-- srv_diff_host_rate: double (nullable = true)\n",
      " |-- dst_host_count: integer (nullable = true)\n",
      " |-- dst_host_srv_count: integer (nullable = true)\n",
      " |-- dst_host_same_srv_rate: double (nullable = true)\n",
      " |-- dst_host_diff_srv_rate: double (nullable = true)\n",
      " |-- dst_host_same_src_port_rate: double (nullable = true)\n",
      " |-- dst_host_srv_diff_host_rate: double (nullable = true)\n",
      " |-- dst_host_serror_rate: double (nullable = true)\n",
      " |-- dst_host_srv_serror_rate: double (nullable = true)\n",
      " |-- dst_host_rerror_rate: double (nullable = true)\n",
      " |-- dst_host_srv_rerror_rate: double (nullable = true)\n",
      " |-- classes: string (nullable = true)\n",
      " |-- difficulty_level: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_read = sqlContext.read.format(\"jdbc\")\\\n",
    "    .option(\"url\", db_properties['url'])\\\n",
    "    .option(\"dbtable\", db_properties['table'])\\\n",
    "    .option(\"user\", db_properties['username'])\\\n",
    "    .option(\"password\", db_properties['password'])\\\n",
    "    .option(\"Driver\", db_properties['driver'])\\\n",
    "    .load()\n",
    "\n",
    "df_read.show(1, vertical=True)\n",
    "df_read.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2>2. Now, let's go ahead and talk about Data Cleaning and Preprocessing.</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "It's important to clean your data before storing them in the database tables. In some cases, it's OK to conduct data cleaning before before you conduct feature engineering. In Data cleaning, we typically need to conduct the following activities:\n",
    "<ul>\n",
    "<li>Rename the column names to remove special characters and blanks - if any - with an underscore “_”;</li>\n",
    "    <li>Choose the correct data type for your columns and cast column data types as needed</li>\n",
    "<li>Drop the columns that are not of interest to you (duplicated, not included in research, etc.)</li>\n",
    "<li>Handle missing values and N/As</li>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "<p style=\"page-break-after:always;\"></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3>2.1 Let's test renaming columns, casting column data types and dropping duplicate rows</h3>\n",
    "You may use these techniques in other activities (e.g., project or HW assignments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Column Rename\n",
    "renamed_columns_df = df_read.withColumnRenamed(\"rerror_rate\",\"newly_renamed_rerror_rate\")\n",
    "# Casting one column type\n",
    "casted_types_df = (renamed_columns_df.withColumn(\"new_column_srv_serror_rate\", \\\n",
    "                    renamed_columns_df[\"srv_serror_rate\"] \\\n",
    "                    .cast(\"integer\")).drop(\"srv_serror_rate\")\n",
    "                    .distinct() # deleting duplicate rows\n",
    "           )\n",
    "casted_types_df = casted_types_df.withColumnRenamed(\"new_column_srv_serror_rate\",\"srv_serror_rate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- duration: integer (nullable = true)\n",
      " |-- protocol_type: string (nullable = true)\n",
      " |-- service: string (nullable = true)\n",
      " |-- flag: string (nullable = true)\n",
      " |-- src_bytes: integer (nullable = true)\n",
      " |-- dst_bytes: integer (nullable = true)\n",
      " |-- land: integer (nullable = true)\n",
      " |-- wrong_fragment: integer (nullable = true)\n",
      " |-- urgent: integer (nullable = true)\n",
      " |-- hot: integer (nullable = true)\n",
      " |-- num_failed_logins: integer (nullable = true)\n",
      " |-- logged_in: integer (nullable = true)\n",
      " |-- num_compromised: integer (nullable = true)\n",
      " |-- root_shell: integer (nullable = true)\n",
      " |-- su_attempted: integer (nullable = true)\n",
      " |-- num_root: integer (nullable = true)\n",
      " |-- num_file_creations: integer (nullable = true)\n",
      " |-- num_shells: integer (nullable = true)\n",
      " |-- num_access_files: integer (nullable = true)\n",
      " |-- num_outbound_cmds: integer (nullable = true)\n",
      " |-- is_host_login: integer (nullable = true)\n",
      " |-- is_guest_login: integer (nullable = true)\n",
      " |-- count: integer (nullable = true)\n",
      " |-- srv_count: integer (nullable = true)\n",
      " |-- serror_rate: double (nullable = true)\n",
      " |-- newly_renamed_rerror_rate: double (nullable = true)\n",
      " |-- srv_rerror_rate: double (nullable = true)\n",
      " |-- same_srv_rate: double (nullable = true)\n",
      " |-- diff_srv_rate: double (nullable = true)\n",
      " |-- srv_diff_host_rate: double (nullable = true)\n",
      " |-- dst_host_count: integer (nullable = true)\n",
      " |-- dst_host_srv_count: integer (nullable = true)\n",
      " |-- dst_host_same_srv_rate: double (nullable = true)\n",
      " |-- dst_host_diff_srv_rate: double (nullable = true)\n",
      " |-- dst_host_same_src_port_rate: double (nullable = true)\n",
      " |-- dst_host_srv_diff_host_rate: double (nullable = true)\n",
      " |-- dst_host_serror_rate: double (nullable = true)\n",
      " |-- dst_host_srv_serror_rate: double (nullable = true)\n",
      " |-- dst_host_rerror_rate: double (nullable = true)\n",
      " |-- dst_host_srv_rerror_rate: double (nullable = true)\n",
      " |-- classes: string (nullable = true)\n",
      " |-- difficulty_level: integer (nullable = true)\n",
      " |-- srv_serror_rate: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "casted_types_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Please note that these column renames are for experimental purposes only to show you how to use these functions. However, this dataset doesn't need these column renames. So, we will go back to use our df_read object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# We are assigning the df_read to casted_types_df because no data type changes were needed\n",
    "casted_types_df = df_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-------------------------------\n",
      " duration                    | 0        \n",
      " protocol_type               | tcp      \n",
      " service                     | ftp_data \n",
      " flag                        | SF       \n",
      " src_bytes                   | 491      \n",
      " dst_bytes                   | 0        \n",
      " land                        | 0        \n",
      " wrong_fragment              | 0        \n",
      " urgent                      | 0        \n",
      " hot                         | 0        \n",
      " num_failed_logins           | 0        \n",
      " logged_in                   | 0        \n",
      " num_compromised             | 0        \n",
      " root_shell                  | 0        \n",
      " su_attempted                | 0        \n",
      " num_root                    | 0        \n",
      " num_file_creations          | 0        \n",
      " num_shells                  | 0        \n",
      " num_access_files            | 0        \n",
      " num_outbound_cmds           | 0        \n",
      " is_host_login               | 0        \n",
      " is_guest_login              | 0        \n",
      " count                       | 2        \n",
      " srv_count                   | 2        \n",
      " serror_rate                 | 0.0      \n",
      " srv_serror_rate             | 0.0      \n",
      " rerror_rate                 | 0.0      \n",
      " srv_rerror_rate             | 0.0      \n",
      " same_srv_rate               | 1.0      \n",
      " diff_srv_rate               | 0.0      \n",
      " srv_diff_host_rate          | 0.0      \n",
      " dst_host_count              | 150      \n",
      " dst_host_srv_count          | 25       \n",
      " dst_host_same_srv_rate      | 0.17     \n",
      " dst_host_diff_srv_rate      | 0.03     \n",
      " dst_host_same_src_port_rate | 0.17     \n",
      " dst_host_srv_diff_host_rate | 0.0      \n",
      " dst_host_serror_rate        | 0.0      \n",
      " dst_host_srv_serror_rate    | 0.0      \n",
      " dst_host_rerror_rate        | 0.05     \n",
      " dst_host_srv_rerror_rate    | 0.0      \n",
      " classes                     | normal   \n",
      " difficulty_level            | 20       \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "casted_types_df.show(1,vertical=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3>2.2.1 Types of Missing Values</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "There are several ways to handle missing values in your dataset. You need to stay vigilent in selectin the approach since some of these methods may impact the quality of your data.\n",
    "\n",
    "<ul>\n",
    "    <li>Missing Completely at Random (MCAR): The probability of missing values is the same across all the variables.</li>\n",
    "<li>Missing at Random (MAR): Like MCAR but it is possible to predict the missing value based on some other variables.</li>\n",
    "<li>Not Missing at Random (NMAR): This can be handled by studying the root cause of missing</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3>2.2.2 Reasons for Missing Values</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "<ul>\n",
    "    <li>Data may be missing for some of the time period of the analysis.</li>\n",
    "<li>Events not happening, such as a student's exam score missing because they didn't take the test.</li>\n",
    "<li>Responses omitted for certain survey questions.</li>\n",
    "<li>Questions not applicable in some contexts.</li>\n",
    "    <li>Random gaps in data.</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "<p style=\"page-break-after:always;\"></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3>2.2.3 Handling Missing Values</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "There are several ways to handle missing values in your dataset. You need to stay vigilent in selectin the approach since some of these methods may impact the quality of your data.\n",
    "\n",
    "<ul>\n",
    "    <li><b>Drop Columns:</b> Removing a column from your dataset is always possible, but you should carefully consider whether to clean it using a different method or to remove it entirely. Your decision should be guided by several factors, such as the importance of the data in the column and the proportion of missing values. As a general guideline, avoid dropping a column if it contains meaningful data in at least 50% of its entries.</li>\n",
    "    <li><b>Drop Rows having Nulls:</b> This is always an option as well. However, depending on the size of your dataset and the number of rows to be dropped, this \"may/may not\" be a good option. For rows, you can use a similar threshold (50%) and drop rows with missing values only if it doesn't significantly reduce your sample size</li>\n",
    "    <li><b>Fill the missing values:</b> This approach is \"usually\" applicable for numeric columns. This is done using an operation that is called <b>imputation</b>. By creating imputed columns, we will create columns which will consist of values that fill the missing value by taking a statistical method such as mean/median of the original columns to fill the missing value.\n",
    "</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3>2.2.3.1 Check NA Values</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3>In some cases, your dataframe is able to detect if your cells/fields are empty or holding a missing value. In this case, missing values can be spotted using isNull or is NaN</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0--------------------------\n",
      " duration                    | 0   \n",
      " protocol_type               | 0   \n",
      " service                     | 0   \n",
      " flag                        | 0   \n",
      " src_bytes                   | 0   \n",
      " dst_bytes                   | 0   \n",
      " land                        | 0   \n",
      " wrong_fragment              | 0   \n",
      " urgent                      | 0   \n",
      " hot                         | 0   \n",
      " num_failed_logins           | 0   \n",
      " logged_in                   | 0   \n",
      " num_compromised             | 0   \n",
      " root_shell                  | 0   \n",
      " su_attempted                | 0   \n",
      " num_root                    | 0   \n",
      " num_file_creations          | 0   \n",
      " num_shells                  | 0   \n",
      " num_access_files            | 0   \n",
      " num_outbound_cmds           | 0   \n",
      " is_host_login               | 0   \n",
      " is_guest_login              | 0   \n",
      " count                       | 0   \n",
      " srv_count                   | 0   \n",
      " serror_rate                 | 0   \n",
      " srv_serror_rate             | 0   \n",
      " rerror_rate                 | 0   \n",
      " srv_rerror_rate             | 0   \n",
      " same_srv_rate               | 0   \n",
      " diff_srv_rate               | 0   \n",
      " srv_diff_host_rate          | 0   \n",
      " dst_host_count              | 0   \n",
      " dst_host_srv_count          | 0   \n",
      " dst_host_same_srv_rate      | 0   \n",
      " dst_host_diff_srv_rate      | 0   \n",
      " dst_host_same_src_port_rate | 0   \n",
      " dst_host_srv_diff_host_rate | 0   \n",
      " dst_host_serror_rate        | 0   \n",
      " dst_host_srv_serror_rate    | 0   \n",
      " dst_host_rerror_rate        | 0   \n",
      " dst_host_srv_rerror_rate    | 0   \n",
      " classes                     | 0   \n",
      " difficulty_level            | 0   \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "null_counts_plays_df = df_read.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) \\\n",
    "                        for c in df_read.columns])\n",
    "\n",
    "null_counts_plays_df.show(truncate=False, vertical=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "So, our NSL-KDD dataset is clean but let's assume some hypothetical scenarios here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3>2.2.3.2 Let's play with some null value handling. To drop all rows with null value(s):</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-------------------------------\n",
      " duration                    | 0        \n",
      " protocol_type               | tcp      \n",
      " service                     | ftp_data \n",
      " flag                        | SF       \n",
      " src_bytes                   | 491      \n",
      " dst_bytes                   | 0        \n",
      " land                        | 0        \n",
      " wrong_fragment              | 0        \n",
      " urgent                      | 0        \n",
      " hot                         | 0        \n",
      " num_failed_logins           | 0        \n",
      " logged_in                   | 0        \n",
      " num_compromised             | 0        \n",
      " root_shell                  | 0        \n",
      " su_attempted                | 0        \n",
      " num_root                    | 0        \n",
      " num_file_creations          | 0        \n",
      " num_shells                  | 0        \n",
      " num_access_files            | 0        \n",
      " num_outbound_cmds           | 0        \n",
      " is_host_login               | 0        \n",
      " is_guest_login              | 0        \n",
      " count                       | 2        \n",
      " srv_count                   | 2        \n",
      " serror_rate                 | 0.0      \n",
      " srv_serror_rate             | 0.0      \n",
      " rerror_rate                 | 0.0      \n",
      " srv_rerror_rate             | 0.0      \n",
      " same_srv_rate               | 1.0      \n",
      " diff_srv_rate               | 0.0      \n",
      " srv_diff_host_rate          | 0.0      \n",
      " dst_host_count              | 150      \n",
      " dst_host_srv_count          | 25       \n",
      " dst_host_same_srv_rate      | 0.17     \n",
      " dst_host_diff_srv_rate      | 0.03     \n",
      " dst_host_same_src_port_rate | 0.17     \n",
      " dst_host_srv_diff_host_rate | 0.0      \n",
      " dst_host_serror_rate        | 0.0      \n",
      " dst_host_srv_serror_rate    | 0.0      \n",
      " dst_host_rerror_rate        | 0.05     \n",
      " dst_host_srv_rerror_rate    | 0.0      \n",
      " classes                     | normal   \n",
      " difficulty_level            | 20       \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "casted_types_df_with_na_dropped_rows = casted_types_df.na.drop()\n",
    "casted_types_df_with_na_dropped_rows.show(1,vertical=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3>2.2.3.3 To drop rows based on number of NAs in the row:</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125973"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "casted_types_df_with_na_dropped_rows = casted_types_df.na.drop(how=\"any\", thresh=2)\n",
    "casted_types_df_with_na_dropped_rows.count()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "<p style=\"page-break-after:always;\"></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3>2.2.3.4 What if the number of missing values is large or we don't want to drop them due to a potential significant impact to our sample size? Imputation can be an option. Let's go ahead and assume we have null values in <b>src_bytes</b> column and we would like to <b>impute</b> them.</h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Invalid argument, not a string or column: None of type <class 'NoneType'>. For column literals, use 'lit', 'array', 'struct' or 'create_map' function.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#In some cases, your missing values are recoded with a string value (and not recognized in Spark as Null explicitly)\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# The below code can be partially used outside of imputation context \u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# to replace a string value with NA using regex_replace\u001b[39;00m\n\u001b[1;32m      4\u001b[0m missing_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNA\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m df_with_substituted_na \u001b[38;5;241m=\u001b[39m (casted_types_df_with_na_dropped_rows\\\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;241m.\u001b[39mwithColumn(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msrc_bytes\u001b[39m\u001b[38;5;124m'\u001b[39m, \\\n\u001b[1;32m      7\u001b[0m                 when(casted_types_df_with_na_dropped_rows\u001b[38;5;241m.\u001b[39msrc_bytes\u001b[38;5;241m==\u001b[39mmissing_value,\\\n\u001b[0;32m----> 8\u001b[0m                     \u001b[43mregexp_replace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_types_df_with_na_dropped_rows\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msrc_bytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmissing_value\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m) \\\n\u001b[1;32m      9\u001b[0m                 \u001b[38;5;241m.\u001b[39motherwise(casted_types_df_with_na_dropped_rows\u001b[38;5;241m.\u001b[39msrc_bytes))\\\n\u001b[1;32m     10\u001b[0m                 )\n\u001b[1;32m     12\u001b[0m df_with_substituted_na\u001b[38;5;241m.\u001b[39mshow(\u001b[38;5;241m1\u001b[39m, vertical\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/systems_and_toolchains/lib/python3.12/site-packages/pyspark/sql/utils.py:160\u001b[0m, in \u001b[0;36mtry_remote_functions.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(functions, f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/systems_and_toolchains/lib/python3.12/site-packages/pyspark/sql/functions.py:6886\u001b[0m, in \u001b[0;36mregexp_replace\u001b[0;34m(string, pattern, replacement)\u001b[0m\n\u001b[1;32m   6884\u001b[0m     replacement_col \u001b[38;5;241m=\u001b[39m _create_column_from_literal(replacement)\n\u001b[1;32m   6885\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 6886\u001b[0m     replacement_col \u001b[38;5;241m=\u001b[39m \u001b[43m_to_java_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreplacement\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6887\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _invoke_function(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregexp_replace\u001b[39m\u001b[38;5;124m\"\u001b[39m, _to_java_column(string), pattern_col, replacement_col)\n",
      "File \u001b[0;32m~/anaconda3/envs/systems_and_toolchains/lib/python3.12/site-packages/pyspark/sql/column.py:65\u001b[0m, in \u001b[0;36m_to_java_column\u001b[0;34m(col)\u001b[0m\n\u001b[1;32m     63\u001b[0m     jcol \u001b[38;5;241m=\u001b[39m _create_column_from_name(col)\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m     66\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid argument, not a string or column: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     67\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m of type \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     68\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor column literals, use \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlit\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstruct\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcreate_map\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     69\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(col, \u001b[38;5;28mtype\u001b[39m(col))\n\u001b[1;32m     70\u001b[0m     )\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m jcol\n",
      "\u001b[0;31mTypeError\u001b[0m: Invalid argument, not a string or column: None of type <class 'NoneType'>. For column literals, use 'lit', 'array', 'struct' or 'create_map' function."
     ]
    }
   ],
   "source": [
    "#In some cases, your missing values are recoded with a string value (and not recognized in Spark as Null explicitly)\n",
    "# The below code can be partially used outside of imputation context \n",
    "# to replace a string value with NA using regex_replace\n",
    "missing_value = \"NA\"\n",
    "df_with_substituted_na = (casted_types_df_with_na_dropped_rows\\\n",
    "    .withColumn('src_bytes', \\\n",
    "                when(casted_types_df_with_na_dropped_rows.src_bytes==missing_value,\\\n",
    "                    regexp_replace(casted_types_df_with_na_dropped_rows.src_bytes,missing_value,None)) \\\n",
    "                .otherwise(casted_types_df_with_na_dropped_rows.src_bytes))\\\n",
    "                )\n",
    "\n",
    "df_with_substituted_na.show(1, vertical=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "columns_to_be_imputed = [\"src_bytes\"]\n",
    "value_not_in_dataset = -200\n",
    "\n",
    "# Replace None/Missing Value with a value that can't be present in the dataset.\n",
    "df_with_filled_na = casted_types_df_with_na_dropped_rows.fillna(-200, columns_to_be_imputed)\n",
    "\n",
    "#Create new columns with imputed values. New columns will be suffixed with \"_imputed\"\n",
    "imputer = Imputer (\n",
    "            inputCols=columns_to_be_imputed,\n",
    "            outputCols=[\"{}_imputed\".format(c) for c in columns_to_be_imputed])\\\n",
    "            .setStrategy(\"median\").setMissingValue(value_not_in_dataset)\n",
    "\n",
    "df_imputed = imputer.fit(df_with_filled_na).transform(df_with_filled_na)\n",
    "# we will drop the old column without imputation. We have only one column to be imputed\n",
    "df_imputed_enhanced = df_imputed.drop(columns_to_be_imputed[0])\n",
    "\n",
    "# We will rename our newly imputed column with the correct name\n",
    "df_fully_imputed = df_imputed_enhanced.withColumnRenamed(\"src_bytes_imputed\",\"src_bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- duration: integer (nullable = true)\n",
      " |-- protocol_type: string (nullable = true)\n",
      " |-- service: string (nullable = true)\n",
      " |-- flag: string (nullable = true)\n",
      " |-- dst_bytes: integer (nullable = true)\n",
      " |-- land: integer (nullable = true)\n",
      " |-- wrong_fragment: integer (nullable = true)\n",
      " |-- urgent: integer (nullable = true)\n",
      " |-- hot: integer (nullable = true)\n",
      " |-- num_failed_logins: integer (nullable = true)\n",
      " |-- logged_in: integer (nullable = true)\n",
      " |-- num_compromised: integer (nullable = true)\n",
      " |-- root_shell: integer (nullable = true)\n",
      " |-- su_attempted: integer (nullable = true)\n",
      " |-- num_root: integer (nullable = true)\n",
      " |-- num_file_creations: integer (nullable = true)\n",
      " |-- num_shells: integer (nullable = true)\n",
      " |-- num_access_files: integer (nullable = true)\n",
      " |-- num_outbound_cmds: integer (nullable = true)\n",
      " |-- is_host_login: integer (nullable = true)\n",
      " |-- is_guest_login: integer (nullable = true)\n",
      " |-- count: integer (nullable = true)\n",
      " |-- srv_count: integer (nullable = true)\n",
      " |-- serror_rate: double (nullable = true)\n",
      " |-- srv_serror_rate: double (nullable = true)\n",
      " |-- rerror_rate: double (nullable = true)\n",
      " |-- srv_rerror_rate: double (nullable = true)\n",
      " |-- same_srv_rate: double (nullable = true)\n",
      " |-- diff_srv_rate: double (nullable = true)\n",
      " |-- srv_diff_host_rate: double (nullable = true)\n",
      " |-- dst_host_count: integer (nullable = true)\n",
      " |-- dst_host_srv_count: integer (nullable = true)\n",
      " |-- dst_host_same_srv_rate: double (nullable = true)\n",
      " |-- dst_host_diff_srv_rate: double (nullable = true)\n",
      " |-- dst_host_same_src_port_rate: double (nullable = true)\n",
      " |-- dst_host_srv_diff_host_rate: double (nullable = true)\n",
      " |-- dst_host_serror_rate: double (nullable = true)\n",
      " |-- dst_host_srv_serror_rate: double (nullable = true)\n",
      " |-- dst_host_rerror_rate: double (nullable = true)\n",
      " |-- dst_host_srv_rerror_rate: double (nullable = true)\n",
      " |-- classes: string (nullable = true)\n",
      " |-- difficulty_level: integer (nullable = true)\n",
      " |-- src_bytes: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_fully_imputed.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-------------------------------\n",
      " duration                    | 0        \n",
      " protocol_type               | tcp      \n",
      " service                     | ftp_data \n",
      " flag                        | SF       \n",
      " dst_bytes                   | 0        \n",
      " land                        | 0        \n",
      " wrong_fragment              | 0        \n",
      " urgent                      | 0        \n",
      " hot                         | 0        \n",
      " num_failed_logins           | 0        \n",
      " logged_in                   | 0        \n",
      " num_compromised             | 0        \n",
      " root_shell                  | 0        \n",
      " su_attempted                | 0        \n",
      " num_root                    | 0        \n",
      " num_file_creations          | 0        \n",
      " num_shells                  | 0        \n",
      " num_access_files            | 0        \n",
      " num_outbound_cmds           | 0        \n",
      " is_host_login               | 0        \n",
      " is_guest_login              | 0        \n",
      " count                       | 2        \n",
      " srv_count                   | 2        \n",
      " serror_rate                 | 0.0      \n",
      " srv_serror_rate             | 0.0      \n",
      " rerror_rate                 | 0.0      \n",
      " srv_rerror_rate             | 0.0      \n",
      " same_srv_rate               | 1.0      \n",
      " diff_srv_rate               | 0.0      \n",
      " srv_diff_host_rate          | 0.0      \n",
      " dst_host_count              | 150      \n",
      " dst_host_srv_count          | 25       \n",
      " dst_host_same_srv_rate      | 0.17     \n",
      " dst_host_diff_srv_rate      | 0.03     \n",
      " dst_host_same_src_port_rate | 0.17     \n",
      " dst_host_srv_diff_host_rate | 0.0      \n",
      " dst_host_serror_rate        | 0.0      \n",
      " dst_host_srv_serror_rate    | 0.0      \n",
      " dst_host_rerror_rate        | 0.05     \n",
      " dst_host_srv_rerror_rate    | 0.0      \n",
      " classes                     | normal   \n",
      " difficulty_level            | 20       \n",
      " src_bytes                   | 491      \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_fully_imputed.show(1,vertical=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "<p style=\"page-break-after:always;\"></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Phase-II: ML Modeling and MLOps </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2>Now, let's go ahead and talk about Feature Engineering.</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The basic process here is:<ul>\n",
    "<li>Begin by classifying your variables into numerical and categorical</li>\n",
    "\n",
    "<li>Then, look at  numerical summaries of numerical variables.</li>\n",
    "\n",
    "<li>Follow this with an examination to the distribution of each variable individually.</li>\n",
    "\n",
    "<li>Then move on to study the relationships among the variables.</li>\n",
    "\n",
    "<li>Try to visualize all what you can!</li>\n",
    "\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Exploring data for machine learning is a lot similar to exploring data when performing a transformation in the sense that we manipulate the data to uncover some inconsistencies, patterns, or gaps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2>1. Classify Your variables</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<ul>\n",
    "<li>The information is organized in variables.</li>\n",
    "<li>A variable is any characteristic of an individual or a case.</li>\n",
    "    <li>In Spark, each attribute (column) in your dataframe represent a variable</li>    \n",
    "    <li>A variable can take different values for different individuals.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3>Reminder: Types of Variables</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<ul>\n",
    "    <li><b>Continuous Variables: or quantitative variables.</b></li>\n",
    "    <li><b>Categorical Variables:</b> can be divided into:\n",
    "        <ul>\n",
    "            <li><b>Binary Variables:</b> when you have only two choices (0/1, True/False)</li>            \n",
    "            <li><b>Ordinal Variables:</b> when the categories have a certain ordering (like low/medium/high)</li>\n",
    "            <li><b>Nominal Variables:</b> when the categories have no specific ordering (like the color of an item).</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "<p style=\"page-break-after:always;\"></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Note the following:\n",
    "    <ul>\n",
    "    <li>Identifying your variables as categorical (with the proper sub-type) or continuous has a direct impact on the data preparation and, down the road, the performance of your machine learning model.</li>\n",
    "    <li>Proper identification is dependent on the context (what does the column mean?) and how you want to encode its meaning.</li>\n",
    "    <li>Don’t worry if you don’t get it right the first time. You can always come back and touch up your feature types.</li>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><figure><img src=\"http://stat.cmu.edu/~mfarag/14810/l12/feature_types.png\"/><figcaption>Image taken from https://livebook.manning.com/#!/book/data-analysis-with-python-and-pyspark/discussion</figcaption></figure></center>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "<p style=\"page-break-after:always;\"></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2>2. Creating a Summary Table</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<ul>\n",
    "<li>Checking the summary statistics for our dataframe helps us validate our numerical columns. This is helpful for several reasons such as understanding the variability in your data and the scale of data for each variable.</li>\n",
    "    <li>Remember, your ML model is mathematical model after all. If you have variable that includes values between 0 and 100, it will have higher influence than a column that has values between 0 and 1.</li>\n",
    "    <li>You may include the Summary columns for some categorical columns but you would have to ignore them during your analysis</li></ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 15:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0--------------------------------------------\n",
      " summary                     | count                 \n",
      " duration                    | 125973                \n",
      " protocol_type               | 125973                \n",
      " service                     | 125973                \n",
      " flag                        | 125973                \n",
      " dst_bytes                   | 125973                \n",
      " land                        | 125973                \n",
      " wrong_fragment              | 125973                \n",
      " urgent                      | 125973                \n",
      " hot                         | 125973                \n",
      " num_failed_logins           | 125973                \n",
      " logged_in                   | 125973                \n",
      " num_compromised             | 125973                \n",
      " root_shell                  | 125973                \n",
      " su_attempted                | 125973                \n",
      " num_root                    | 125973                \n",
      " num_file_creations          | 125973                \n",
      " num_shells                  | 125973                \n",
      " num_access_files            | 125973                \n",
      " num_outbound_cmds           | 125973                \n",
      " is_host_login               | 125973                \n",
      " is_guest_login              | 125973                \n",
      " count                       | 125973                \n",
      " srv_count                   | 125973                \n",
      " serror_rate                 | 125973                \n",
      " srv_serror_rate             | 125973                \n",
      " rerror_rate                 | 125973                \n",
      " srv_rerror_rate             | 125973                \n",
      " same_srv_rate               | 125973                \n",
      " diff_srv_rate               | 125973                \n",
      " srv_diff_host_rate          | 125973                \n",
      " dst_host_count              | 125973                \n",
      " dst_host_srv_count          | 125973                \n",
      " dst_host_same_srv_rate      | 125973                \n",
      " dst_host_diff_srv_rate      | 125973                \n",
      " dst_host_same_src_port_rate | 125973                \n",
      " dst_host_srv_diff_host_rate | 125973                \n",
      " dst_host_serror_rate        | 125973                \n",
      " dst_host_srv_serror_rate    | 125973                \n",
      " dst_host_rerror_rate        | 125973                \n",
      " dst_host_srv_rerror_rate    | 125973                \n",
      " classes                     | 125973                \n",
      " difficulty_level            | 125973                \n",
      " src_bytes                   | 125973                \n",
      "-RECORD 1--------------------------------------------\n",
      " summary                     | mean                  \n",
      " duration                    | 287.1446500440571     \n",
      " protocol_type               | null                  \n",
      " service                     | null                  \n",
      " flag                        | null                  \n",
      " dst_bytes                   | 19779.114421344257    \n",
      " land                        | 1.9845522453224102E-4 \n",
      " wrong_fragment              | 0.022687401268525795  \n",
      " urgent                      | 1.1113492573805498E-4 \n",
      " hot                         | 0.20440888126820828   \n",
      " num_failed_logins           | 0.0012224841831186047 \n",
      " logged_in                   | 0.3957355941352512    \n",
      " num_compromised             | 0.279250315543807     \n",
      " root_shell                  | 0.0013415573178379495 \n",
      " su_attempted                | 0.0011034110483992602 \n",
      " num_root                    | 0.30219173949973405   \n",
      " num_file_creations          | 0.012669381534138267  \n",
      " num_shells                  | 4.1278686702706137E-4 \n",
      " num_access_files            | 0.004096115834345455  \n",
      " num_outbound_cmds           | 0.0                   \n",
      " is_host_login               | 7.938208981289641E-6  \n",
      " is_guest_login              | 0.009422654060790804  \n",
      " count                       | 84.1075547934875      \n",
      " srv_count                   | 27.737888277646796    \n",
      " serror_rate                 | 0.28448453239980326   \n",
      " srv_serror_rate             | 0.2824853738499541    \n",
      " rerror_rate                 | 0.11995848316702819   \n",
      " srv_rerror_rate             | 0.1211832694307515    \n",
      " same_srv_rate               | 0.6609276591015364    \n",
      " diff_srv_rate               | 0.06305263826378092   \n",
      " srv_diff_host_rate          | 0.0973216482897197    \n",
      " dst_host_count              | 182.14894461511594    \n",
      " dst_host_srv_count          | 115.65300500900987    \n",
      " dst_host_same_srv_rate      | 0.5212416946488446    \n",
      " dst_host_diff_srv_rate      | 0.0829511085708952    \n",
      " dst_host_same_src_port_rate | 0.14837885896186095   \n",
      " dst_host_srv_diff_host_rate | 0.032542449572537116  \n",
      " dst_host_serror_rate        | 0.28445246203550506   \n",
      " dst_host_srv_serror_rate    | 0.27848451652336653   \n",
      " dst_host_rerror_rate        | 0.11883181316631937   \n",
      " dst_host_srv_rerror_rate    | 0.1202398926754181    \n",
      " classes                     | null                  \n",
      " difficulty_level            | 19.50406039389393     \n",
      " src_bytes                   | 45566.74300048423     \n",
      "-RECORD 2--------------------------------------------\n",
      " summary                     | stddev                \n",
      " duration                    | 2604.515309867581     \n",
      " protocol_type               | null                  \n",
      " service                     | null                  \n",
      " flag                        | null                  \n",
      " dst_bytes                   | 4021269.1514414363    \n",
      " land                        | 0.01408607167151311   \n",
      " wrong_fragment              | 0.25352998595201387   \n",
      " urgent                      | 0.014366026620154288  \n",
      " hot                         | 2.1499684337047573    \n",
      " num_failed_logins           | 0.04523913898133003   \n",
      " logged_in                   | 0.48901005300524314   \n",
      " num_compromised             | 23.942042242795054    \n",
      " root_shell                  | 0.036602843839798484  \n",
      " su_attempted                | 0.04515438381386554   \n",
      " num_root                    | 24.39961808883781     \n",
      " num_file_creations          | 0.48393506939604364   \n",
      " num_shells                  | 0.022181128678694116  \n",
      " num_access_files            | 0.09936955575066035   \n",
      " num_outbound_cmds           | 0.0                   \n",
      " is_host_login               | 0.002817482738419109  \n",
      " is_guest_login              | 0.09661232709143137   \n",
      " count                       | 114.50860735418443    \n",
      " srv_count                   | 72.6358396472384      \n",
      " serror_rate                 | 0.44645562433102254   \n",
      " srv_serror_rate             | 0.4470224983640152    \n",
      " rerror_rate                 | 0.3204355207495192    \n",
      " srv_rerror_rate             | 0.32364722800546275   \n",
      " same_srv_rate               | 0.43962286240748155   \n",
      " diff_srv_rate               | 0.18031440750857608   \n",
      " srv_diff_host_rate          | 0.2598304981211563    \n",
      " dst_host_count              | 99.20621303459828     \n",
      " dst_host_srv_count          | 110.70274078086435    \n",
      " dst_host_same_srv_rate      | 0.4489493637176776    \n",
      " dst_host_diff_srv_rate      | 0.18892179990461488   \n",
      " dst_host_same_src_port_rate | 0.3089971303729862    \n",
      " dst_host_srv_diff_host_rate | 0.11256380488119017   \n",
      " dst_host_serror_rate        | 0.44478405031649426   \n",
      " dst_host_srv_serror_rate    | 0.4456691238860277    \n",
      " dst_host_rerror_rate        | 0.3065574580251714    \n",
      " dst_host_srv_rerror_rate    | 0.3194593904552323    \n",
      " classes                     | null                  \n",
      " difficulty_level            | 2.2915029391013584    \n",
      " src_bytes                   | 5870331.18189357      \n",
      "-RECORD 3--------------------------------------------\n",
      " summary                     | min                   \n",
      " duration                    | 0                     \n",
      " protocol_type               | icmp                  \n",
      " service                     | IRC                   \n",
      " flag                        | OTH                   \n",
      " dst_bytes                   | 0                     \n",
      " land                        | 0                     \n",
      " wrong_fragment              | 0                     \n",
      " urgent                      | 0                     \n",
      " hot                         | 0                     \n",
      " num_failed_logins           | 0                     \n",
      " logged_in                   | 0                     \n",
      " num_compromised             | 0                     \n",
      " root_shell                  | 0                     \n",
      " su_attempted                | 0                     \n",
      " num_root                    | 0                     \n",
      " num_file_creations          | 0                     \n",
      " num_shells                  | 0                     \n",
      " num_access_files            | 0                     \n",
      " num_outbound_cmds           | 0                     \n",
      " is_host_login               | 0                     \n",
      " is_guest_login              | 0                     \n",
      " count                       | 0                     \n",
      " srv_count                   | 0                     \n",
      " serror_rate                 | 0.0                   \n",
      " srv_serror_rate             | 0.0                   \n",
      " rerror_rate                 | 0.0                   \n",
      " srv_rerror_rate             | 0.0                   \n",
      " same_srv_rate               | 0.0                   \n",
      " diff_srv_rate               | 0.0                   \n",
      " srv_diff_host_rate          | 0.0                   \n",
      " dst_host_count              | 0                     \n",
      " dst_host_srv_count          | 0                     \n",
      " dst_host_same_srv_rate      | 0.0                   \n",
      " dst_host_diff_srv_rate      | 0.0                   \n",
      " dst_host_same_src_port_rate | 0.0                   \n",
      " dst_host_srv_diff_host_rate | 0.0                   \n",
      " dst_host_serror_rate        | 0.0                   \n",
      " dst_host_srv_serror_rate    | 0.0                   \n",
      " dst_host_rerror_rate        | 0.0                   \n",
      " dst_host_srv_rerror_rate    | 0.0                   \n",
      " classes                     | back                  \n",
      " difficulty_level            | 0                     \n",
      " src_bytes                   | 0                     \n",
      "-RECORD 4--------------------------------------------\n",
      " summary                     | 25%                   \n",
      " duration                    | 0                     \n",
      " protocol_type               | null                  \n",
      " service                     | null                  \n",
      " flag                        | null                  \n",
      " dst_bytes                   | 0                     \n",
      " land                        | 0                     \n",
      " wrong_fragment              | 0                     \n",
      " urgent                      | 0                     \n",
      " hot                         | 0                     \n",
      " num_failed_logins           | 0                     \n",
      " logged_in                   | 0                     \n",
      " num_compromised             | 0                     \n",
      " root_shell                  | 0                     \n",
      " su_attempted                | 0                     \n",
      " num_root                    | 0                     \n",
      " num_file_creations          | 0                     \n",
      " num_shells                  | 0                     \n",
      " num_access_files            | 0                     \n",
      " num_outbound_cmds           | 0                     \n",
      " is_host_login               | 0                     \n",
      " is_guest_login              | 0                     \n",
      " count                       | 2                     \n",
      " srv_count                   | 2                     \n",
      " serror_rate                 | 0.0                   \n",
      " srv_serror_rate             | 0.0                   \n",
      " rerror_rate                 | 0.0                   \n",
      " srv_rerror_rate             | 0.0                   \n",
      " same_srv_rate               | 0.09                  \n",
      " diff_srv_rate               | 0.0                   \n",
      " srv_diff_host_rate          | 0.0                   \n",
      " dst_host_count              | 82                    \n",
      " dst_host_srv_count          | 10                    \n",
      " dst_host_same_srv_rate      | 0.05                  \n",
      " dst_host_diff_srv_rate      | 0.0                   \n",
      " dst_host_same_src_port_rate | 0.0                   \n",
      " dst_host_srv_diff_host_rate | 0.0                   \n",
      " dst_host_serror_rate        | 0.0                   \n",
      " dst_host_srv_serror_rate    | 0.0                   \n",
      " dst_host_rerror_rate        | 0.0                   \n",
      " dst_host_srv_rerror_rate    | 0.0                   \n",
      " classes                     | null                  \n",
      " difficulty_level            | 18                    \n",
      " src_bytes                   | 0                     \n",
      "-RECORD 5--------------------------------------------\n",
      " summary                     | 50%                   \n",
      " duration                    | 0                     \n",
      " protocol_type               | null                  \n",
      " service                     | null                  \n",
      " flag                        | null                  \n",
      " dst_bytes                   | 0                     \n",
      " land                        | 0                     \n",
      " wrong_fragment              | 0                     \n",
      " urgent                      | 0                     \n",
      " hot                         | 0                     \n",
      " num_failed_logins           | 0                     \n",
      " logged_in                   | 0                     \n",
      " num_compromised             | 0                     \n",
      " root_shell                  | 0                     \n",
      " su_attempted                | 0                     \n",
      " num_root                    | 0                     \n",
      " num_file_creations          | 0                     \n",
      " num_shells                  | 0                     \n",
      " num_access_files            | 0                     \n",
      " num_outbound_cmds           | 0                     \n",
      " is_host_login               | 0                     \n",
      " is_guest_login              | 0                     \n",
      " count                       | 14                    \n",
      " srv_count                   | 8                     \n",
      " serror_rate                 | 0.0                   \n",
      " srv_serror_rate             | 0.0                   \n",
      " rerror_rate                 | 0.0                   \n",
      " srv_rerror_rate             | 0.0                   \n",
      " same_srv_rate               | 1.0                   \n",
      " diff_srv_rate               | 0.0                   \n",
      " srv_diff_host_rate          | 0.0                   \n",
      " dst_host_count              | 255                   \n",
      " dst_host_srv_count          | 63                    \n",
      " dst_host_same_srv_rate      | 0.51                  \n",
      " dst_host_diff_srv_rate      | 0.02                  \n",
      " dst_host_same_src_port_rate | 0.0                   \n",
      " dst_host_srv_diff_host_rate | 0.0                   \n",
      " dst_host_serror_rate        | 0.0                   \n",
      " dst_host_srv_serror_rate    | 0.0                   \n",
      " dst_host_rerror_rate        | 0.0                   \n",
      " dst_host_srv_rerror_rate    | 0.0                   \n",
      " classes                     | null                  \n",
      " difficulty_level            | 20                    \n",
      " src_bytes                   | 44                    \n",
      "-RECORD 6--------------------------------------------\n",
      " summary                     | 75%                   \n",
      " duration                    | 0                     \n",
      " protocol_type               | null                  \n",
      " service                     | null                  \n",
      " flag                        | null                  \n",
      " dst_bytes                   | 516                   \n",
      " land                        | 0                     \n",
      " wrong_fragment              | 0                     \n",
      " urgent                      | 0                     \n",
      " hot                         | 0                     \n",
      " num_failed_logins           | 0                     \n",
      " logged_in                   | 1                     \n",
      " num_compromised             | 0                     \n",
      " root_shell                  | 0                     \n",
      " su_attempted                | 0                     \n",
      " num_root                    | 0                     \n",
      " num_file_creations          | 0                     \n",
      " num_shells                  | 0                     \n",
      " num_access_files            | 0                     \n",
      " num_outbound_cmds           | 0                     \n",
      " is_host_login               | 0                     \n",
      " is_guest_login              | 0                     \n",
      " count                       | 143                   \n",
      " srv_count                   | 18                    \n",
      " serror_rate                 | 1.0                   \n",
      " srv_serror_rate             | 1.0                   \n",
      " rerror_rate                 | 0.0                   \n",
      " srv_rerror_rate             | 0.0                   \n",
      " same_srv_rate               | 1.0                   \n",
      " diff_srv_rate               | 0.06                  \n",
      " srv_diff_host_rate          | 0.0                   \n",
      " dst_host_count              | 255                   \n",
      " dst_host_srv_count          | 255                   \n",
      " dst_host_same_srv_rate      | 1.0                   \n",
      " dst_host_diff_srv_rate      | 0.07                  \n",
      " dst_host_same_src_port_rate | 0.06                  \n",
      " dst_host_srv_diff_host_rate | 0.02                  \n",
      " dst_host_serror_rate        | 1.0                   \n",
      " dst_host_srv_serror_rate    | 1.0                   \n",
      " dst_host_rerror_rate        | 0.0                   \n",
      " dst_host_srv_rerror_rate    | 0.0                   \n",
      " classes                     | null                  \n",
      " difficulty_level            | 21                    \n",
      " src_bytes                   | 276                   \n",
      "-RECORD 7--------------------------------------------\n",
      " summary                     | max                   \n",
      " duration                    | 42908                 \n",
      " protocol_type               | udp                   \n",
      " service                     | whois                 \n",
      " flag                        | SH                    \n",
      " dst_bytes                   | 1309937401            \n",
      " land                        | 1                     \n",
      " wrong_fragment              | 3                     \n",
      " urgent                      | 3                     \n",
      " hot                         | 77                    \n",
      " num_failed_logins           | 5                     \n",
      " logged_in                   | 1                     \n",
      " num_compromised             | 7479                  \n",
      " root_shell                  | 1                     \n",
      " su_attempted                | 2                     \n",
      " num_root                    | 7468                  \n",
      " num_file_creations          | 43                    \n",
      " num_shells                  | 2                     \n",
      " num_access_files            | 9                     \n",
      " num_outbound_cmds           | 0                     \n",
      " is_host_login               | 1                     \n",
      " is_guest_login              | 1                     \n",
      " count                       | 511                   \n",
      " srv_count                   | 511                   \n",
      " serror_rate                 | 1.0                   \n",
      " srv_serror_rate             | 1.0                   \n",
      " rerror_rate                 | 1.0                   \n",
      " srv_rerror_rate             | 1.0                   \n",
      " same_srv_rate               | 1.0                   \n",
      " diff_srv_rate               | 1.0                   \n",
      " srv_diff_host_rate          | 1.0                   \n",
      " dst_host_count              | 255                   \n",
      " dst_host_srv_count          | 255                   \n",
      " dst_host_same_srv_rate      | 1.0                   \n",
      " dst_host_diff_srv_rate      | 1.0                   \n",
      " dst_host_same_src_port_rate | 1.0                   \n",
      " dst_host_srv_diff_host_rate | 1.0                   \n",
      " dst_host_serror_rate        | 1.0                   \n",
      " dst_host_srv_serror_rate    | 1.0                   \n",
      " dst_host_rerror_rate        | 1.0                   \n",
      " dst_host_srv_rerror_rate    | 1.0                   \n",
      " classes                     | warezmaster           \n",
      " difficulty_level            | 21                    \n",
      " src_bytes                   | 1379963888            \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_fully_imputed.summary().show(truncate=False, vertical=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Wouldn't it be better to use graphs to look at these numbers rather than looking at it yourself?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3>The five-number summary</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The five-number summary of a set of observations consists of the smallest observation, the first quartile, the median, the third quartile, and the largest observation, written in order from smallest to largest.\n",
    "In symbols, the five-number summary is\n",
    "<ul>\n",
    "<li>Minimum </li>\n",
    "<li>25% of your data (Q1)</li>\n",
    "<li>Median of your data </li>\n",
    "<li>75% of your data (Q3)</li>\n",
    "<li>Maximum</li>\n",
    "</ul>\n",
    "\n",
    "These five numbers give a reasonably complete description of both the center and the spread of the distribution."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "<p style=\"page-break-after:always;\"></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3>Boxplots</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><figure><img src=\"http://stat.cmu.edu/~mfarag/14810/l12/boxplot.png\"/><figcaption>Boxplot Structure</figcaption></figure></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A boxplot is a graph of the five-number summary. \n",
    "<ul>\n",
    "    <li>A central box spans the quartiles 𝑄1 and 𝑄3.</li>\n",
    "<li>A line in the box marks the median M.</li>\n",
    "<li>Lines extend from the box out to the smallest and largest observations</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Boxplots are\n",
    "<ul>\n",
    "<li>Good for comparing data sets by showing them side-by-side on the same graph.</li>\n",
    "<li>Good at showing amount of variability.</li>\n",
    "<li>Weak at showing the shape of the distribution (e.g. does not show how many modes there are).</li>\n",
    "    <li>Location of median indicates symmetry or asymmetry.</li>\n",
    "</ul>\n",
    "\n",
    "<b>Now, let's Draw Boxplots!!</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('duration', 'int'),\n",
       " ('protocol_type', 'string'),\n",
       " ('service', 'string'),\n",
       " ('flag', 'string'),\n",
       " ('dst_bytes', 'int'),\n",
       " ('land', 'int'),\n",
       " ('wrong_fragment', 'int'),\n",
       " ('urgent', 'int'),\n",
       " ('hot', 'int'),\n",
       " ('num_failed_logins', 'int'),\n",
       " ('logged_in', 'int'),\n",
       " ('num_compromised', 'int'),\n",
       " ('root_shell', 'int'),\n",
       " ('su_attempted', 'int'),\n",
       " ('num_root', 'int'),\n",
       " ('num_file_creations', 'int'),\n",
       " ('num_shells', 'int'),\n",
       " ('num_access_files', 'int'),\n",
       " ('num_outbound_cmds', 'int'),\n",
       " ('is_host_login', 'int'),\n",
       " ('is_guest_login', 'int'),\n",
       " ('count', 'int'),\n",
       " ('srv_count', 'int'),\n",
       " ('serror_rate', 'double'),\n",
       " ('srv_serror_rate', 'double'),\n",
       " ('rerror_rate', 'double'),\n",
       " ('srv_rerror_rate', 'double'),\n",
       " ('same_srv_rate', 'double'),\n",
       " ('diff_srv_rate', 'double'),\n",
       " ('srv_diff_host_rate', 'double'),\n",
       " ('dst_host_count', 'int'),\n",
       " ('dst_host_srv_count', 'int'),\n",
       " ('dst_host_same_srv_rate', 'double'),\n",
       " ('dst_host_diff_srv_rate', 'double'),\n",
       " ('dst_host_same_src_port_rate', 'double'),\n",
       " ('dst_host_srv_diff_host_rate', 'double'),\n",
       " ('dst_host_serror_rate', 'double'),\n",
       " ('dst_host_srv_serror_rate', 'double'),\n",
       " ('dst_host_rerror_rate', 'double'),\n",
       " ('dst_host_srv_rerror_rate', 'double'),\n",
       " ('classes', 'string'),\n",
       " ('difficulty_level', 'int'),\n",
       " ('src_bytes', 'int')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will draw boxplots for the numerical features\n",
    "# Now let's check the datatypes of the dataframe\n",
    "df_fully_imputed.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['duration',\n",
       " 'dst_bytes',\n",
       " 'land',\n",
       " 'wrong_fragment',\n",
       " 'urgent',\n",
       " 'hot',\n",
       " 'num_failed_logins',\n",
       " 'logged_in',\n",
       " 'num_compromised',\n",
       " 'root_shell',\n",
       " 'su_attempted',\n",
       " 'num_root',\n",
       " 'num_file_creations',\n",
       " 'num_shells',\n",
       " 'num_access_files',\n",
       " 'num_outbound_cmds',\n",
       " 'is_host_login',\n",
       " 'is_guest_login',\n",
       " 'count',\n",
       " 'srv_count',\n",
       " 'serror_rate',\n",
       " 'srv_serror_rate',\n",
       " 'rerror_rate',\n",
       " 'srv_rerror_rate',\n",
       " 'same_srv_rate',\n",
       " 'diff_srv_rate',\n",
       " 'srv_diff_host_rate',\n",
       " 'dst_host_count',\n",
       " 'dst_host_srv_count',\n",
       " 'dst_host_same_srv_rate',\n",
       " 'dst_host_diff_srv_rate',\n",
       " 'dst_host_same_src_port_rate',\n",
       " 'dst_host_srv_diff_host_rate',\n",
       " 'dst_host_serror_rate',\n",
       " 'dst_host_srv_serror_rate',\n",
       " 'dst_host_rerror_rate',\n",
       " 'dst_host_srv_rerror_rate',\n",
       " 'difficulty_level',\n",
       " 'src_bytes']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_features = [feature[0] for feature in df_fully_imputed.dtypes if feature[1] in ('int','double')]\n",
    "numeric_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Extract data and convert them into Pandas for visualization\n",
    "converted_data = df_fully_imputed[numeric_features].toPandas()\n",
    "\n",
    "figure = plt.boxplot(converted_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "That looks ugly!!! Let's get a subset of the variables and display them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "spotted_data = df_fully_imputed[numeric_features[36:38]].toPandas()\n",
    "figure_subset = plt.boxplot(spotted_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Did you think what the circles in the previous graph represent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The answer is <b>Outliers</b>."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "<p style=\"page-break-after:always;\"></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Based on these results, we MAY need to <b>handle outliers</b>!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2>3. Outliers</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "An outlier is an observation that is usually large or small relative to the other values in a data set. Identifying outliers is crucial for the selection of the ML model. Some models are more sensitive to outliers than others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Outliers are typically attributable to one of the following causes:\n",
    "<ul><li>The observation is observed, recorded, or entered incorrectly.</li>\n",
    "<li>The observation comes from a different population.</li>\n",
    "<li>The observation is correct but represents a rare event</li>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3>How to spot an Outlier in Numerical Variable?</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "There are several ways to find outliers. The most important way is the Inter-Quartile Range (IQR). The IQR is a measure of spread that is less sensitive to the influence of extreme values.<br/> The IQR is defined as Q3 - Q1 from your boxplot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3>How does the IQR is used in spotting Outliers?</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The rule of <b>1.5×IQR Criterion for outliers</b>. Call an observation a suspected outlier if it falls:\n",
    "<ul>\n",
    "    <li>more than 1.5×IQR above the 3rd quartile or</li>\n",
    "    <li>more than 1.5×IQR below the 1st quartile</li>\n",
    "</ul>\n",
    "\n",
    "<center><figure><img src=\"http://stat.cmu.edu/~mfarag/14810/l13/iqr_for_outliers.png\"/></figure></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['whiskers', 'caps', 'boxes', 'medians', 'fliers', 'means'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "figure_subset.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3>How to Print Q1 and Q3 Ranges?</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0, 14.0, 21.0]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Values printed as comma separated Q1, Q3 for each object.\n",
    "[item.get_ydata()[1] for item in figure_subset['whiskers']]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "<p style=\"page-break-after:always;\"></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3>How to Print the Outliers?</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.01, 1.  , 1.  , ..., 0.02, 0.93, 1.  ]),\n",
       " array([12., 11.,  2., ..., 10., 12., 11.])]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how to print outliers?!\n",
    "[item.get_ydata() for item in figure_subset['fliers']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3>Look through the following code and understand the find_outliers() function</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "def column_add(a,b):\n",
    "     return  a.__add__(b)\n",
    "    \n",
    "def find_outliers(df):\n",
    "    # Identifying the numerical columns in a spark dataframe\n",
    "    numeric_columns = [column[0] for column in df.dtypes if column[1]=='int']\n",
    "\n",
    "    # Using the `for` loop to create new columns by identifying the outliers for each feature\n",
    "    for column in numeric_columns:\n",
    "\n",
    "        less_Q1 = 'less_Q1_{}'.format(column)\n",
    "        more_Q3 = 'more_Q3_{}'.format(column)\n",
    "        Q1 = 'Q1_{}'.format(column)\n",
    "        Q3 = 'Q3_{}'.format(column)\n",
    "\n",
    "        # Q1 : First Quartile ., Q3 : Third Quartile\n",
    "        Q1 = df.approxQuantile(column,[0.25],relativeError=0)\n",
    "        Q3 = df.approxQuantile(column,[0.75],relativeError=0)\n",
    "        \n",
    "        # IQR : Inter Quantile Range\n",
    "        # We need to define the index [0], as Q1 & Q3 are a set of lists., to perform a mathematical operation\n",
    "        # Q1 & Q3 are defined seperately so as to have a clear indication on First Quantile & 3rd Quantile\n",
    "        IQR = Q3[0] - Q1[0]\n",
    "        \n",
    "        #selecting the data, with -1.5*IQR to + 1.5*IQR., where param = 1.5 default value\n",
    "        less_Q1 =  Q1[0] - 1.5*IQR\n",
    "        more_Q3 =  Q3[0] + 1.5*IQR\n",
    "        \n",
    "        isOutlierCol = 'is_outlier_{}'.format(column)\n",
    "        \n",
    "        df = df.withColumn(isOutlierCol,when((df[column] > more_Q3) | (df[column] < less_Q1), 1).otherwise(0))\n",
    "    \n",
    "\n",
    "    # Selecting the specific columns which we have added above, to check if there are any outliers\n",
    "    selected_columns = [column for column in df.columns if column.startswith(\"is_outlier\")]\n",
    "    # Adding all the outlier columns into a new colum \"total_outliers\", to see the total number of outliers\n",
    "    df = df.withColumn('total_outliers',reduce(column_add, ( df[col] for col in  selected_columns)))\n",
    "\n",
    "    # Dropping the extra columns created above, just to create nice dataframe., without extra columns\n",
    "    df = df.drop(*[column for column in df.columns if column.startswith(\"is_outlier\")])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0--------------------------\n",
      " duration                    | 0   \n",
      " dst_bytes                   | 0   \n",
      " land                        | 0   \n",
      " wrong_fragment              | 0   \n",
      " urgent                      | 0   \n",
      " hot                         | 0   \n",
      " num_failed_logins           | 0   \n",
      " logged_in                   | 0   \n",
      " num_compromised             | 0   \n",
      " root_shell                  | 0   \n",
      " su_attempted                | 0   \n",
      " num_root                    | 0   \n",
      " num_file_creations          | 0   \n",
      " num_shells                  | 0   \n",
      " num_access_files            | 0   \n",
      " num_outbound_cmds           | 0   \n",
      " is_host_login               | 0   \n",
      " is_guest_login              | 0   \n",
      " count                       | 0   \n",
      " srv_count                   | 0   \n",
      " serror_rate                 | 0   \n",
      " srv_serror_rate             | 0   \n",
      " rerror_rate                 | 0   \n",
      " srv_rerror_rate             | 0   \n",
      " same_srv_rate               | 0   \n",
      " diff_srv_rate               | 0   \n",
      " srv_diff_host_rate          | 0   \n",
      " dst_host_count              | 0   \n",
      " dst_host_srv_count          | 0   \n",
      " dst_host_same_srv_rate      | 0   \n",
      " dst_host_diff_srv_rate      | 0   \n",
      " dst_host_same_src_port_rate | 0   \n",
      " dst_host_srv_diff_host_rate | 0   \n",
      " dst_host_serror_rate        | 0   \n",
      " dst_host_srv_serror_rate    | 0   \n",
      " dst_host_rerror_rate        | 0   \n",
      " dst_host_srv_rerror_rate    | 0   \n",
      " difficulty_level            | 0   \n",
      " src_bytes                   | 0   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# As a reminder, we don't have any null values for the outliers to be handled\n",
    "numeric_columns = [column[0] for column in df_fully_imputed.dtypes if column[1] in ('int','double')]\n",
    "df_fully_imputed.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in numeric_columns]).show(1, vertical=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-------------------------------\n",
      " duration                    | 0        \n",
      " protocol_type               | tcp      \n",
      " service                     | ftp_data \n",
      " flag                        | SF       \n",
      " dst_bytes                   | 0        \n",
      " land                        | 0        \n",
      " wrong_fragment              | 0        \n",
      " urgent                      | 0        \n",
      " hot                         | 0        \n",
      " num_failed_logins           | 0        \n",
      " logged_in                   | 0        \n",
      " num_compromised             | 0        \n",
      " root_shell                  | 0        \n",
      " su_attempted                | 0        \n",
      " num_root                    | 0        \n",
      " num_file_creations          | 0        \n",
      " num_shells                  | 0        \n",
      " num_access_files            | 0        \n",
      " num_outbound_cmds           | 0        \n",
      " is_host_login               | 0        \n",
      " is_guest_login              | 0        \n",
      " count                       | 2        \n",
      " srv_count                   | 2        \n",
      " serror_rate                 | 0.0      \n",
      " srv_serror_rate             | 0.0      \n",
      " rerror_rate                 | 0.0      \n",
      " srv_rerror_rate             | 0.0      \n",
      " same_srv_rate               | 1.0      \n",
      " diff_srv_rate               | 0.0      \n",
      " srv_diff_host_rate          | 0.0      \n",
      " dst_host_count              | 150      \n",
      " dst_host_srv_count          | 25       \n",
      " dst_host_same_srv_rate      | 0.17     \n",
      " dst_host_diff_srv_rate      | 0.03     \n",
      " dst_host_same_src_port_rate | 0.17     \n",
      " dst_host_srv_diff_host_rate | 0.0      \n",
      " dst_host_serror_rate        | 0.0      \n",
      " dst_host_srv_serror_rate    | 0.0      \n",
      " dst_host_rerror_rate        | 0.05     \n",
      " dst_host_srv_rerror_rate    | 0.0      \n",
      " classes                     | normal   \n",
      " difficulty_level            | 20       \n",
      " src_bytes                   | 491      \n",
      " total_outliers              | 0        \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_with_outlier_handling = find_outliers(df_fully_imputed)\n",
    "df_with_outlier_handling.show(1, vertical=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "<p style=\"page-break-after:always;\"></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 72:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|total_outliers|count|\n",
      "+--------------+-----+\n",
      "|             1|41051|\n",
      "|             6|  247|\n",
      "|             3| 2637|\n",
      "|             5| 1342|\n",
      "|             9|    9|\n",
      "|             4|  452|\n",
      "|             8|   55|\n",
      "|             7|   39|\n",
      "|            10|    4|\n",
      "|            11|    1|\n",
      "|             2| 6915|\n",
      "|             0|73221|\n",
      "+--------------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_with_outlier_handling.groupby(\"total_outliers\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We don't want to lose lots of records for outliers. We will drop the rows with more than 4 outliers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124276\n"
     ]
    }
   ],
   "source": [
    "df_with_substituted_na_and_outliers = df_with_outlier_handling.\\\n",
    "        filter(df_with_outlier_handling['total_Outliers']<=4)\n",
    "print(df_with_substituted_na_and_outliers.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2>4. Variable Distribution</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<ul>\n",
    "<li>The distribution of a variable tells us what values it takes and how often it takes these\n",
    "values.</li>\n",
    "    <li>In any graph of data, look for the overall pattern and for striking deviations from that\n",
    "pattern.</li>\n",
    "    <li>Overall pattern of a distribution can be described by its shape centre and spread</li>\n",
    "    <li>An important kind of deviation is <b>an outlier</b> an individual value that falls outside the\n",
    "overall pattern.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Try to answer the following questions when looking at the distribution.\n",
    "<ul>\n",
    "<li>Does the distribution have one or several major peaks, usually called modes A\n",
    "    distribution with one major peak is called unimodal</li>\n",
    "    <li>Is it approximately symmetric or skewed in one direction?</li>\n",
    "</ul>\n",
    "\n",
    "We can use <b>Seaborn</b> to visualize the variable distribution along with its <b>correlation</b> with other variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spotted_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msb\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m sb\u001b[38;5;241m.\u001b[39mpairplot(\u001b[43mspotted_data\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'spotted_data' is not defined"
     ]
    }
   ],
   "source": [
    "import seaborn as sb\n",
    "\n",
    "sb.pairplot(spotted_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<ul>\n",
    "    <li>Distributions show visual correlation of variables and we identified two possible columns to be dropped. Let's take a look at the correlation between all the variables and find the variables with strong correlation.</li>\n",
    "    <li><b>Strong correlation</b> is identified with <b>>= 0.8 correlation coefficient.</b> </li>\n",
    "    <li><b>In order for correlation to work, null values should be handled. </b></li>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "<p style=\"page-break-after:always;\"></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2>5. Correlations</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Correlation means a mutual relationship between two or more things. Consider data points (xᵢ , yᵢ), i = 1,2,…n in a dataset. <b>The objective of correlation</b> is to see if large values of “x” are paired with large values of “y” and small values of “x” are paired with small values of “y”. If not, check if small values of “x” are paired with large values of “y” and vice versa.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In general, it is recommended to avoid having correlated features in your dataset. Indeed, a group of highly correlated features will not bring additional information (or just very few), but will increase the complexity of the algorithm, thus increasing the risk of errors. Depending on the features and the model, correlated features might not always harm the performance of the model but that is a real risk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3>Why would you drop highly correlated features?</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In feature engineering, we remove highly correlated features for <b>storage and speed concerns.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3>Now that we handled null values, we can calculate the correlation using the <b>corr()</b> function in Pandas dataframe. PySpark has built-in correlation support as well using the Correlation class. However, it doesn't print the values as nicely as corr() function. So, for academic purposes, we will use the corr() function.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'tcp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m correlation_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mdf_with_substituted_na_and_outliers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoPandas\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(correlation_matrix)\n",
      "File \u001b[0;32m~/anaconda3/envs/systems_and_toolchains/lib/python3.12/site-packages/pandas/core/frame.py:11049\u001b[0m, in \u001b[0;36mDataFrame.corr\u001b[0;34m(self, method, min_periods, numeric_only)\u001b[0m\n\u001b[1;32m  11047\u001b[0m cols \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m  11048\u001b[0m idx \u001b[38;5;241m=\u001b[39m cols\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m> 11049\u001b[0m mat \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m  11051\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpearson\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m  11052\u001b[0m     correl \u001b[38;5;241m=\u001b[39m libalgos\u001b[38;5;241m.\u001b[39mnancorr(mat, minp\u001b[38;5;241m=\u001b[39mmin_periods)\n",
      "File \u001b[0;32m~/anaconda3/envs/systems_and_toolchains/lib/python3.12/site-packages/pandas/core/frame.py:1993\u001b[0m, in \u001b[0;36mDataFrame.to_numpy\u001b[0;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[1;32m   1991\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1992\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(dtype)\n\u001b[0;32m-> 1993\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1994\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dtype:\n\u001b[1;32m   1995\u001b[0m     result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(result, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[0;32m~/anaconda3/envs/systems_and_toolchains/lib/python3.12/site-packages/pandas/core/internals/managers.py:1694\u001b[0m, in \u001b[0;36mBlockManager.as_array\u001b[0;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[1;32m   1692\u001b[0m         arr\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1693\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1694\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interleave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1695\u001b[0m     \u001b[38;5;66;03m# The underlying data was copied within _interleave, so no need\u001b[39;00m\n\u001b[1;32m   1696\u001b[0m     \u001b[38;5;66;03m# to further copy if copy=True or setting na_value\u001b[39;00m\n\u001b[1;32m   1698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_value \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n",
      "File \u001b[0;32m~/anaconda3/envs/systems_and_toolchains/lib/python3.12/site-packages/pandas/core/internals/managers.py:1753\u001b[0m, in \u001b[0;36mBlockManager._interleave\u001b[0;34m(self, dtype, na_value)\u001b[0m\n\u001b[1;32m   1751\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1752\u001b[0m         arr \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mget_values(dtype)\n\u001b[0;32m-> 1753\u001b[0m     \u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindexer\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m arr\n\u001b[1;32m   1754\u001b[0m     itemmask[rl\u001b[38;5;241m.\u001b[39mindexer] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1756\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m itemmask\u001b[38;5;241m.\u001b[39mall():\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'tcp'"
     ]
    }
   ],
   "source": [
    "correlation_matrix = df_with_substituted_na_and_outliers.toPandas().corr()\n",
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In the previous results, look for strong correlations among variables. Notice the following:\n",
    "<ul>Strong Correlations among:\n",
    "    <li>serror_rate</li>\n",
    "    <li>dst_host_serror_rate</li>\n",
    "    <li>srv_serror_rate</li>\n",
    "    <li>dst_host_srv_serror_rate</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Strong Correlations among:\n",
    "<ul>\n",
    "    <li>rerror_rate</li>\n",
    "    <li>srv_rerror_rate</li>\n",
    "    <li>dst_host_rerror_rate</li>\n",
    "    <li>dst_host_srv_rerror_rate</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3>So, we should keep one variable from each group</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df_with_handled_correlations = df_with_substituted_na_and_outliers\\\n",
    "                .drop(\"dst_host_serror_rate\",\"srv_serror_rate\",\"dst_host_srv_serror_rate\",\n",
    "                     \"srv_rerror_rate\",\"dst_host_rerror_rate\",\"dst_host_srv_rerror_rate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "At this point, you should have handled continuous variables. <b>Next, let's look at categorical variables: Binary, Nominal and Ordinal variables</b>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "<p style=\"page-break-after:always;\"></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2>6. Handle Binary Variables (by casting them)</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "If you have boolean variables (i.e. True/False variables), you should convert them to 0's and 1's. \n",
    "<ul>\n",
    "    <li>0 belongs to False and 1 reflects True values.</li> \n",
    "    <li>In this dataset,there are no False and True values. They are already converted to 0's and 1's (e.g. is_guest_login variable)</li>\n",
    "    <li>However, you will have the opportunity to cast binary variables in the homework.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3>Here is an example on how to handle binary variables</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------------------+\n",
      "|is_guest_login|is_guest_login_encoded|\n",
      "+--------------+----------------------+\n",
      "|             1|                     1|\n",
      "|             0|                     0|\n",
      "+--------------+----------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_with_handled_binary = (df_with_handled_correlations\n",
    "              .withColumn(\"is_guest_login_encoded\", \\\n",
    "                          df_with_handled_correlations[\"is_guest_login\"].cast(\"integer\")))\n",
    "df_with_handled_binary.select(\"is_guest_login\",\"is_guest_login_encoded\").distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Again, we don't need to handle binary variables in this example and therefore, we don't need is_guest_login_encoded column. So, I'll assign the df_with_handled_binary to its old value. You don't need this step in the HW."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# You don't need this if you are handling binary variables\n",
    "df_with_handled_binary = df_with_handled_correlations"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "<p style=\"page-break-after:always;\"></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2>7. Handling Ordinal and Nominal Variables</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Many machine learning algorithms cannot work with categorical data directly. The categories must be converted into numbers. This is required for both input and output variables that are categorical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Converting strings to numbers can be achieved using one of the following <b>options:</b>\n",
    "<ul>\n",
    "    <li>StringIndexer from pyspark.ml.feature. This option assigns a number to each level.  This may work for problems where there is a natural ordinal relationship between the categories, and in turn the integer values, such as labels for temperature 'cold', 'warm', and 'hot'. In StringIndexers, the most frequent value would get index 0, followed by the next most frequent and so on. However, there may be problems when there is no ordinal relationship and allowing the representation to lean on any such relationship might be damaging to learning to solve the problem. An example might be the labels 'dog' and 'cat'.<br/>\n",
    "\n",
    "In these cases, we would like to give the network more expressive power to learn a probability-like number for each possible label value. This can help in both making the problem easier for the network to model. When a one hot encoding is used for the output variable, it may offer a more nuanced set of predictions than a single label.\n",
    "</li>  \n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<ul>\n",
    "    <li>OneHotEncoder (for Spark >= 3.0) or OneHotEncoderEstimator (for Spark >= 2.3) from pyspark.ml.feature library. A one hot encoding allows the representation of categorical data to be more expressive. This option will create dummy variables for each category, thereby increasing the number of features we work with. In our selected dataset, the special teams play type and offensive information variables need to be encoded.</li>\n",
    "   </ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3>String Indexer vs. One-Hot Encoder</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "String Indexing assigns a unique integer value to each category. 0 is assigned to the most frequent category, 1 to the next most frequent value, and so on. We have to define the input column name that we want to index and the output column name in which we want the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "However, <b>String Indexers impose an order or rank on your data and therefore, they only fit ordinal variables.</b> To represent <b>nominal variables,</b> we should use <b>One-Hot encoders.</b> In Spark, encoding is done as series of tasks that are executed via <b>pipelines</b>."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "<p style=\"page-break-after:always;\"></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Data Processing Pipelines</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "It's popular to use several machine learning models together. Therefore, machine learning workflows could get complex and hard to maintain. Data processing pipelines can help reducing the complexity of the machine learning workflow by allowing the reuse of workflow components across several models. A pipeline is a linear sequence of data processing and transformation stages, where each stage can be either a data transformer (for data preparation and feature engineering) or a machine learning estimator (for model training). Pipelines are designed to make it easier to construct, evaluate, and deploy machine learning workflows. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2>Pipeline Components</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The main pipeline components are:\n",
    "    <ul>\n",
    "    <li>Transformers</li>\n",
    "    <li>Estimators</li>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2>Transformers</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<b>Transformers</b> typically refer to components or stages in a machine learning pipeline that are used to transform and preprocess data. These transformers are part of the Spark ML library and they are used to perform various operations on data. These operations include feature extraction, transformation, and scaling, before feeding it into machine learning algorithms. \n",
    "Technically, a Transformer implements a method transform(), which converts one DataFrame into another, generally by appending one or more columns.<br/>\n",
    "\n",
    "Examples of built-in transformers include: Tokenizer, StandardScaler, VectorAssembler, OneHotEncoder, and StringIndexer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can also create custom Transformers by subclassing the `Transformer` class (in `pyspark.ml`). The basic syntax for creating a transformer is\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Transformer\n",
    "\n",
    "class myCustomTransformer(Transformer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def _transform(self, input_df):\n",
    "        # do some processing steps here\n",
    "        return output_df\n",
    "    \n",
    "transformer1 =  myCustomTransformer()\n",
    "transformer2 =  myCustomTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "# You can use different types of transformers, estimatorabss as well.\n",
    "mypipeline = Pipeline(stages=[transformer1, transformer2])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "<p style=\"page-break-after:always;\"></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2>Estimators</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "An estimator is an algorithm or model-building tool that takes a dataset and returns a model. In other words, it's an abstraction of a learning algorithm.\n",
    "\n",
    "Examples of built-in estimators include\n",
    "<ul>\n",
    "    <li>LogisticRegression: An estimator used for binary classification.</li>\n",
    "<li>RandomForestClassifier: An estimator for classification tasks using random forests.</li>\n",
    "<li>LinearRegression: An estimator for linear regression tasks.</li>\n",
    "<li>KMeans: An estimator for clustering using the K-means algorithm.</li>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3>Estimator Components</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Estimators typically have two main methods: fit and transform.\n",
    "<ul>\n",
    "    <li>The <b>fit</b> method is used to train the estimator on a given dataset. It takes a DataFrame as input and returns a model.</li>\n",
    "    <li>The <b>transform</b> method is used to apply the trained model to new data, transforming the input data into predictions or other outputs.</li>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3>Let's take an example where we try to one-hot encode activity classes in our NSL-KDD dataset</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "\n",
    "# We don't have any ordinal variables. Only nominal variables\n",
    "# first part : transform the columns to numeric\n",
    "stage_1 = StringIndexer(inputCol= 'classes', outputCol= 'classes_index')\n",
    "stage_2 = StringIndexer(inputCol= 'protocol_type', outputCol= 'protocol_type_index')\n",
    "stage_3 = StringIndexer(inputCol= 'service', outputCol= 'service_index')\n",
    "stage_4 = StringIndexer(inputCol= 'flag', outputCol= 'flag_index')\n",
    "\n",
    "# second part : one-hot encode the numeric columns\n",
    "stage_5= OneHotEncoder(inputCols=[\"classes_index\",\"protocol_type_index\",\n",
    "                                  \"service_index\",\"flag_index\"], \n",
    "                        outputCols=['classes_encoded','protocol_type_encoded',\n",
    "                                   'service_encoded','flag_encoded'])\n",
    "\n",
    "# setup the pipeline\n",
    "pipeline = Pipeline(stages=[stage_1, stage_2, stage_3, stage_4, stage_5])\n",
    "\n",
    "# fit the pipeline model and transform the data as defined\n",
    "pipeline_model = pipeline.fit(df_with_handled_binary)\n",
    "df_encoded = pipeline_model.transform(df_with_handled_binary)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "<p style=\"page-break-after:always;\"></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3>In order to view/read the output of One-Hot encoding, it's best to convert your mini-dataframe to Pandas</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classes</th>\n",
       "      <th>classes_index</th>\n",
       "      <th>classes_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>portsweep</td>\n",
       "      <td>4.0</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>buffer_overflow</td>\n",
       "      <td>14.0</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ipsweep</td>\n",
       "      <td>3.0</td>\n",
       "      <td>(0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>warezmaster</td>\n",
       "      <td>12.0</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>satan</td>\n",
       "      <td>2.0</td>\n",
       "      <td>(0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>imap</td>\n",
       "      <td>15.0</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>guess_passwd</td>\n",
       "      <td>11.0</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>loadmodule</td>\n",
       "      <td>16.0</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>nmap</td>\n",
       "      <td>6.0</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>back</td>\n",
       "      <td>9.0</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>spy</td>\n",
       "      <td>20.0</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ftp_write</td>\n",
       "      <td>18.0</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>pod</td>\n",
       "      <td>10.0</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>neptune</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>warezclient</td>\n",
       "      <td>8.0</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>multihop</td>\n",
       "      <td>19.0</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>normal</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>rootkit</td>\n",
       "      <td>17.0</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>land</td>\n",
       "      <td>13.0</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>smurf</td>\n",
       "      <td>5.0</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>teardrop</td>\n",
       "      <td>7.0</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            classes  classes_index  \\\n",
       "0         portsweep            4.0   \n",
       "1   buffer_overflow           14.0   \n",
       "2           ipsweep            3.0   \n",
       "3       warezmaster           12.0   \n",
       "4             satan            2.0   \n",
       "5              imap           15.0   \n",
       "6      guess_passwd           11.0   \n",
       "7        loadmodule           16.0   \n",
       "8              nmap            6.0   \n",
       "9              back            9.0   \n",
       "10              spy           20.0   \n",
       "11        ftp_write           18.0   \n",
       "12              pod           10.0   \n",
       "13          neptune            1.0   \n",
       "14      warezclient            8.0   \n",
       "15         multihop           19.0   \n",
       "16           normal            0.0   \n",
       "17          rootkit           17.0   \n",
       "18             land           13.0   \n",
       "19            smurf            5.0   \n",
       "20         teardrop            7.0   \n",
       "\n",
       "                                      classes_encoded  \n",
       "0   (0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1   (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "2   (0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "3   (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "4   (0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "5   (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "6   (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "7   (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "8   (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...  \n",
       "9   (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "10  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "11  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "12  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "13  (0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "14  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...  \n",
       "15  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "16  (1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "17  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "18  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "19  (0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...  \n",
       "20  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Notice, the length of our One-Hot Encoding array\n",
    "print(df_encoded.select(\"classes\").distinct().count())\n",
    "# In our NSL-KDD dataset, the length is 3. Now, let's view some examples\n",
    "df_encoded.select(\"classes\",\"classes_index\",\"classes_encoded\")\\\n",
    "                .distinct().toPandas()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Read more about One-Hot Encoding and String Indexing from this article: <a href=\"https://medium.com/@nutanbhogendrasharma/role-of-onehotencoder-and-pipelines-in-pyspark-ml-feature-part-2-3275767e74f0\">https://medium.com/@nutanbhogendrasharma/role-of-onehotencoder-and-pipelines-in-pyspark-ml-feature-part-2-3275767e74f0</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2>8. Combining Features into Single Vector</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Typically, machine learning models accept the ML input as a vector of features. So, to combine your features into a single vector in Spark, you may use VectorAssembler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['duration', 'dst_bytes', 'land', 'wrong_fragment', 'urgent', 'hot', 'num_failed_logins', 'logged_in', 'num_compromised', 'root_shell', 'su_attempted', 'num_root', 'num_file_creations', 'num_shells', 'num_access_files', 'num_outbound_cmds', 'is_host_login', 'is_guest_login', 'count', 'srv_count', 'serror_rate', 'rerror_rate', 'same_srv_rate', 'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count', 'dst_host_same_srv_rate', 'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate', 'difficulty_level', 'src_bytes', 'total_outliers', 'classes_encoded', 'protocol_type_encoded', 'service_encoded', 'flag_encoded']\n"
     ]
    }
   ],
   "source": [
    "feature_list = df_encoded.drop(\"classes\",\"classes_index\",\n",
    "                                        \"protocol_type\",\"protocol_type_index\",\n",
    "                                        \"service\",\"service_index\",\n",
    "                                        \"flag\",\"flag_index\").columns\n",
    "print(feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "\n",
    "vector_assembler = VectorAssembler(\n",
    "    inputCols=feature_list, \n",
    "    outputCol=\"vectorized_features\")\n",
    "\n",
    "df_with_assembled_features = vector_assembler.transform(df_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------------------------------------------------+\n",
      "|vectorized_features                                                                                                  |\n",
      "+---------------------------------------------------------------------------------------------------------------------+\n",
      "|(135,[18,19,22,25,26,27,28,29,31,32,34,54,60,125],[2.0,2.0,1.0,150.0,25.0,0.17,0.03,0.17,20.0,491.0,1.0,1.0,1.0,1.0])|\n",
      "+---------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_with_assembled_features.select(\"vectorized_features\").show(1, truncate=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "<p style=\"page-break-after:always;\"></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3>Important Note: Your Machine Learning Target/Outcome Variable MUST NOT be in the Feature List that is Assembled</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Let's take an example if we are trying to predict the activity/attack classes. \n",
    "# In this case, classes should not be in the feature list.\n",
    "# Notice we are dropping classes_encoded variable here\n",
    "feature_list = df_encoded.drop(\"classes\",\"classes_index\",\n",
    "                                        \"protocol_type\",\"protocol_type_index\",\n",
    "                                        \"service\",\"service_index\",\n",
    "                                        \"flag\",\"flag_index\",\n",
    "                              \"classes_encoded\").columns\n",
    "\n",
    "vector_assembler = VectorAssembler(\n",
    "    inputCols=feature_list, \n",
    "    outputCol=\"vectorized_features\")\n",
    "\n",
    "df_with_assembled_features = vector_assembler.transform(df_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vectorized_features</th>\n",
       "      <th>classes_encoded</th>\n",
       "      <th>classes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>neptune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(0.0, 147.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>(1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(0.0, 2313.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0....</td>\n",
       "      <td>(1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>neptune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(0.0, 357.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0...</td>\n",
       "      <td>(1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122981</th>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...</td>\n",
       "      <td>nmap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122982</th>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>neptune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122983</th>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...</td>\n",
       "      <td>nmap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122984</th>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>neptune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122985</th>\n",
       "      <td>(0.0, 8435.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0....</td>\n",
       "      <td>(1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>122986 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      vectorized_features  \\\n",
       "0       (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1       (0.0, 147.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...   \n",
       "2       (0.0, 2313.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0....   \n",
       "3       (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4       (0.0, 357.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0...   \n",
       "...                                                   ...   \n",
       "122981  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "122982  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "122983  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "122984  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "122985  (0.0, 8435.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0....   \n",
       "\n",
       "                                          classes_encoded  classes  \n",
       "0       (0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  neptune  \n",
       "1       (1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   normal  \n",
       "2       (1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   normal  \n",
       "3       (0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  neptune  \n",
       "4       (1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   normal  \n",
       "...                                                   ...      ...  \n",
       "122981  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...     nmap  \n",
       "122982  (0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  neptune  \n",
       "122983  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...     nmap  \n",
       "122984  (0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  neptune  \n",
       "122985  (1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   normal  \n",
       "\n",
       "[122986 rows x 3 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_assembled_features.select(\"vectorized_features\",\"classes_encoded\",\"classes\")\\\n",
    "    .distinct().toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now that we are done with assembling all the features, <b>let's scale them so they all have standard domains and no feature will have significantly higher impact than another one before we develop our machine learning model.</b>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "<p style=\"page-break-after:always;\"></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2>9. Data Scaling</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In most cases, the numerical features of the dataset do not have a certain range and they differ from each other. In order for a symmetric dataset, scaling is required.\n",
    "\n",
    "<h4>Normalization</h4>\n",
    "Normalization (or min-max normalization) scales all values in a fixed range between 0 and 1. This transformation does not change the distribution of the feature and due to the decreased standard deviations, the effects of the outliers increases. Therefore, before normalization, it is recommended to handle the outliers\n",
    "<h4>Standardization</h4>\n",
    "Standardization (or z-score normalization) scales the values while taking into account standard deviation. If the standard deviation of features is different, their range also would differ from each other. This reduces the effect of the outliers in the features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><figure><img width=\"300\" height=\"120\" src=\"http://stat.cmu.edu/~mfarag/652/lectures/l22/scaling.png\"/><figcaption>Scaling Formulas</figcaption></figure></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In this class, we will focus on standard scalers. StandardScalers standardize features by removing the mean and scaling to unit variance using column summary statistics on the samples in the training set.\n",
    "\n",
    "The “unit std” is computed using the corrected sample standard deviation, which is computed as the square root of the unbiased sample variance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "<p style=\"page-break-after:always;\"></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3>To scale data to predict Activity/Attack Classes</h3>\n",
    "The code is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classes</th>\n",
       "      <th>classes_encoded</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neptune</td>\n",
       "      <td>(0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ipsweep</td>\n",
       "      <td>(0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neptune</td>\n",
       "      <td>(0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nmap</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neptune</td>\n",
       "      <td>(0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122981</th>\n",
       "      <td>normal</td>\n",
       "      <td>(1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 8.299159495710271e-05, 0.0, 0.0, 0.0, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122982</th>\n",
       "      <td>teardrop</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 11.753590125868877, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122983</th>\n",
       "      <td>normal</td>\n",
       "      <td>(1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.05262337...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122984</th>\n",
       "      <td>neptune</td>\n",
       "      <td>(0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122985</th>\n",
       "      <td>smurf</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>122986 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         classes                                    classes_encoded  \\\n",
       "0        neptune  (0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1        ipsweep  (0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2        neptune  (0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3           nmap  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...   \n",
       "4        neptune  (0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "...          ...                                                ...   \n",
       "122981    normal  (1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "122982  teardrop  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...   \n",
       "122983    normal  (1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "122984   neptune  (0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "122985     smurf  (0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                                 features  \n",
       "0       (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1       (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "2       (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "3       (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "4       (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "...                                                   ...  \n",
       "122981  (0.0, 8.299159495710271e-05, 0.0, 0.0, 0.0, 0....  \n",
       "122982  (0.0, 0.0, 0.0, 11.753590125868877, 0.0, 0.0, ...  \n",
       "122983  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.05262337...  \n",
       "122984  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "122985  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "\n",
       "[122986 rows x 3 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.feature import StandardScaler\n",
    "standard_scaler = StandardScaler(inputCol= 'vectorized_features', outputCol= 'features')\n",
    "scaled_model = standard_scaler.fit(df_with_assembled_features)\n",
    "df_with_scaled_features = scaled_model.transform(df_with_assembled_features)\n",
    "\n",
    "df_with_scaled_features.select(\"classes\",\"classes_encoded\",\"features\").distinct().toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3>And at this point, your data should be ready for your ML model.</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2>Summary of Data Engineering</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    " <ul>\n",
    "    <li>1. Data Ingestion</li>\n",
    "    <li>2. Data Cleaning. This includes handling missing values (via dropping or imputation), renaming columns and casting column data types.</li>\n",
    "    <li>3. Variable Classification</li>\n",
    "        <li>4. For continuous variables, \n",
    "            <ul>\n",
    "                <li>use boxplots to identify if outliers exist and handle outliers.</li>\n",
    "                <li>use variable distributions and handle high correlations</li>\n",
    "            </ul>\n",
    "        <li>5. For Binary variables, cast them from boolean to integer data types - if needed-</li>\n",
    "        <li>6. For ordinal variables, encode them using StringIndexers</li>\n",
    "        <li>7. For nominal variables, encode them using One-Hot Encoding</li>\n",
    "        <li>8. Assemble your input features as into single vector</li>\n",
    "        <li>9. Scale your feature vector</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Reading</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<ul>\n",
    "    <li>Types of Missing Values: <a href=\"https://stefvanbuuren.name/fimd/sec-MCAR.html\">https://stefvanbuuren.name/fimd/sec-MCAR.html<a/></li>\n",
    "<li>Read more about One-Hot Encoding and String Indexing from this article: <a href=\"https://stefvanbuuren.name/fimd/sec-MCAR.html\">https://medium.com/@nutanbhogendrasharma/role-of-onehotencoder-and-pipelines-in-pyspark-ml-feature-part-2-3275767e74f0</a></li>\n",
    "</ul>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
