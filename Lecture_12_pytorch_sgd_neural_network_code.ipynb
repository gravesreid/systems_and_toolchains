{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><center> PyTorch: Stochastic Gradient Descent and Neural Networks </center> </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch  # now import the tensorflow module\n",
    "from torch import nn\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Create Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[0.]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "class MyLinearRegressionModel(nn.Module): \n",
    "    def __init__(self,d): # d is the dimension of the input\n",
    "        super(MyLinearRegressionModel,self).__init__()   # call the init function of super class\n",
    "        # we usually create variables for all our model parameters (w and b in our case) in __init__ and give them initial values. \n",
    "        # need to create them as nn.Parameter so that the model knows it is an parameter that needs to be trained\n",
    "        self.w = nn.Parameter(torch.zeros(1,d, dtype=torch.float)) \n",
    "        self.b = nn.Parameter(torch.zeros(1,dtype=torch.float))\n",
    "    def forward(self,x):\n",
    "        # The main purpose of the forward function is to specify given input x, how the output is calculated. \n",
    "        return torch.inner(x,self.w) + self.b\n",
    "    \n",
    "# Let's check out our model \n",
    "\n",
    "mymodel = MyLinearRegressionModel(1) # creating a model instance with input dimension 1\n",
    "print(mymodel.w)\n",
    "print(mymodel.b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Creating Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The torch Dataset is similar to tf.data.Dataset. The general way to create a dataset is through subclassing the Dataset class and define the `__len__()` and `__getitem__()` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "x = torch.arange(0,10,.1,dtype=torch.float) \n",
    "x = x[:,None]\n",
    "y = x*3+torch.randn(x.shape)\n",
    "\n",
    "# Example of dataset \n",
    "class MyDataset(Dataset): \n",
    "    def __init__(self,x,y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.x.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.x[idx],self.y[idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([0.]), tensor([-2.4001]))\n",
      "(tensor([0.1000]), tensor([1.1807]))\n",
      "(tensor([0.2000]), tensor([1.6287]))\n",
      "(tensor([0.3000]), tensor([0.3131]))\n",
      "(tensor([0.4000]), tensor([0.9996]))\n",
      "(tensor([0.5000]), tensor([1.0470]))\n",
      "(tensor([0.6000]), tensor([1.6486]))\n",
      "(tensor([0.7000]), tensor([2.6891]))\n",
      "(tensor([0.8000]), tensor([2.4025]))\n",
      "(tensor([0.9000]), tensor([3.7481]))\n",
      "(tensor([1.]), tensor([4.6804]))\n",
      "(tensor([1.1000]), tensor([3.8141]))\n",
      "(tensor([1.2000]), tensor([4.1419]))\n",
      "(tensor([1.3000]), tensor([4.0506]))\n",
      "(tensor([1.4000]), tensor([3.3797]))\n",
      "(tensor([1.5000]), tensor([2.7713]))\n",
      "(tensor([1.6000]), tensor([4.4830]))\n",
      "(tensor([1.7000]), tensor([4.2594]))\n",
      "(tensor([1.8000]), tensor([5.8098]))\n",
      "(tensor([1.9000]), tensor([5.1898]))\n",
      "(tensor([2.]), tensor([6.6558]))\n",
      "(tensor([2.1000]), tensor([4.3551]))\n",
      "(tensor([2.2000]), tensor([7.8975]))\n",
      "(tensor([2.3000]), tensor([7.5955]))\n",
      "(tensor([2.4000]), tensor([8.2080]))\n",
      "(tensor([2.5000]), tensor([6.8814]))\n",
      "(tensor([2.6000]), tensor([8.6287]))\n",
      "(tensor([2.7000]), tensor([8.0063]))\n",
      "(tensor([2.8000]), tensor([8.7161]))\n",
      "(tensor([2.9000]), tensor([7.7645]))\n",
      "(tensor([3.]), tensor([9.3330]))\n",
      "(tensor([3.1000]), tensor([10.7470]))\n",
      "(tensor([3.2000]), tensor([9.5420]))\n",
      "(tensor([3.3000]), tensor([9.1326]))\n",
      "(tensor([3.4000]), tensor([9.4267]))\n",
      "(tensor([3.5000]), tensor([10.0321]))\n",
      "(tensor([3.6000]), tensor([11.3917]))\n",
      "(tensor([3.7000]), tensor([9.8070]))\n",
      "(tensor([3.8000]), tensor([10.2598]))\n",
      "(tensor([3.9000]), tensor([12.8626]))\n",
      "(tensor([4.]), tensor([13.1315]))\n",
      "(tensor([4.1000]), tensor([11.6676]))\n",
      "(tensor([4.2000]), tensor([12.6749]))\n",
      "(tensor([4.3000]), tensor([12.2581]))\n",
      "(tensor([4.4000]), tensor([13.6171]))\n",
      "(tensor([4.5000]), tensor([12.5292]))\n",
      "(tensor([4.6000]), tensor([14.0246]))\n",
      "(tensor([4.7000]), tensor([14.3578]))\n",
      "(tensor([4.8000]), tensor([13.9888]))\n",
      "(tensor([4.9000]), tensor([15.0177]))\n",
      "(tensor([5.]), tensor([17.0547]))\n",
      "(tensor([5.1000]), tensor([16.4281]))\n",
      "(tensor([5.2000]), tensor([15.9286]))\n",
      "(tensor([5.3000]), tensor([16.2639]))\n",
      "(tensor([5.4000]), tensor([14.1842]))\n",
      "(tensor([5.5000]), tensor([16.2822]))\n",
      "(tensor([5.6000]), tensor([17.4190]))\n",
      "(tensor([5.7000]), tensor([16.2637]))\n",
      "(tensor([5.8000]), tensor([17.4205]))\n",
      "(tensor([5.9000]), tensor([16.5193]))\n",
      "(tensor([6.]), tensor([17.6467]))\n",
      "(tensor([6.1000]), tensor([18.8245]))\n",
      "(tensor([6.2000]), tensor([19.1748]))\n",
      "(tensor([6.3000]), tensor([19.5288]))\n",
      "(tensor([6.4000]), tensor([19.4343]))\n",
      "(tensor([6.5000]), tensor([20.1224]))\n",
      "(tensor([6.6000]), tensor([20.3981]))\n",
      "(tensor([6.7000]), tensor([20.3442]))\n",
      "(tensor([6.8000]), tensor([20.9928]))\n",
      "(tensor([6.9000]), tensor([19.6296]))\n",
      "(tensor([7.]), tensor([22.4450]))\n",
      "(tensor([7.1000]), tensor([23.3842]))\n",
      "(tensor([7.2000]), tensor([21.8675]))\n",
      "(tensor([7.3000]), tensor([20.6867]))\n",
      "(tensor([7.4000]), tensor([22.8636]))\n",
      "(tensor([7.5000]), tensor([22.3209]))\n",
      "(tensor([7.6000]), tensor([22.7212]))\n",
      "(tensor([7.7000]), tensor([21.9457]))\n",
      "(tensor([7.8000]), tensor([22.2663]))\n",
      "(tensor([7.9000]), tensor([22.1926]))\n",
      "(tensor([8.]), tensor([23.1714]))\n",
      "(tensor([8.1000]), tensor([22.6316]))\n",
      "(tensor([8.2000]), tensor([25.2092]))\n",
      "(tensor([8.3000]), tensor([25.8502]))\n",
      "(tensor([8.4000]), tensor([24.5456]))\n",
      "(tensor([8.5000]), tensor([26.4719]))\n",
      "(tensor([8.6000]), tensor([26.6413]))\n",
      "(tensor([8.7000]), tensor([26.2837]))\n",
      "(tensor([8.8000]), tensor([25.9100]))\n",
      "(tensor([8.9000]), tensor([27.4849]))\n",
      "(tensor([9.]), tensor([27.8019]))\n",
      "(tensor([9.1000]), tensor([28.6836]))\n",
      "(tensor([9.2000]), tensor([27.1535]))\n",
      "(tensor([9.3000]), tensor([26.8374]))\n",
      "(tensor([9.4000]), tensor([26.7467]))\n",
      "(tensor([9.5000]), tensor([29.3643]))\n",
      "(tensor([9.6000]), tensor([27.6855]))\n",
      "(tensor([9.7000]), tensor([28.1644]))\n",
      "(tensor([9.8000]), tensor([29.9913]))\n",
      "(tensor([9.9000]), tensor([30.1210]))\n"
     ]
    }
   ],
   "source": [
    "mydataset = MyDataset(x,y)\n",
    "for item in mydataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[3.6000],\n",
      "        [9.0000],\n",
      "        [1.9000],\n",
      "        [9.1000]]), tensor([[11.3917],\n",
      "        [27.8019],\n",
      "        [ 5.1898],\n",
      "        [28.6836]])]\n",
      "[tensor([[9.4000],\n",
      "        [4.4000],\n",
      "        [8.8000],\n",
      "        [1.3000]]), tensor([[26.7467],\n",
      "        [13.6171],\n",
      "        [25.9100],\n",
      "        [ 4.0506]])]\n",
      "[tensor([[2.4000],\n",
      "        [4.1000],\n",
      "        [1.4000],\n",
      "        [6.6000]]), tensor([[ 8.2080],\n",
      "        [11.6676],\n",
      "        [ 3.3797],\n",
      "        [20.3981]])]\n",
      "[tensor([[1.7000],\n",
      "        [7.5000],\n",
      "        [6.5000],\n",
      "        [2.0000]]), tensor([[ 4.2594],\n",
      "        [22.3209],\n",
      "        [20.1224],\n",
      "        [ 6.6558]])]\n",
      "[tensor([[9.5000],\n",
      "        [2.5000],\n",
      "        [2.1000],\n",
      "        [0.6000]]), tensor([[29.3643],\n",
      "        [ 6.8814],\n",
      "        [ 4.3551],\n",
      "        [ 1.6486]])]\n",
      "[tensor([[8.5000],\n",
      "        [3.5000],\n",
      "        [0.4000],\n",
      "        [2.6000]]), tensor([[26.4719],\n",
      "        [10.0321],\n",
      "        [ 0.9996],\n",
      "        [ 8.6287]])]\n",
      "[tensor([[5.3000],\n",
      "        [7.9000],\n",
      "        [8.2000],\n",
      "        [5.0000]]), tensor([[16.2639],\n",
      "        [22.1926],\n",
      "        [25.2092],\n",
      "        [17.0547]])]\n",
      "[tensor([[9.3000],\n",
      "        [9.9000],\n",
      "        [0.0000],\n",
      "        [4.5000]]), tensor([[26.8374],\n",
      "        [30.1210],\n",
      "        [-2.4001],\n",
      "        [12.5292]])]\n",
      "[tensor([[5.1000],\n",
      "        [1.1000],\n",
      "        [6.9000],\n",
      "        [4.7000]]), tensor([[16.4281],\n",
      "        [ 3.8141],\n",
      "        [19.6296],\n",
      "        [14.3578]])]\n",
      "[tensor([[4.6000],\n",
      "        [8.4000],\n",
      "        [7.3000],\n",
      "        [1.8000]]), tensor([[14.0246],\n",
      "        [24.5456],\n",
      "        [20.6867],\n",
      "        [ 5.8098]])]\n",
      "[tensor([[8.0000],\n",
      "        [9.6000],\n",
      "        [3.4000],\n",
      "        [6.4000]]), tensor([[23.1714],\n",
      "        [27.6855],\n",
      "        [ 9.4267],\n",
      "        [19.4343]])]\n",
      "[tensor([[7.2000],\n",
      "        [3.0000],\n",
      "        [3.9000],\n",
      "        [2.9000]]), tensor([[21.8675],\n",
      "        [ 9.3330],\n",
      "        [12.8626],\n",
      "        [ 7.7645]])]\n",
      "[tensor([[8.3000],\n",
      "        [7.6000],\n",
      "        [6.8000],\n",
      "        [5.9000]]), tensor([[25.8502],\n",
      "        [22.7212],\n",
      "        [20.9928],\n",
      "        [16.5193]])]\n",
      "[tensor([[4.2000],\n",
      "        [3.2000],\n",
      "        [3.8000],\n",
      "        [2.7000]]), tensor([[12.6749],\n",
      "        [ 9.5420],\n",
      "        [10.2598],\n",
      "        [ 8.0063]])]\n",
      "[tensor([[7.1000],\n",
      "        [6.0000],\n",
      "        [8.1000],\n",
      "        [5.4000]]), tensor([[23.3842],\n",
      "        [17.6467],\n",
      "        [22.6316],\n",
      "        [14.1842]])]\n",
      "[tensor([[1.2000],\n",
      "        [3.7000],\n",
      "        [2.8000],\n",
      "        [5.5000]]), tensor([[ 4.1419],\n",
      "        [ 9.8070],\n",
      "        [ 8.7161],\n",
      "        [16.2822]])]\n",
      "[tensor([[5.7000],\n",
      "        [8.9000],\n",
      "        [1.6000],\n",
      "        [5.2000]]), tensor([[16.2637],\n",
      "        [27.4849],\n",
      "        [ 4.4830],\n",
      "        [15.9286]])]\n",
      "[tensor([[7.4000],\n",
      "        [5.8000],\n",
      "        [6.3000],\n",
      "        [4.9000]]), tensor([[22.8636],\n",
      "        [17.4205],\n",
      "        [19.5288],\n",
      "        [15.0177]])]\n",
      "[tensor([[8.6000],\n",
      "        [6.2000],\n",
      "        [9.2000],\n",
      "        [3.1000]]), tensor([[26.6413],\n",
      "        [19.1748],\n",
      "        [27.1535],\n",
      "        [10.7470]])]\n",
      "[tensor([[4.0000],\n",
      "        [4.8000],\n",
      "        [0.2000],\n",
      "        [0.3000]]), tensor([[13.1315],\n",
      "        [13.9888],\n",
      "        [ 1.6287],\n",
      "        [ 0.3131]])]\n",
      "[tensor([[6.7000],\n",
      "        [7.0000],\n",
      "        [9.7000],\n",
      "        [2.2000]]), tensor([[20.3442],\n",
      "        [22.4450],\n",
      "        [28.1644],\n",
      "        [ 7.8975]])]\n",
      "[tensor([[4.3000],\n",
      "        [7.8000],\n",
      "        [1.5000],\n",
      "        [0.8000]]), tensor([[12.2581],\n",
      "        [22.2663],\n",
      "        [ 2.7713],\n",
      "        [ 2.4025]])]\n",
      "[tensor([[7.7000],\n",
      "        [0.9000],\n",
      "        [9.8000],\n",
      "        [6.1000]]), tensor([[21.9457],\n",
      "        [ 3.7481],\n",
      "        [29.9913],\n",
      "        [18.8245]])]\n",
      "[tensor([[0.7000],\n",
      "        [1.0000],\n",
      "        [0.1000],\n",
      "        [8.7000]]), tensor([[ 2.6891],\n",
      "        [ 4.6804],\n",
      "        [ 1.1807],\n",
      "        [26.2837]])]\n",
      "[tensor([[2.3000],\n",
      "        [3.3000],\n",
      "        [0.5000],\n",
      "        [5.6000]]), tensor([[ 7.5955],\n",
      "        [ 9.1326],\n",
      "        [ 1.0470],\n",
      "        [17.4190]])]\n"
     ]
    }
   ],
   "source": [
    "mydataloader = DataLoader(mydataset, batch_size = 4, shuffle = True)\n",
    "for item in mydataloader:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main difference between SGD and GD is that time, we use a batch of data of compute the gradient, as opposed to the full training dataset. \n",
    "\n",
    "Typically, the SGD is implemented as a nested for-loop, where the outer loop go through a number of epochs, where the inner loop go through all batches in the data set, and the batches can be obtained from the DataLoader. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2849636/279297630.py:71: MatplotlibDeprecationWarning: The tostring_rgb function was deprecated in Matplotlib 3.8 and will be removed in 3.10. Use buffer_rgba instead.\n",
      "  image = np.frombuffer(canvas.tostring_rgb(), dtype='uint8')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving GIF file\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import imageio\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "from matplotlib.figure import Figure\n",
    "\n",
    "mymodel = MyLinearRegressionModel(1) # creating a model instance with input dimension 1\n",
    "lr = 1e-3\n",
    "batch_size = 2\n",
    "\n",
    "optimizer = torch.optim.SGD(mymodel.parameters(), lr = lr) # this line creates a optimizer, and we tell optimizer we are optimizing the parameters in mymodel\n",
    "mydataloader = DataLoader(mydataset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "\n",
    "frames = []\n",
    "\n",
    "losses = []\n",
    "losses_all = []\n",
    "N_epochs = 6\n",
    "\n",
    "gd_steps = 0\n",
    "N_batches = len(mydataloader)\n",
    "for epoch in range(N_epochs):\n",
    "    batch_loss = []\n",
    "    for batch_id, (x_batch, y_batch) in enumerate(mydataloader):\n",
    "        gd_steps+=1\n",
    "        # pass input data to get the prediction outputs by the current model\n",
    "        prediction = mymodel(x_batch)\n",
    "\n",
    "        # compare prediction and the actual output and compute the loss\n",
    "        loss = torch.mean((prediction - y_batch)**2)\n",
    "\n",
    "        # compute the gradient\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        # Generate visualization plots\n",
    "        fig, ax = plt.subplots(nrows = 1, ncols = 3)\n",
    "        canvas = FigureCanvas(fig)\n",
    "        ax[0].plot(x,y,'ro')\n",
    "        prediction_full = mymodel(x)\n",
    "        ax[0].plot(x,prediction_full.detach(),linewidth = 2)\n",
    "        ax[0].legend(['data','prediction of mymodel'],loc = 'upper left')\n",
    "        ax[0].set_title(f\"Batch size = {batch_size}, Learning rate = {lr}, Epoch #{epoch}, Batch #{batch_id}\", fontsize = 20)\n",
    "        ax[0].set_xlim((0,10))\n",
    "        ax[0].set_ylim((0,30))\n",
    "        losses_all.append(loss.detach().numpy())\n",
    "        ax[1].plot(np.arange(gd_steps),np.array(losses_all).squeeze(),linewidth=2 )\n",
    "        ax[1].set_xlim((0,(N_epochs+1)*(N_batches)))\n",
    "        ax[1].set_ylim((0,30))\n",
    "        ax[1].set_title(\"Training loss\", fontsize = 20)\n",
    "        ax[1].set_xlabel(\"# of SGD Iterations\", fontsize = 20)\n",
    "\n",
    "        batch_loss.append(loss.detach().numpy())\n",
    "        if epoch>0:\n",
    "            ax[2].plot(np.arange(epoch),np.array(losses).squeeze(),linewidth=2 )\n",
    "        else:\n",
    "            ax[2].plot(np.arange(epoch+1),np.mean(np.array(batch_loss).squeeze()),linewidth=2 )\n",
    "        \n",
    "        ax[2].set_xlim((0,N_epochs-1))\n",
    "        ax[2].set_ylim((0,30))\n",
    "        ax[2].set_title(\"Training loss\", fontsize = 20)\n",
    "        ax[2].set_xlabel(\"# of Epochs\", fontsize = 20)\n",
    "\n",
    "        fig.set_size_inches(27,9) \n",
    "        canvas.draw()       # draw the canvas, cache the renderer\n",
    "\n",
    "        image = np.frombuffer(canvas.tostring_rgb(), dtype='uint8')\n",
    "\n",
    "        image = image.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "\n",
    "        frames.append(image)\n",
    "        plt.close(fig)\n",
    "    losses.append(np.mean(np.array(batch_loss)))\n",
    "\n",
    "print(\"Saving GIF file\")\n",
    "with imageio.get_writer(\"SGD.gif\", mode=\"I\") as writer:\n",
    "    for frame in frames:\n",
    "        writer.append_data(frame)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Simple Neural Nework with PyTorch\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Equivalent Way to Build Linear Regression Model with Built-in Layers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our previous linear model, we declared all the parameters (`w` and `b`) in the model and manually coded all the mathematical operations. \n",
    "\n",
    "PyTorch provides many built-in layers such that you don't need to do the above yourself. For linear regression, you can just use `nn.Linear(input_dim, output_dim)` to create a linear function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "\n",
    "\n",
    "class MyLinearRegressionModel_withBuiltinLayers(nn.Module): \n",
    "    def __init__(self,d): \n",
    "        super(MyLinearRegressionModel_withBuiltinLayers,self).__init__()  \n",
    "        self.linear_layer = nn.Linear(d,1) # define a linear layer and store it as an attribute\n",
    "    def forward(self,x):\n",
    "        return self.linear_layer(x) # use the linear layer to give the output\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can print a model instance, which will show what are the layers inside. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyLinearRegressionModel_withBuiltinLayers(\n",
      "  (linear_layer): Linear(in_features=1, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "mymodel_lr = MyLinearRegressionModel_withBuiltinLayers(1)\n",
    "\n",
    "print(mymodel_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also show all the parameters within the `linear_layer`. It has a `weight` parameter and `bias` parameter, which is the same as the `w` and the `b` parameter we defined before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear_layer.weight tensor([[-0.3158]])\n",
      "linear_layer.bias tensor([-0.4169])\n"
     ]
    }
   ],
   "source": [
    "for name,param in mymodel_lr.state_dict().items():\n",
    "    print(name, param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Build Neural Network Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the built-in layers, it is now convenient to create a neural network, which is a connection of linear layers with nonlinear activation functions. To create neural networks in PyTorch, we need to ''connect'' ``nn.Linear()`` and nonlinear activation functions (``nn.ReLU()`` if using ReLU as activation) together. We can do this conveniently using the ``nn.Sequential()``. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "myMultiLayerPerceptron(\n",
      "  (sequential): Sequential(\n",
      "    (0): Linear(in_features=1, out_features=20, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=20, out_features=20, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=20, out_features=20, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=20, out_features=20, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=20, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "# Example: using Sequential in Pytorch\n",
    "\n",
    "class myMultiLayerPerceptron(nn.Module):\n",
    "    def __init__(self,input_dim,output_dim):\n",
    "        super().__init__()\n",
    "        self.sequential = nn.Sequential(  # here we stack multiple layers together\n",
    "            nn.Linear(input_dim,20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20,20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20,20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20,20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20,output_dim)\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        y = self.sequential(x)\n",
    "        return y\n",
    "    \n",
    "# Let's check out our model \n",
    "\n",
    "mymodel = myMultiLayerPerceptron(1,1) # creating a model instance with input dimension 1 and output dimension 1\n",
    "\n",
    "print(mymodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequential.0.weight tensor([[-0.3262],\n",
      "        [-0.5736],\n",
      "        [ 0.4825],\n",
      "        [ 0.5747],\n",
      "        [ 0.1424],\n",
      "        [ 0.4363],\n",
      "        [-0.1051],\n",
      "        [ 0.0578],\n",
      "        [ 0.2398],\n",
      "        [-0.6316],\n",
      "        [ 0.3802],\n",
      "        [-0.6331],\n",
      "        [-0.0120],\n",
      "        [-0.2262],\n",
      "        [ 0.7034],\n",
      "        [ 0.7774],\n",
      "        [ 0.6515],\n",
      "        [ 0.2252],\n",
      "        [-0.9417],\n",
      "        [-0.9179]])\n",
      "sequential.0.bias tensor([ 0.3145,  0.0064, -0.5481, -0.8626, -0.3112, -0.4158, -0.9600,  0.0123,\n",
      "         0.3446,  0.8307, -0.8500, -0.8668, -0.8996,  0.4065, -0.1638,  0.5884,\n",
      "         0.0063,  0.3406,  0.4253,  0.5690])\n",
      "sequential.2.weight tensor([[-0.0441,  0.0530,  0.1801,  0.1953,  0.1557,  0.2094, -0.1536,  0.0892,\n",
      "          0.1098, -0.1314, -0.1362, -0.1670,  0.1380, -0.1560,  0.1190, -0.2234,\n",
      "         -0.1462, -0.0713, -0.0212,  0.1814],\n",
      "        [-0.1853,  0.1756, -0.0481,  0.2119,  0.1818, -0.1372,  0.0034,  0.1173,\n",
      "          0.0291, -0.1928,  0.1514, -0.0070, -0.0544,  0.2168,  0.1509, -0.0777,\n",
      "         -0.0006, -0.1660, -0.0428,  0.0171],\n",
      "        [-0.1068, -0.1705,  0.0726, -0.0816,  0.1078, -0.0044,  0.1558, -0.1845,\n",
      "          0.2206,  0.0943, -0.1118, -0.1590,  0.0824, -0.1237, -0.0596, -0.1472,\n",
      "         -0.1668, -0.0482,  0.2142, -0.0535],\n",
      "        [ 0.0194, -0.1894, -0.0453, -0.1629,  0.1941, -0.2019,  0.0097,  0.1507,\n",
      "         -0.0148,  0.1483, -0.0694,  0.0625, -0.1716, -0.1383,  0.2137, -0.0645,\n",
      "          0.1839,  0.0508, -0.1895, -0.0097],\n",
      "        [-0.0896, -0.1022, -0.0972, -0.2144,  0.0721, -0.0414, -0.2088, -0.1540,\n",
      "         -0.2153,  0.0525,  0.0537,  0.1571,  0.0776,  0.0341, -0.1590,  0.2027,\n",
      "         -0.0750, -0.1890, -0.0432, -0.0148],\n",
      "        [-0.0971, -0.1772, -0.0690, -0.0347,  0.1750,  0.2123,  0.0962, -0.1797,\n",
      "         -0.2101,  0.0012, -0.0758,  0.1722,  0.1167,  0.1261,  0.0875,  0.0538,\n",
      "         -0.1205,  0.1931,  0.0012, -0.0029],\n",
      "        [ 0.0571, -0.1739, -0.1005,  0.1034, -0.1991,  0.1404, -0.1800,  0.1406,\n",
      "         -0.1208, -0.0186,  0.0926, -0.1050, -0.2012,  0.1732, -0.2150,  0.0470,\n",
      "          0.2142,  0.0538,  0.1148, -0.0972],\n",
      "        [ 0.1156, -0.0070,  0.0570, -0.0102, -0.1384,  0.2142, -0.2092,  0.1864,\n",
      "         -0.0861, -0.1949, -0.1268, -0.2113, -0.0439, -0.1061,  0.2207, -0.1419,\n",
      "         -0.0907, -0.1223, -0.2097, -0.2036],\n",
      "        [ 0.2210, -0.0858, -0.1173, -0.1275, -0.0571, -0.1673,  0.1781,  0.0085,\n",
      "         -0.1377, -0.1245,  0.0306, -0.0205,  0.1636, -0.1502,  0.1505, -0.1995,\n",
      "         -0.0616, -0.0552, -0.0149,  0.1216],\n",
      "        [-0.0230, -0.2141,  0.1961,  0.1308, -0.1790, -0.1559, -0.0793, -0.0875,\n",
      "          0.1787,  0.2178,  0.2159, -0.2047, -0.1180, -0.2095,  0.0240,  0.2192,\n",
      "         -0.1757,  0.2153,  0.1650,  0.0385],\n",
      "        [ 0.0539,  0.1659, -0.0418, -0.1925,  0.1798, -0.0875, -0.0432,  0.1429,\n",
      "          0.0981,  0.0663,  0.0635, -0.1891,  0.0297,  0.0206, -0.1071,  0.1757,\n",
      "          0.2204, -0.1053,  0.0743,  0.0248],\n",
      "        [-0.0783, -0.1279,  0.1658,  0.1361, -0.0766, -0.1233,  0.1832,  0.0550,\n",
      "         -0.2125, -0.0425,  0.2166,  0.0167,  0.2153,  0.1471, -0.1803, -0.1048,\n",
      "         -0.0019,  0.0597, -0.1392, -0.0052],\n",
      "        [ 0.0583, -0.2097,  0.0868,  0.1848,  0.1128,  0.1763,  0.1894,  0.0330,\n",
      "         -0.1281,  0.0264, -0.0624,  0.0188, -0.2050,  0.2182,  0.0210, -0.1183,\n",
      "         -0.1147, -0.2083,  0.0685, -0.0294],\n",
      "        [-0.1639,  0.1761,  0.1361,  0.0365,  0.0570, -0.0420,  0.0483,  0.0975,\n",
      "          0.1304,  0.1988, -0.1917, -0.1595,  0.1107, -0.0550, -0.0640, -0.0052,\n",
      "         -0.0598,  0.1312,  0.1363, -0.0881],\n",
      "        [-0.0774, -0.0094, -0.1544, -0.1626,  0.0067, -0.0281,  0.0491, -0.1171,\n",
      "          0.1660,  0.1661,  0.0379, -0.0541, -0.2175, -0.1375, -0.1171,  0.0109,\n",
      "         -0.0940, -0.0657, -0.0007,  0.0601],\n",
      "        [ 0.1749,  0.0565, -0.1936, -0.0246,  0.0251,  0.1599, -0.0493,  0.1868,\n",
      "         -0.0137,  0.0211, -0.1609,  0.0551,  0.0193, -0.2015,  0.2113, -0.0143,\n",
      "         -0.1432,  0.1660, -0.1223,  0.1426],\n",
      "        [-0.0126, -0.2231,  0.2177,  0.0990,  0.0634,  0.0672,  0.1009,  0.2093,\n",
      "          0.0102,  0.0812,  0.1486,  0.1051,  0.0347, -0.1752, -0.1285, -0.0173,\n",
      "          0.0422,  0.1595,  0.1693,  0.0203],\n",
      "        [ 0.0015, -0.1491,  0.0237,  0.0567,  0.0954, -0.1154,  0.1984, -0.1661,\n",
      "          0.1027, -0.0673,  0.1281, -0.0554,  0.0722, -0.0941, -0.1584,  0.0015,\n",
      "         -0.2209, -0.2102, -0.0857, -0.1358],\n",
      "        [-0.0766, -0.0905,  0.0531, -0.1656,  0.1444,  0.0784, -0.0712, -0.0656,\n",
      "         -0.1172, -0.1524, -0.2004,  0.2118,  0.1916,  0.2149, -0.1819, -0.1478,\n",
      "         -0.1782, -0.0149, -0.1179, -0.1844],\n",
      "        [ 0.0215, -0.1839, -0.0235, -0.1543, -0.1234, -0.1080, -0.0914,  0.1653,\n",
      "          0.0382, -0.1951, -0.2024,  0.0074,  0.1349,  0.0428,  0.0637,  0.0407,\n",
      "         -0.0659, -0.0813, -0.1040, -0.0314]])\n",
      "sequential.2.bias tensor([ 0.0678, -0.0224, -0.1749, -0.0512,  0.1235,  0.2100,  0.0348,  0.0770,\n",
      "        -0.0709, -0.0212, -0.0979, -0.0460,  0.0830, -0.1940, -0.0386,  0.0090,\n",
      "        -0.0987,  0.0567,  0.0433,  0.0020])\n",
      "sequential.4.weight tensor([[-2.6845e-02, -2.1034e-01,  3.4608e-02, -2.6588e-02,  1.2347e-01,\n",
      "          3.6397e-02, -5.0506e-02,  2.5019e-02, -3.5766e-03,  2.0281e-01,\n",
      "          2.0921e-01, -1.5117e-01,  9.4155e-02,  1.3908e-02,  2.1739e-01,\n",
      "          1.8367e-01,  1.0893e-01,  1.6144e-01, -2.0266e-01, -1.0845e-01],\n",
      "        [ 2.0849e-01,  2.1270e-01,  4.4599e-02,  1.0125e-01,  2.6348e-02,\n",
      "         -1.4401e-01,  3.9814e-02, -3.6746e-02,  3.9312e-02,  5.2296e-03,\n",
      "         -1.3813e-01,  1.1226e-01,  9.8575e-02, -1.4270e-01,  1.1595e-01,\n",
      "         -1.8882e-01,  4.4526e-02,  1.7142e-01, -8.1428e-02,  5.8103e-02],\n",
      "        [ 1.9059e-01,  1.3674e-01,  5.6149e-02, -1.1667e-01, -2.1165e-01,\n",
      "          2.2195e-01, -7.8499e-02, -2.2703e-02,  1.3013e-01, -1.3582e-01,\n",
      "          1.4043e-01,  7.4816e-02,  1.1759e-01, -2.5316e-02,  1.7539e-01,\n",
      "         -1.7965e-01, -1.4585e-01, -5.6925e-02, -2.2089e-01, -9.4458e-02],\n",
      "        [-2.2002e-01, -1.9915e-01, -1.4555e-01, -8.8338e-02, -1.0411e-01,\n",
      "         -7.6541e-02,  6.5431e-02,  1.3493e-01, -5.2387e-02,  6.3569e-02,\n",
      "         -5.1126e-03,  1.0311e-01, -1.2933e-01,  8.8549e-02, -1.7202e-01,\n",
      "         -1.0653e-01, -1.0046e-01, -9.8646e-02, -5.6328e-02, -2.0671e-01],\n",
      "        [ 1.5463e-01,  4.5200e-02, -1.6549e-01,  1.8141e-01,  1.6104e-01,\n",
      "          1.8409e-01, -1.5937e-01,  1.1834e-01, -8.1347e-03, -7.8612e-02,\n",
      "          1.8264e-01,  3.4407e-02, -1.3915e-01,  1.8990e-01, -7.8604e-02,\n",
      "         -1.9396e-01,  1.5246e-01, -2.1809e-01, -2.4677e-02, -1.0932e-02],\n",
      "        [-7.2756e-02,  1.3596e-01,  2.2027e-01,  1.3224e-01, -7.5765e-02,\n",
      "         -1.0762e-01,  1.7928e-01,  2.1194e-01,  4.0725e-03,  1.6717e-01,\n",
      "         -1.5416e-01,  2.0577e-01,  7.5032e-02,  1.8894e-01, -6.7331e-02,\n",
      "          6.5001e-02,  2.1082e-01, -1.8085e-01, -1.0292e-01,  1.7266e-01],\n",
      "        [ 9.4631e-02,  2.8365e-03,  3.1772e-02,  8.6728e-02,  1.6169e-01,\n",
      "         -6.7997e-02,  2.0794e-01,  1.0335e-04, -1.7593e-01, -1.8424e-01,\n",
      "         -6.3733e-02,  6.5346e-02, -1.9799e-01, -1.5066e-01,  1.8684e-01,\n",
      "         -2.9632e-02, -2.2272e-01,  8.4226e-02,  1.8557e-01, -2.1797e-02],\n",
      "        [-1.4682e-01,  2.0739e-01,  7.9039e-02, -1.8599e-01,  3.0836e-03,\n",
      "         -2.2048e-01,  1.1441e-01, -2.2072e-01, -4.3082e-02,  1.1795e-01,\n",
      "          1.5244e-02,  1.1627e-01, -1.9348e-01,  1.3667e-02, -4.5212e-02,\n",
      "          6.9871e-02,  1.4830e-02,  1.5880e-02,  1.2927e-01, -6.3202e-02],\n",
      "        [ 2.6465e-02,  1.1307e-01,  1.3287e-01,  9.3942e-02,  1.7704e-01,\n",
      "         -1.9473e-01, -4.1394e-03,  8.3698e-03,  1.8217e-01,  1.6810e-01,\n",
      "         -1.4511e-01,  1.5715e-01, -1.9827e-01, -4.4404e-03, -9.9184e-02,\n",
      "          2.1831e-01,  4.6152e-02,  1.5371e-01, -1.8079e-01,  1.7215e-01],\n",
      "        [-1.8928e-01,  1.3336e-02, -2.1105e-01, -1.1116e-01, -1.0180e-01,\n",
      "          1.2334e-01, -1.8216e-01, -1.3334e-01, -1.3742e-01, -1.3224e-01,\n",
      "         -7.6367e-02, -4.5961e-02,  2.1958e-01, -9.6598e-02, -2.1843e-01,\n",
      "          1.2824e-01,  3.2586e-02, -1.6856e-01, -2.1568e-01, -1.1242e-01],\n",
      "        [-1.0406e-01, -1.4148e-01,  1.2811e-01,  1.6392e-01, -2.1961e-01,\n",
      "         -1.6297e-01,  6.7578e-02, -3.4764e-02, -2.2241e-01, -5.5433e-02,\n",
      "         -5.7088e-02, -2.0160e-01,  6.3384e-02, -9.8177e-02, -9.7657e-02,\n",
      "          9.0695e-02,  4.1300e-02, -1.4466e-01, -1.2104e-01,  1.5135e-01],\n",
      "        [ 1.0394e-02, -2.3190e-02, -2.0855e-01, -1.7241e-01, -2.1074e-02,\n",
      "          1.6380e-02, -1.5119e-01, -1.8538e-01,  1.8042e-01, -3.7765e-02,\n",
      "         -5.3288e-02,  5.8126e-02, -6.3471e-02, -1.6947e-01, -8.7866e-02,\n",
      "          5.8782e-02, -4.2578e-02, -1.5336e-01, -1.0302e-01, -1.4164e-01],\n",
      "        [ 1.2368e-01,  1.2270e-01, -2.0027e-01,  9.1925e-02,  1.7092e-01,\n",
      "          1.1951e-01, -5.3475e-02,  1.8715e-01,  7.5541e-02,  2.1450e-03,\n",
      "         -1.4859e-01, -5.0138e-02, -2.1801e-01, -1.1496e-01,  1.9216e-01,\n",
      "          8.3418e-02,  2.3394e-02,  8.9272e-02,  7.7256e-02, -1.9698e-01],\n",
      "        [-8.8543e-03, -1.8142e-01,  2.1410e-01,  1.6365e-01, -2.1194e-01,\n",
      "         -1.8332e-02, -1.3160e-01,  1.6470e-01,  2.2289e-01, -1.7373e-01,\n",
      "         -5.7153e-02, -7.0978e-02,  1.4177e-01,  2.7710e-02, -8.7108e-02,\n",
      "         -1.6704e-01, -2.4789e-02,  1.7278e-01, -1.3561e-01,  1.6531e-01],\n",
      "        [-3.6759e-02,  6.0073e-02,  2.9451e-02, -1.3525e-01,  1.0990e-01,\n",
      "         -2.0574e-01,  1.1801e-01, -1.6112e-01,  1.5100e-01, -2.0503e-01,\n",
      "          1.4814e-01, -1.7348e-01, -8.0253e-02, -2.0565e-01, -1.0111e-01,\n",
      "         -1.7386e-03, -4.7629e-02, -8.0951e-02,  4.6588e-02,  4.9266e-02],\n",
      "        [ 4.9759e-02,  1.0981e-01, -3.2107e-02,  9.1148e-02,  1.8892e-01,\n",
      "          1.6012e-01,  1.8402e-01, -1.3079e-01,  1.4156e-01,  1.5891e-01,\n",
      "          2.0304e-01,  1.2873e-01,  1.5483e-01, -1.8359e-01, -1.2428e-01,\n",
      "         -8.5864e-02,  2.6201e-02, -1.0927e-01,  2.0453e-01, -1.3974e-02],\n",
      "        [-1.1173e-01, -1.2669e-01,  7.5783e-05, -1.0872e-01, -1.8098e-01,\n",
      "          2.1606e-01,  1.8213e-01,  2.2434e-02,  3.6151e-03, -1.6343e-01,\n",
      "          1.1928e-01, -1.9139e-01,  3.1787e-02,  1.5996e-01,  6.3366e-02,\n",
      "         -5.8582e-04, -1.8744e-01,  1.5068e-01,  9.5942e-02,  1.1201e-01],\n",
      "        [ 5.0468e-02, -1.7481e-01, -2.0760e-01,  1.5591e-01, -1.7375e-02,\n",
      "         -1.6989e-01, -1.8264e-01,  7.4530e-02,  1.0233e-01,  5.1845e-02,\n",
      "         -1.8755e-01,  1.6662e-01,  6.0437e-02, -7.2650e-02,  1.4323e-01,\n",
      "         -1.2700e-01,  1.5976e-01, -6.9013e-02,  1.6557e-01,  9.5195e-03],\n",
      "        [ 2.3546e-02, -1.4939e-01,  6.6354e-02,  5.6271e-02,  1.0382e-01,\n",
      "         -1.9269e-01,  2.8914e-02,  1.9912e-01,  1.9988e-01, -5.3060e-02,\n",
      "         -1.6253e-01, -1.3949e-01,  6.2461e-02,  1.5028e-02, -2.1531e-01,\n",
      "         -1.6006e-01,  1.2268e-01,  1.3364e-01, -1.9111e-01,  2.1770e-02],\n",
      "        [-1.4553e-01, -1.9770e-01, -5.3086e-02, -5.7814e-02,  1.1158e-01,\n",
      "          2.0364e-01,  2.1472e-01,  2.6097e-02, -1.5206e-01,  1.5276e-02,\n",
      "         -2.2170e-01, -1.2316e-01, -2.1113e-01, -5.6250e-02, -1.3187e-01,\n",
      "         -1.3048e-01,  1.3196e-01,  1.1236e-01,  1.1195e-01, -1.5197e-01]])\n",
      "sequential.4.bias tensor([-0.1354,  0.0697, -0.0065,  0.1799,  0.0987, -0.0619, -0.0181, -0.0606,\n",
      "        -0.1474, -0.1287, -0.2000,  0.0678, -0.2079,  0.1742,  0.1410, -0.1541,\n",
      "        -0.0207, -0.0576, -0.1111,  0.1616])\n",
      "sequential.6.weight tensor([[-1.4289e-01, -7.2244e-02,  1.1300e-01,  6.5873e-02,  9.8802e-02,\n",
      "         -1.1279e-01, -1.4832e-01,  1.1679e-01,  1.0064e-01,  1.6886e-01,\n",
      "          3.4637e-03, -1.0056e-01, -8.5729e-02, -2.0998e-01,  8.0558e-02,\n",
      "          1.0702e-01,  2.1709e-02,  1.7379e-01,  2.0078e-01, -2.4398e-02],\n",
      "        [ 3.5726e-02, -7.3012e-02,  8.8944e-02,  4.0783e-02, -6.8371e-03,\n",
      "         -1.0917e-01,  6.1152e-02, -3.9411e-02,  3.2884e-02, -1.8204e-01,\n",
      "          6.9720e-03,  1.1977e-01,  1.7913e-01,  5.9261e-02,  4.4478e-02,\n",
      "          4.6890e-02,  2.2154e-01, -2.0097e-01,  9.0432e-02,  4.5955e-02],\n",
      "        [ 1.4993e-01, -8.6061e-02, -1.8627e-01,  7.2936e-02, -1.0223e-01,\n",
      "          1.0088e-01,  3.1078e-02, -1.6848e-01, -2.0178e-01, -1.0651e-01,\n",
      "         -1.7382e-01, -2.0022e-01,  6.9468e-02, -5.0212e-02,  1.2971e-01,\n",
      "         -7.6709e-02,  1.8917e-01,  1.7377e-01, -3.3364e-02,  1.5437e-01],\n",
      "        [ 1.9993e-01, -1.2337e-01, -1.4796e-01,  1.9680e-01, -1.6512e-01,\n",
      "          1.5621e-01,  2.0709e-01,  1.4005e-01,  1.2109e-01,  1.7386e-01,\n",
      "          5.1307e-02, -2.1287e-01, -5.1717e-02,  2.0143e-01, -1.6816e-01,\n",
      "          1.8281e-01, -1.2111e-01, -5.0627e-02, -4.4558e-04, -1.8461e-01],\n",
      "        [-2.7129e-03,  1.3878e-01,  2.1764e-01, -1.5726e-01,  1.5018e-01,\n",
      "         -1.4977e-01,  5.0858e-02,  4.4780e-02, -1.5508e-01,  1.3892e-01,\n",
      "         -5.7081e-02,  5.1431e-02,  1.1922e-01, -1.9981e-03,  5.2698e-02,\n",
      "         -2.1277e-01, -1.7249e-01, -1.4281e-01,  3.7255e-02,  8.6528e-02],\n",
      "        [ 6.3595e-02,  1.1831e-01,  1.7233e-04,  1.2360e-01,  1.3111e-01,\n",
      "          2.0701e-01, -1.0937e-01, -2.2287e-01, -4.6580e-02, -6.0404e-02,\n",
      "          6.0877e-02, -3.1622e-02,  1.2795e-01,  6.3796e-02,  1.7871e-02,\n",
      "         -2.7427e-02,  1.7549e-01, -5.5215e-02, -1.2986e-01,  1.7524e-01],\n",
      "        [ 3.6263e-02,  2.3961e-02,  1.7859e-01,  7.9940e-03,  9.8426e-02,\n",
      "          4.2668e-02, -1.4939e-01, -9.9997e-02, -1.9601e-01, -1.9364e-01,\n",
      "         -7.9387e-02, -2.1244e-01,  1.0799e-01,  1.7207e-01, -5.7113e-02,\n",
      "         -1.3586e-01, -1.0529e-01, -1.2278e-01, -1.0753e-01,  1.4033e-01],\n",
      "        [ 1.0278e-01,  9.7488e-02, -1.0169e-02, -4.6916e-02, -8.0430e-02,\n",
      "         -6.0860e-02, -1.0953e-01,  1.7206e-01,  8.9243e-02, -1.6010e-01,\n",
      "         -1.1861e-01,  1.2667e-01, -5.4926e-02,  9.0554e-02, -1.3709e-01,\n",
      "          2.0771e-01, -7.4566e-02, -6.0602e-02, -2.6124e-02, -4.0347e-03],\n",
      "        [ 1.7621e-01, -4.3086e-02, -4.9375e-02, -1.5879e-01, -1.4644e-01,\n",
      "          3.0282e-02, -1.7985e-01,  9.5627e-02, -1.1270e-01, -9.4719e-02,\n",
      "          6.1524e-03,  9.7673e-02,  8.2959e-02, -1.8098e-01,  1.7175e-01,\n",
      "          7.7786e-02, -1.6506e-01,  1.9288e-01,  1.3906e-01, -1.7658e-02],\n",
      "        [-8.0806e-02,  7.4597e-02, -6.2787e-02, -1.9026e-01, -4.7081e-02,\n",
      "          1.8996e-01, -1.7427e-02,  7.5326e-02, -2.9946e-02, -4.4124e-04,\n",
      "         -1.4533e-01, -6.4674e-02,  5.6681e-02,  1.0432e-01, -7.3395e-02,\n",
      "          2.0811e-01, -2.2127e-01,  5.0556e-03,  1.2825e-01, -1.3694e-01],\n",
      "        [ 1.2963e-01,  4.9677e-02, -1.1157e-01,  1.4324e-01,  7.4650e-02,\n",
      "         -2.1923e-01,  1.3649e-01, -1.6469e-01, -1.2668e-01, -1.1311e-02,\n",
      "         -1.2164e-03,  4.9176e-02, -9.3475e-02, -3.3653e-02,  1.9343e-01,\n",
      "          1.4251e-01, -1.0344e-01, -2.7910e-02, -1.2530e-01,  1.1127e-01],\n",
      "        [-2.9236e-02, -1.4687e-01,  1.5510e-02, -8.0768e-02,  1.5962e-01,\n",
      "          1.0227e-01, -1.6701e-02,  1.9454e-01,  2.7622e-02, -1.5266e-01,\n",
      "          1.8619e-01, -2.1830e-01, -8.1708e-02,  1.4743e-01, -1.4885e-01,\n",
      "         -9.6924e-03,  2.0835e-02,  1.2636e-02, -4.5263e-03,  4.4992e-02],\n",
      "        [-2.1024e-01, -7.4037e-02, -1.3663e-01, -5.5232e-02, -7.9619e-02,\n",
      "         -1.2897e-01, -1.8844e-02,  2.0786e-01,  7.6850e-02,  1.4230e-01,\n",
      "         -1.2619e-01,  6.0153e-02,  5.8867e-02, -9.4444e-02, -7.7841e-02,\n",
      "          3.0920e-02, -1.0999e-01,  4.0565e-02,  9.6586e-02, -1.5373e-01],\n",
      "        [ 9.1032e-02, -1.8307e-01, -1.7601e-01, -1.3210e-01, -5.9426e-02,\n",
      "          7.3621e-02,  1.4027e-02,  2.1892e-01,  4.3615e-02,  1.3588e-01,\n",
      "          2.1779e-01,  6.3571e-03, -5.6641e-02,  2.1359e-01, -1.2054e-02,\n",
      "          1.0176e-01, -8.6414e-02,  5.1964e-02,  8.6911e-02, -2.0433e-01],\n",
      "        [ 2.9353e-02,  7.5357e-02, -1.5336e-01, -1.6955e-01, -1.5722e-01,\n",
      "          1.3437e-02,  1.4342e-01, -9.0781e-02,  1.5592e-01, -1.4651e-01,\n",
      "         -1.0526e-01,  1.6682e-01, -1.4394e-01, -2.9582e-02, -1.7842e-01,\n",
      "         -1.7897e-02,  2.2150e-01,  4.1977e-02, -1.0314e-02,  6.0142e-02],\n",
      "        [ 2.1614e-01, -1.0076e-01,  1.1262e-01, -1.5192e-01,  9.0526e-02,\n",
      "         -1.3587e-01,  1.6828e-01,  2.0630e-01, -1.0792e-01, -2.1351e-03,\n",
      "         -6.4717e-02, -1.8140e-01,  1.6382e-01, -5.0054e-02,  5.8724e-02,\n",
      "          1.4626e-01,  1.8578e-01, -1.9725e-01,  8.9853e-02,  1.7534e-01],\n",
      "        [-5.5483e-02, -4.5858e-02,  8.9747e-02, -4.0444e-02, -8.4415e-02,\n",
      "          6.5609e-02,  2.5776e-03,  2.1350e-01,  5.4611e-02,  1.4960e-01,\n",
      "         -1.7164e-01, -1.4329e-01, -6.9560e-02, -1.6113e-01, -2.0494e-01,\n",
      "         -2.2034e-01,  1.2787e-01, -1.0156e-01, -2.2262e-01,  8.9305e-03],\n",
      "        [-1.8739e-01, -2.1812e-01,  8.9479e-03, -1.0342e-01,  5.3867e-02,\n",
      "          1.6032e-01, -1.7573e-01,  1.0108e-01,  1.2482e-01, -1.1615e-01,\n",
      "          1.8616e-01,  1.6436e-01,  1.7840e-01, -6.3646e-02, -1.2080e-02,\n",
      "          1.6278e-01,  1.6463e-01, -1.9213e-01,  2.2028e-02,  9.9731e-02],\n",
      "        [ 6.8054e-02, -1.5807e-02, -1.9972e-01,  1.2136e-01, -1.5747e-01,\n",
      "         -1.8255e-01, -1.4959e-01, -2.2132e-01, -2.6077e-02, -1.9449e-01,\n",
      "         -1.0282e-01,  1.0223e-02,  1.7183e-01, -1.8574e-02, -1.5161e-01,\n",
      "         -7.6656e-02,  1.8269e-02,  1.2559e-01, -4.8398e-03,  9.4625e-02],\n",
      "        [ 1.9807e-01, -3.6876e-03,  2.1865e-01,  8.8132e-02,  1.5182e-01,\n",
      "         -2.1384e-01,  4.5210e-02, -1.4153e-01, -1.3284e-01,  1.1677e-01,\n",
      "         -1.1971e-01,  4.1472e-02,  1.4826e-01, -1.0717e-01, -7.2039e-02,\n",
      "         -1.7820e-01, -6.1517e-02,  7.3576e-02, -1.1100e-01,  3.2683e-02]])\n",
      "sequential.6.bias tensor([-0.1593, -0.0176, -0.0220, -0.0533,  0.2113, -0.1347, -0.1690,  0.0889,\n",
      "         0.2161, -0.1742, -0.1350, -0.0250, -0.2075,  0.0774, -0.1294, -0.2183,\n",
      "        -0.0335, -0.2190, -0.0040, -0.0534])\n",
      "sequential.8.weight tensor([[-0.1489,  0.1178, -0.0167, -0.1140, -0.0481,  0.1571, -0.1665, -0.2107,\n",
      "         -0.1379,  0.0131,  0.0167, -0.1816,  0.2053,  0.0985, -0.2189, -0.0568,\n",
      "          0.0009,  0.0079,  0.1687,  0.0573]])\n",
      "sequential.8.bias tensor([0.2202])\n"
     ]
    }
   ],
   "source": [
    "for name,param in mymodel.state_dict().items():\n",
    "    print(name,param)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which one is correct?\n",
    "\n",
    "In pytorch, you need to specify the input and output dimension for each layer. The input dimension of each layer must match the output dimension for the previous layer. Which one of the following code is correct?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myMultiLayerPerceptron_1(nn.Module):\n",
    "    def __init__(self,input_dim,output_dim):\n",
    "        super().__init__()\n",
    "        self.sequential = nn.Sequential(  # here we stack multiple layers together\n",
    "            nn.Linear(input_dim,20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20,30),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20,30),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20,30),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20,output_dim)\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        y = self.sequential(x)\n",
    "        return y\n",
    "\n",
    "class myMultiLayerPerceptron_2(nn.Module):\n",
    "    def __init__(self,input_dim,output_dim):\n",
    "        super().__init__()\n",
    "        self.sequential = nn.Sequential(  # here we stack multiple layers together\n",
    "            nn.Linear(input_dim,30),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(30,20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20,30),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(30,20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20,output_dim)\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        y = self.sequential(x)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x30 and 20x30)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m mymlp_1 \u001b[38;5;241m=\u001b[39m myMultiLayerPerceptron_1(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmymlp_1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/systems_and_toolchains/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/systems_and_toolchains/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[12], line 16\u001b[0m, in \u001b[0;36mmyMultiLayerPerceptron_1.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,x):\n\u001b[0;32m---> 16\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msequential\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[0;32m~/anaconda3/envs/systems_and_toolchains/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/systems_and_toolchains/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/systems_and_toolchains/lib/python3.12/site-packages/torch/nn/modules/container.py:219\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 219\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/systems_and_toolchains/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/systems_and_toolchains/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/systems_and_toolchains/lib/python3.12/site-packages/torch/nn/modules/linear.py:117\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x30 and 20x30)"
     ]
    }
   ],
   "source": [
    "mymlp_1 = myMultiLayerPerceptron_1(1,1)\n",
    "mymlp_1(torch.tensor([[1.0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0011]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mymlp_2 = myMultiLayerPerceptron_2(1,1)\n",
    "mymlp_2(torch.tensor([[1.0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Prepare Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since neural networks are nonlinear ML models, we are going to create some nonlinear training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f378f97e570>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Now let's create some simple synthetic data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "N_samples = 50\n",
    "x = torch.linspace(-10,10,N_samples,dtype=torch.float) \n",
    "x = x[:,None]\n",
    "y = torch.sin(0.5*x) + np.random.randn(N_samples,1)*0.2\n",
    "\n",
    "\n",
    "prediction = mymodel(x).detach().numpy()\n",
    "plt.plot(x,y,'ro')\n",
    "plt.plot(x,prediction)\n",
    "plt.legend(['data','prediction of mymodel before training'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we will be running SGD, we need to do batching. Therefore, let's convert the training data tensors into Dataset objects. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class MyDataset(Dataset): \n",
    "    def __init__(self,x,y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.x.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.x[idx],self.y[idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydataset = MyDataset(x,y) # generate a Dataset based on x,y\n",
    "\n",
    "# Randomly split dataset into train and validate dataset\n",
    "dataset_len = len(mydataset)\n",
    "train_dataset_len = round(dataset_len*0.8)\n",
    "validate_dataset_len = dataset_len - train_dataset_len\n",
    "train_dataset,validate_dataset = torch.utils.data.random_split(mydataset,[train_dataset_len, validate_dataset_len])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Training Neural Network via Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, the training loop is almost identical as before, which is a nested for-loop. In each training iteration in the training loop, recall we have the following steps. \n",
    "\n",
    "- First the prediction is computed based on the input variable of a small batch of the training data set (obtained from DataLoader). \n",
    "- Then, the prediction, together with the true output, is used to compute the loss.\n",
    "- Then, we run the optimizer.zero_grad(), which clears the gradient computed from the previous loop. \n",
    "- Then, we run loss.backward() which calculates the gradient of the loss w.r.t. the parameters\n",
    "- Finally, optimizer.step() conducts a gradient step\n",
    "\n",
    "One difference this time is that at the end of each epoch, we also calculate the validation loss using the validation dataset. This is a common practice in deep learning. \n",
    "\n",
    "The code below also saves the traning process as a GIF file so that you can visualize the training process. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda\n",
      "Epoch 0 of 160\n",
      "Training Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/reid/anaconda3/envs/systems_and_toolchains/lib/python3.12/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/reid/anaconda3/envs/systems_and_toolchains/lib/python3.12/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/tmp/ipykernel_2849636/2682029514.py:85: MatplotlibDeprecationWarning: The tostring_rgb function was deprecated in Matplotlib 3.8 and will be removed in 3.10. Use buffer_rgba instead.\n",
      "  image = np.frombuffer(canvas.tostring_rgb(), dtype='uint8')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 160\n",
      "Training Loss: 0.5764197694769678\n",
      "Epoch 2 of 160\n",
      "Training Loss: 0.5705828780891544\n",
      "Epoch 3 of 160\n",
      "Training Loss: 0.5672512644396163\n",
      "Epoch 4 of 160\n",
      "Training Loss: 0.5629199128326474\n",
      "Epoch 5 of 160\n",
      "Training Loss: 0.5595089623585141\n",
      "Epoch 6 of 160\n",
      "Training Loss: 0.5562329535568686\n",
      "Epoch 7 of 160\n",
      "Training Loss: 0.5554412750246751\n",
      "Epoch 8 of 160\n",
      "Training Loss: 0.5536735939056315\n",
      "Epoch 9 of 160\n",
      "Training Loss: 0.5511834433001873\n",
      "Epoch 10 of 160\n",
      "Training Loss: 0.5502660946988402\n",
      "Epoch 11 of 160\n",
      "Training Loss: 0.5493080843242792\n",
      "Epoch 12 of 160\n",
      "Training Loss: 0.5474740112832396\n",
      "Epoch 13 of 160\n",
      "Training Loss: 0.5460318332387467\n",
      "Epoch 14 of 160\n",
      "Training Loss: 0.5448335303859475\n",
      "Epoch 15 of 160\n",
      "Training Loss: 0.5435540238113744\n",
      "Epoch 16 of 160\n",
      "Training Loss: 0.5417537645039581\n",
      "Epoch 17 of 160\n",
      "Training Loss: 0.539558938908413\n",
      "Epoch 18 of 160\n",
      "Training Loss: 0.5378597337332249\n",
      "Epoch 19 of 160\n",
      "Training Loss: 0.5367159373629147\n",
      "Epoch 20 of 160\n",
      "Training Loss: 0.534815970209652\n",
      "Epoch 21 of 160\n",
      "Training Loss: 0.5337866507613912\n",
      "Epoch 22 of 160\n",
      "Training Loss: 0.5313586555131379\n",
      "Epoch 23 of 160\n",
      "Training Loss: 0.5293638167296725\n",
      "Epoch 24 of 160\n",
      "Training Loss: 0.5271357943084879\n",
      "Epoch 25 of 160\n",
      "Training Loss: 0.5247233352801013\n",
      "Epoch 26 of 160\n",
      "Training Loss: 0.5224041843048267\n",
      "Epoch 27 of 160\n",
      "Training Loss: 0.5197026832209445\n",
      "Epoch 28 of 160\n",
      "Training Loss: 0.5172469173586673\n",
      "Epoch 29 of 160\n",
      "Training Loss: 0.5143929798002274\n",
      "Epoch 30 of 160\n",
      "Training Loss: 0.5113603778724657\n",
      "Epoch 31 of 160\n",
      "Training Loss: 0.5080169201438215\n",
      "Epoch 32 of 160\n",
      "Training Loss: 0.5042922317073472\n",
      "Epoch 33 of 160\n",
      "Training Loss: 0.5003190422604004\n",
      "Epoch 34 of 160\n",
      "Training Loss: 0.4967976392623614\n",
      "Epoch 35 of 160\n",
      "Training Loss: 0.4924992489648864\n",
      "Epoch 36 of 160\n",
      "Training Loss: 0.4882024324513263\n",
      "Epoch 37 of 160\n",
      "Training Loss: 0.48397904424576815\n",
      "Epoch 38 of 160\n",
      "Training Loss: 0.47922253529772935\n",
      "Epoch 39 of 160\n",
      "Training Loss: 0.4743711788344061\n",
      "Epoch 40 of 160\n",
      "Training Loss: 0.469065387369092\n",
      "Epoch 41 of 160\n",
      "Training Loss: 0.4645120730605203\n",
      "Epoch 42 of 160\n",
      "Training Loss: 0.4586364804785961\n",
      "Epoch 43 of 160\n",
      "Training Loss: 0.4542544080633567\n",
      "Epoch 44 of 160\n",
      "Training Loss: 0.4516319872254593\n",
      "Epoch 45 of 160\n",
      "Training Loss: 0.446401701424693\n",
      "Epoch 46 of 160\n",
      "Training Loss: 0.44307897755486025\n",
      "Epoch 47 of 160\n",
      "Training Loss: 0.4386787958688744\n",
      "Epoch 48 of 160\n",
      "Training Loss: 0.4330202351475178\n",
      "Epoch 49 of 160\n",
      "Training Loss: 0.42785910005712213\n",
      "Epoch 50 of 160\n",
      "Training Loss: 0.42291314187831397\n",
      "Epoch 51 of 160\n",
      "Training Loss: 0.42081177082915905\n",
      "Epoch 52 of 160\n",
      "Training Loss: 0.4174564647650306\n",
      "Epoch 53 of 160\n",
      "Training Loss: 0.41283912247170634\n",
      "Epoch 54 of 160\n",
      "Training Loss: 0.40720636190887344\n",
      "Epoch 55 of 160\n",
      "Training Loss: 0.4021865776881692\n",
      "Epoch 56 of 160\n",
      "Training Loss: 0.3980115924921478\n",
      "Epoch 57 of 160\n",
      "Training Loss: 0.3930642105430072\n",
      "Epoch 58 of 160\n",
      "Training Loss: 0.38841415633104764\n",
      "Epoch 59 of 160\n",
      "Training Loss: 0.38394131136594284\n",
      "Epoch 60 of 160\n",
      "Training Loss: 0.3802435162707502\n",
      "Epoch 61 of 160\n",
      "Training Loss: 0.37540898741285916\n",
      "Epoch 62 of 160\n",
      "Training Loss: 0.3708627750298706\n",
      "Epoch 63 of 160\n",
      "Training Loss: 0.3659140434709653\n",
      "Epoch 64 of 160\n",
      "Training Loss: 0.36128692575365756\n",
      "Epoch 65 of 160\n",
      "Training Loss: 0.3572413716234568\n",
      "Epoch 66 of 160\n",
      "Training Loss: 0.3526144034788217\n",
      "Epoch 67 of 160\n",
      "Training Loss: 0.34939567522182985\n",
      "Epoch 68 of 160\n",
      "Training Loss: 0.3452356428459132\n",
      "Epoch 69 of 160\n",
      "Training Loss: 0.343297027167609\n",
      "Epoch 70 of 160\n",
      "Training Loss: 0.3403105601970905\n",
      "Epoch 71 of 160\n",
      "Training Loss: 0.3374097095536075\n",
      "Epoch 72 of 160\n",
      "Training Loss: 0.33401837411320656\n",
      "Epoch 73 of 160\n",
      "Training Loss: 0.33040303914738167\n",
      "Epoch 74 of 160\n",
      "Training Loss: 0.3270028270286618\n",
      "Epoch 75 of 160\n",
      "Training Loss: 0.3237357447032466\n",
      "Epoch 76 of 160\n",
      "Training Loss: 0.3202192327907716\n",
      "Epoch 77 of 160\n",
      "Training Loss: 0.3168366233712664\n",
      "Epoch 78 of 160\n",
      "Training Loss: 0.3150036717062919\n",
      "Epoch 79 of 160\n",
      "Training Loss: 0.31278036551365535\n",
      "Epoch 80 of 160\n",
      "Training Loss: 0.3097184259088436\n",
      "Epoch 81 of 160\n",
      "Training Loss: 0.30651936646177547\n",
      "Epoch 82 of 160\n",
      "Training Loss: 0.3034712410742845\n",
      "Epoch 83 of 160\n",
      "Training Loss: 0.30058428224348277\n",
      "Epoch 84 of 160\n",
      "Training Loss: 0.29803119810170714\n",
      "Epoch 85 of 160\n",
      "Training Loss: 0.29529205492488814\n",
      "Epoch 86 of 160\n",
      "Training Loss: 0.2927251340655861\n",
      "Epoch 87 of 160\n",
      "Training Loss: 0.2899609742874786\n",
      "Epoch 88 of 160\n",
      "Training Loss: 0.287493319427846\n",
      "Epoch 89 of 160\n",
      "Training Loss: 0.28509026415763916\n",
      "Epoch 90 of 160\n",
      "Training Loss: 0.28290335351408763\n",
      "Epoch 91 of 160\n",
      "Training Loss: 0.2803663796848737\n",
      "Epoch 92 of 160\n",
      "Training Loss: 0.2778864819712749\n",
      "Epoch 93 of 160\n",
      "Training Loss: 0.275917852937336\n",
      "Epoch 94 of 160\n",
      "Training Loss: 0.2740851558462737\n",
      "Epoch 95 of 160\n",
      "Training Loss: 0.2721464431556962\n",
      "Epoch 96 of 160\n",
      "Training Loss: 0.26978961178580363\n",
      "Epoch 97 of 160\n",
      "Training Loss: 0.26900202585212335\n",
      "Epoch 98 of 160\n",
      "Training Loss: 0.26726582236298985\n",
      "Epoch 99 of 160\n",
      "Training Loss: 0.2652397825342244\n",
      "Epoch 100 of 160\n",
      "Training Loss: 0.26341054994840674\n",
      "Epoch 101 of 160\n",
      "Training Loss: 0.2616401543654936\n",
      "Epoch 102 of 160\n",
      "Training Loss: 0.2596188221782063\n",
      "Epoch 103 of 160\n",
      "Training Loss: 0.2578531379945962\n",
      "Epoch 104 of 160\n",
      "Training Loss: 0.2562187523156529\n",
      "Epoch 105 of 160\n",
      "Training Loss: 0.2547061881912765\n",
      "Epoch 106 of 160\n",
      "Training Loss: 0.25281073574850715\n",
      "Epoch 107 of 160\n",
      "Training Loss: 0.2511061849660127\n",
      "Epoch 108 of 160\n",
      "Training Loss: 0.24945385423078684\n",
      "Epoch 109 of 160\n",
      "Training Loss: 0.2482033360945622\n",
      "Epoch 110 of 160\n",
      "Training Loss: 0.24626277054321255\n",
      "Epoch 111 of 160\n",
      "Training Loss: 0.24462490538838752\n",
      "Epoch 112 of 160\n",
      "Training Loss: 0.24334036125358022\n",
      "Epoch 113 of 160\n",
      "Training Loss: 0.2419192622115259\n",
      "Epoch 114 of 160\n",
      "Training Loss: 0.24030760331162043\n",
      "Epoch 115 of 160\n",
      "Training Loss: 0.23857039733221697\n",
      "Epoch 116 of 160\n",
      "Training Loss: 0.2368505782296562\n",
      "Epoch 117 of 160\n",
      "Training Loss: 0.2351360563352932\n",
      "Epoch 118 of 160\n",
      "Training Loss: 0.23349458137304227\n",
      "Epoch 119 of 160\n",
      "Training Loss: 0.23188049349097473\n",
      "Epoch 120 of 160\n",
      "Training Loss: 0.2304775711305276\n",
      "Epoch 121 of 160\n",
      "Training Loss: 0.22897514546577755\n",
      "Epoch 122 of 160\n",
      "Training Loss: 0.2274191207946023\n",
      "Epoch 123 of 160\n",
      "Training Loss: 0.22600653805586618\n",
      "Epoch 124 of 160\n",
      "Training Loss: 0.22467857668093114\n",
      "Epoch 125 of 160\n",
      "Training Loss: 0.22347559102460413\n",
      "Epoch 126 of 160\n",
      "Training Loss: 0.2220845903031792\n",
      "Epoch 127 of 160\n",
      "Training Loss: 0.22094380095495275\n",
      "Epoch 128 of 160\n",
      "Training Loss: 0.22019828800366942\n",
      "Epoch 129 of 160\n",
      "Training Loss: 0.2189989081477002\n",
      "Epoch 130 of 160\n",
      "Training Loss: 0.21757547633473184\n",
      "Epoch 131 of 160\n",
      "Training Loss: 0.21625035142345356\n",
      "Epoch 132 of 160\n",
      "Training Loss: 0.21491613754155844\n",
      "Epoch 133 of 160\n",
      "Training Loss: 0.21353894490873734\n",
      "Epoch 134 of 160\n",
      "Training Loss: 0.21227351065099065\n",
      "Epoch 135 of 160\n",
      "Training Loss: 0.21104461879523048\n",
      "Epoch 136 of 160\n",
      "Training Loss: 0.2099762464977184\n",
      "Epoch 137 of 160\n",
      "Training Loss: 0.20882100282922977\n",
      "Epoch 138 of 160\n",
      "Training Loss: 0.2075717141514881\n",
      "Epoch 139 of 160\n",
      "Training Loss: 0.20637491875710343\n",
      "Epoch 140 of 160\n",
      "Training Loss: 0.2052698451919685\n",
      "Epoch 141 of 160\n",
      "Training Loss: 0.2040598673427661\n",
      "Epoch 142 of 160\n",
      "Training Loss: 0.2028766225585523\n",
      "Epoch 143 of 160\n",
      "Training Loss: 0.20195860554338277\n",
      "Epoch 144 of 160\n",
      "Training Loss: 0.2009104132935614\n",
      "Epoch 145 of 160\n",
      "Training Loss: 0.199972405359992\n",
      "Epoch 146 of 160\n",
      "Training Loss: 0.1989553105240347\n",
      "Epoch 147 of 160\n",
      "Training Loss: 0.19792574772871557\n",
      "Epoch 148 of 160\n",
      "Training Loss: 0.19684772646399243\n",
      "Epoch 149 of 160\n",
      "Training Loss: 0.1958338513861492\n",
      "Epoch 150 of 160\n",
      "Training Loss: 0.19488900525372824\n",
      "Epoch 151 of 160\n",
      "Training Loss: 0.193867997022318\n",
      "Epoch 152 of 160\n",
      "Training Loss: 0.19283728252343102\n",
      "Epoch 153 of 160\n",
      "Training Loss: 0.1919296492511591\n",
      "Epoch 154 of 160\n",
      "Training Loss: 0.19102530860406952\n",
      "Epoch 155 of 160\n",
      "Training Loss: 0.19008695048945584\n",
      "Epoch 156 of 160\n",
      "Training Loss: 0.18923961964443686\n",
      "Epoch 157 of 160\n",
      "Training Loss: 0.1884299034216947\n",
      "Epoch 158 of 160\n",
      "Training Loss: 0.1875424929470231\n",
      "Epoch 159 of 160\n",
      "Training Loss: 0.18675287171457508\n",
      "Saving GIF file\n"
     ]
    }
   ],
   "source": [
    "# Now let's do the training!\n",
    "import io\n",
    "import imageio\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "from matplotlib.figure import Figure\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Training on {device}\")\n",
    "\n",
    "mymodel = myMultiLayerPerceptron(1,1).to(device) # creating a model instance with input dimension 1\n",
    "\n",
    "# Three hyper parameters for training\n",
    "lr = .04\n",
    "batch_size = 10\n",
    "N_epochs = 160\n",
    "\n",
    "# Create dataloaders for training and validation\n",
    "train_dataloader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n",
    "validate_dataloader = DataLoader(validate_dataset,batch_size = batch_size,shuffle = True)\n",
    "\n",
    "# Create optimizer\n",
    "optimizer = torch.optim.SGD(mymodel.parameters(), lr = lr) # this line creates a optimizer, and we tell optimizer we are optimizing the parameters in mymodel\n",
    "\n",
    "frames = [] # This variable stores all images to be saved to the GIF file\n",
    "losses = [] # training losses of each epoch\n",
    "validate_losses = [] # validation losses of each epoch\n",
    "losses_all = [] # training losses of each SGD iteration\n",
    "\n",
    "gd_steps = 0\n",
    "N_batches = len(train_dataloader)\n",
    "x = x.to(device)\n",
    "y = y.to(device)\n",
    "\n",
    "for epoch in range(N_epochs):\n",
    "    batch_loss = []\n",
    "    print(f\"Epoch {epoch} of {N_epochs}\")\n",
    "    print(f\"Training Loss: {np.mean(np.array(losses))}\")\n",
    "    for batch_id, (x_batch, y_batch) in enumerate(train_dataloader):\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        gd_steps+=1\n",
    "        # pass input data to get the prediction outputs by the current model\n",
    "        prediction = mymodel(x_batch)\n",
    "\n",
    "        # compare prediction and the actual output and compute the loss\n",
    "        loss = torch.mean((prediction - y_batch)**2)\n",
    "\n",
    "        # compute the gradient\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # Generate visualization plots\n",
    "        fig, ax = plt.subplots(nrows = 1, ncols = 3)\n",
    "        canvas = FigureCanvas(fig)\n",
    "        ax[0].plot(x.cpu(), y.cpu(), 'ro')\n",
    "        prediction_full = mymodel(x)\n",
    "        ax[0].plot(x.cpu(), prediction_full.detach().cpu(), linewidth = 2)\n",
    "        ax[0].legend(['data','prediction of mymodel'],loc = 'upper left')\n",
    "        ax[0].set_title(f\"Batch size = {batch_size}, Learning rate = {lr}, Epoch #{epoch}, Batch #{batch_id}\", fontsize = 20)\n",
    "        ax[0].set_xlim((-10,10))\n",
    "        ax[0].set_ylim((-2,2))\n",
    "        losses_all.append(loss.detach().cpu().numpy())\n",
    "        ax[1].plot(np.arange(gd_steps),np.array(losses_all).squeeze(),linewidth=2 )\n",
    "        ax[1].set_xlim((0,(N_epochs+1)*(N_batches)))\n",
    "        ax[1].set_ylim((0,2))\n",
    "        ax[1].set_title(\"Train loss per iteration\", fontsize = 20)\n",
    "        ax[1].set_xlabel(\"# of SGD Iterations\", fontsize = 20)\n",
    "\n",
    "        batch_loss.append(loss.detach().cpu().numpy())\n",
    "        if epoch>0:\n",
    "            ax[2].plot(np.arange(epoch),np.array(losses).squeeze(),linewidth=2, label = 'train loss' )\n",
    "            ax[2].plot(np.arange(epoch),np.array(validate_losses).squeeze(),linewidth=2, label = 'validate loss')\n",
    "            ax[2].legend(fontsize = 20)\n",
    "        \n",
    "        ax[2].set_xlim((0,N_epochs-1))\n",
    "        ax[2].set_ylim((0,2))\n",
    "        ax[2].set_title(\"Train/validate loss per epoch\", fontsize = 20)\n",
    "        ax[2].set_xlabel(\"# of Epochs\", fontsize = 20)\n",
    "        fig.set_size_inches(27,9) \n",
    "        canvas.draw()       # draw the canvas, cache the renderer\n",
    "\n",
    "        image = np.frombuffer(canvas.tostring_rgb(), dtype='uint8')\n",
    "\n",
    "        image = image.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "\n",
    "        frames.append(image)\n",
    "        plt.close(fig)\n",
    "    \n",
    "    # Calculate Validation Loss\n",
    "    validate_batch_loss = []\n",
    "    for x_batch, y_batch in validate_dataloader:\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        # pass input data to get the prediction outputs by the current model\n",
    "        prediction = mymodel(x_batch)\n",
    "\n",
    "        # compare prediction and the actual output and compute the loss\n",
    "        loss = torch.mean((prediction - y_batch)**2)\n",
    "        validate_batch_loss.append(loss.detach().cpu().numpy())\n",
    "\n",
    "    validate_losses.append(np.mean(np.array(validate_batch_loss)))\n",
    "    losses.append(np.mean(np.array(batch_loss)))\n",
    "\n",
    "print(\"Saving GIF file\")\n",
    "with imageio.get_writer(\"MLPSGD.gif\", mode=\"I\") as writer:\n",
    "    for frame in frames:\n",
    "        writer.append_data(frame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f3821e58470>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi8AAAGdCAYAAADaPpOnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB3EklEQVR4nO3dd3xUVfo/8M+dSSe9kE4SQi+hl4ChK00EAqKAUqSoX1CwrbK/FVB3F1exsOraBRtYELAhSAkd6Z3QQjopkJBO2sz9/TFkSLh3kkkyfT7v1yuvMOfemTnDZGaeOec5zxFEURRBREREZCUU5u4AERERUWMweCEiIiKrwuCFiIiIrAqDFyIiIrIqDF6IiIjIqjB4ISIiIqvC4IWIiIisCoMXIiIisioO5u6AoanValy7dg0eHh4QBMHc3SEiIiI9iKKI4uJihISEQKGof2zF5oKXa9euITw83NzdICIioiZIT09HWFhYvefYXPDi4eEBQPPgPT09zdwbIiIi0kdRURHCw8O1n+P1sbngpWaqyNPTk8ELERGRldEn5YMJu0RERGRVGLwQERGRVWHwQkRERFbF5nJeiOyJKIqorq6GSqUyd1eIiBrk6OgIpVLZ7Nth8EJkpSorK5GVlYWysjJzd4WISC+CICAsLAzu7u7Nuh0GL0RWSK1WIzk5GUqlEiEhIXBycmJRRiKyaKIo4vr168jIyEDbtm2bNQLD4IXIClVWVkKtViM8PBxubm7m7g4RkV4CAgKQkpKCqqqqZgUvTNglsmINldAmIrIkhhoh5sgLEZG1EkWgpASorAScnAB3d4DTh2QHGLwQEVmjmzeB9HRN4FLDyQkIDwd8fMzXLyIT4Jgzkb1TqYBdu4B16zS/zbTsesiQIVi8eLFZ7tvq3LwJJCXVDVwAzeWkJM1xIhvG4MUSWciHCdmBDRuAyEhg6FBg2jTN78hITbsF27VrFwRBQEFBgbm7YnqiqBlxqU96uuY8IhvF4MXSWOmHCVmhDRuAyZOBjIy67ZmZmnb+zVmmmhyX+lRWas4jslEMXiwJP0zIVFQqYNEi+W/nNW2LFxtt1K+0tBQzZsyAu7s7goOD8dZbb9U5/vXXX6N3797w8PBAUFAQpk2bhtzcXABASkoKhg4dCgDw8fGBIAiYNWsWAGDLli2455574O3tDT8/P9x///1ISkoyymMwm4YCl8aeR2SFGLxYCjN/mJCd2btXGiTXVjM1sXevUe7+hRdewO7du/Hzzz/jzz//xK5du3D8+HHt8aqqKrz22ms4deoUNm3ahJSUFG2AEh4ejp9++gkAcPHiRWRlZWHVqlUANEHRs88+i6NHj2LHjh1QKBSYOHEi1Gq1UR6HWTg5GfY8IivE1UaWojEfJkOGmKxbZKOysgx7XiOUlJTg888/xzfffIPhw4cDAL788kuEhYVpz3nssce0/27dujX++9//ok+fPigpKYG7uzt8fX0BAC1btoS3t7f23EmTJtW5ry+++AIBAQE4f/48unTpYvDHYhbu7prApL6RlZpl00Q2iiMvlsKMHyZkh4KDDXteIyQlJaGyshL9+vXTtvn6+qJ9+/bay8eOHcO4cePQqlUreHh4YPDgwQCAtLS0em/78uXLmDp1Klq3bg1PT09ERkbqdT2rIgia5dD1CQ9nvReyaQxeLIUZP0zIDsXFAWFhuj/gaj4g4+JM2y9opn5GjhwJT09PfPvttzhy5Ag2btwIQLMtQn3GjRuH/Px8fPrppzh06BAOHTqk1/Wsjo8PEB0tnRpyctK0s84L2ThOG1mKmg+TzEz5vBdB0Bw3w4cJ2SClEli1SpMILgh1/+ZqApp339WcZ2DR0dFwdHTEoUOH0KpVKwDAzZs3cenSJQwePBgXLlxAXl4eXn/9dYTfHmE4evRondtwuv2hraqVA5aXl4eLFy/i008/Rdzt18m+ffsM3n+L4eMDeHuzwi7ZJY68WIqaDxNA+uZj5A8TslPx8cD69UBoaN32sDBNe3y8Ue7W3d0dc+bMwQsvvICdO3fi7NmzmDVrlnafplatWsHJyQnvvfcerl69il9++QWvvfZanduIiIiAIAj47bffcP36dZSUlMDHxwd+fn745JNPcOXKFezcuRPPPvusUR6DxRAEwMMD8PPT/GbgQnaCwYslMdOHCdmx+HggJQVISADWrtX8Tk42+t/am2++ibi4OIwbNw4jRozAPffcg169egHQ7Dq7Zs0a/Pjjj+jUqRNef/11rFy5ss71Q0ND8corr+Cll15CYGAgFi5cCIVCge+++w7Hjh1Dly5d8Mwzz+DNN9806uMgIvMQRNG2yjAWFRXBy8sLhYWF8PT0NHd3mkal0qwqysrS5LjExXHEheooLy9HcnIyoqKi4OLiYu7uEBHppb73rsZ8fjPnxRIplVwOTWSJuIszkUVg8EJEpA/u4kxkMZjzQkTUEO7iTGRRGLwQEdWHuzgTWRwGL0RE9eEuzkQWh8ELEVF9uIszkcVh8EJEVB/u4kxkcRi8EBHVp2YX5/pwF2cik2LwQkQ2LTIyEu+++672siAI2LRpk/43ILOLs9CnDzbt2nWnwUy7OGdnZ+Pee+9FixYt4O3tbfL7N5W7n8OGLF++HN27d2/2/S5fvhyBgYGN/5uxEI39f9u1axcEQUBBQYHR+mQorPNCRHYlKysLPnrWZVm+fDk2bdqEkydPanZrvl3nJeuPP+Dj6Wn2Oi/vvPMOsrKycPLkSXh5eZmlD7YqMTERr7zyCjZu3Ij+/fvDx8cHkZGRWLx4MRYvXmyU+xwyZAi6d+/eqICjPkeOHEGLFi30Pn/AgAHIysqyir8lBi9EZPEqKyu1O0k3V1BQUNOuWGsX56CoKIuosJuUlIRevXqhbdu2ZuuDrUpKSgIAjB8/HoKBn+Pm/D2LogiVSgUHh4Y/vgMCAhp1205OTk1/fZgYp42IbMBLP53GxP/tN+vPSz+d1quvQ4YMwcKFC7Fw4UJ4eXnB398fL7/8MmpvsxYZGYnXXnsNM2bMgKenJ+bPnw8A2LdvH+Li4uDq6orw8HA8/fTTKC0t1V4vNzcX48aNg6urK6KiovDtt99K7v/uKYCMjAxMnToVvr6+aNGiBXr37o1Dhw5hzZo1eOWVV3Dq1CkIggBBELDmyy8BDw8I/v7YtGOHNnA5c+YMhg0bBldXV/j5+WH+/PkoqbV0etasWZgwYQJWrlyJ4OBg+Pn5YcGCBaiqqqr3/+rDDz9EdHQ0nJyc0L59e3z99dd1/o9++uknfPXVVxAEAbNmzZK9jZr7/ve//43AwEB4e3vj1VdfRXV1NV544QX4+voiLCwMq1ev1l5n2LBhWLhwYZ3buX79OpycnLBjxw7t/f/zn//EjBkz4O7ujoiICPzyyy+4fv06xo8fD3d3d8TExODo0aN1buenn35C586d4ezsjMjISLz11lt1juvzHBYUFGDu3LkICAiAp6cnhg0bhlOnTtX7f1mbSqXCnDlzEBUVBVdXV7Rv3x6rVq3SHl++fDnGjRsHAFAoFBAEAUOGDEFqaiqeeeYZ7d9DjYb+LnX9Pdc2a9Ys7N69G6tWrdLefkpKinYq548//kCvXr3g7OyMffv2ISkpCePHj0dgYCDc3d3Rp08fbN++vc5tyk2ZfvbZZ5g4cSLc3NzQtm1b/PLLL9rjd08brVmzBt7e3ti6dSs6duwId3d3jBo1CllZWdrrVFdX4+mnn4a3tzf8/Pzw4osvYubMmZgwYYLez0dTMHghsgEXc4pxIq3ArD8Xc4r17u+XX34JBwcHHD58GKtWrcLbb7+Nzz77rM45K1euRLdu3XDixAm8/PLLSEpKwqhRozBp0iScPn0a33//Pfbt21fnQ3bWrFlIT09HQkIC1q9fj//973/Izc3V2Y+SkhIMHjwYmZmZ+OWXX3Dq1Cn87W9/g1qtxkMPPYTnnnsOnTt3RlZWFrKysvDQQw9JbqO0tBQjR46Ej48Pjhw5gh9//BHbt2+XfPgnJCQgKSkJCQkJ+HLNGqxZswZr3n8fKC6WLXC3ceNGLFq0CM899xzOnj2Lxx9/HLNnz0ZCQgIAzZTAqFGjMGXKFGRlZdX58L3bzp07ce3aNezZswdvv/02li1bhvvvvx8+Pj44dOgQnnjiCTz++OPIyMgAAMydOxdr165FRUWF9ja++eYbhIaGYtiwYdq2d955BwMHDsSJEycwduxYPProo5gxYwYeeeQRHD9+HNHR0ZgxY4Y2MD127BimTJmChx9+GGfOnMHy5cvx8ssvY82aNY16Dh988EHk5ubijz/+wLFjx9CzZ08MHz4c+fn5Ov8PalOr1QgLC8OPP/6I8+fPY+nSpfj73/+OH374AQDw/PPPa4O5mud+w4YNCAsLw6uvvqptA6DX3yUg/Xu+26pVqxAbG4t58+Zpbz+8Vq7VSy+9hNdffx2JiYmIiYlBSUkJxowZgx07duDEiRMYNWoUxo0bh7S0tHof+yuvvIIpU6bg9OnTGDNmDKZPn17v/1tZWRlWrlyJr7/+Gnv27EFaWhqef/557fH//Oc/+Pbbb7F69Wrs378fRUVFpskPEo1o9+7d4v333y8GBweLAMSNGzc2eJ2EhASxR48eopOTkxgdHS2uXr26UfdZWFgoAhALCwub1mkiK3Dr1i3x/Pnz4q1bt0RRFMUJH+wTI178zaw/Ez7Yp1ffBw8eLHbs2FFUq9XathdffFHs2LGj9nJERIQ4YcKEOtebM2eOOH/+/Dpte/fuFRUKhXjr1i3x4sWLIgDx8OHD2uOJiYkiAPGdd97RttV+L/r4449FDw8PMS8vT7avy5YtE7t16yZpr30bn3zyiejj4yOWlJRoj//++++iQqEQs7OzRVEUxZkzZ4oRERFidXW1KObni+KpU+KDI0aID917rygeOSKKp05p2msZMGCAOG/evDptDz74oDhmzBjt5fHjx4szZ86U7XuNmvtWqVTatvbt24txcXHay9XV1WKLFi3EdevWiaKo+fvy8fERv//+e+05MTEx4vLly7WXIyIixEceeUR7OSsrSwQgvvzyy9q2gwcPigDErKwsURRFcdq0aeK9995bp38vvPCC2KlTJ1EURb2ew71794qenp5ieXl5nduJjo4WP/74Y1EUdT9v9VmwYIE4adIk7eWNGzeKd39ERkRE1PlbEsWG/y5rrnf337OcwYMHi4sWLarTlpCQIAIQN23a1OD1O3fuLL733ns6+wtA/Mc//qG9XFJSIgIQ//jjjzr3dfPmTVEURXH16tUiAPHKlSva63zwwQdiYGCg9nJgYKD45ptvai9XV1eLrVq1EsePHy/bx7vfu2przOe3UUdeSktL0a1bN3zwwQd6nZ+cnIyxY8di6NChOHnyJBYvXoy5c+di69atxuwmEZlY//796wy7x8bG4vLly1CpVNq23r1717nOqVOnsGbNGri7u2t/Ro4cCbVajeTkZCQmJsLBwQG9evXSXqdDhw71rsI5efIkevToAV9f3yY/lsTERHTr1q1OYuTAgQOhVqtx8eJFbVvnzp2hLCrS7pEU7OeH3Jo9kWT2SEpMTMTAgQPr3NfAgQORmJjY6D527twZCsWdt/vAwEB07dpVe1mpVMLPz087wuHi4oJHH30UX3zxBQDg+PHjOHv2rGRqKiYmps5tAqhzuzVtNber6zHVPPf6PIenTp1CSUkJ/Pz86vwtJCcna/NU9PHBBx+gV69eCAgIgLu7Oz755JMGRy3kNPR3WePuv+fGuvv6JSUleP7559GxY0d4e3vD3d0diYmJDT6G2s9ZixYt4OnpWe/opJubG6Kjo7WXg4ODtecXFhYiJycHffv21R5XKpV1nj9jMWrC7ujRozF69Gi9z//oo48QFRWlnQPt2LEj9u3bh3feeQcjR440VjcNR6UC9u4FsrKA4GAgLg5QKs3dKyKrdPcqiZKSEjz++ON4+umnJee2atUKly5davR9uLq6Nrl/jeXo6FhnjyRBEKBWq+uelJ6uSQo2cIKoo6NjncuCIMi21e7P3Llz0b17d2RkZGD16tUYNmwYIiIidN5uTTAq1yZ5nM1QUlKC4OBg7Kq9VP02fZeLf/fdd3j++efx1ltvITY2Fh4eHnjzzTdx6NChJvWnvr/LGo1Z9SPn7us///zz2LZtG1auXIk2bdrA1dUVkydPRmUDlZ4bet71OV+0gH28LGq10cGDBzFixIg6bSNHjqx3WVpFRUWdedmioiJjda9+GzYAixYBt+eMAQBhYcCqVUB8vHn6RHajfaCHubvQqD7c/SHx119/oW3btlDWE+z37NkT58+fR5s2bWSPd+jQAdXV1Th27Bj69OkDALh48WK9NStiYmLw2WefIT8/X3b0xcnJqc5okJyOHTtizZo1KC0t1X7A7N+/HwqFAu3bt79zYnW1/nskeXigY8eO2L9/P2bOnKk9vH//fnTq1Kn+2zCQrl27onfv3vj000+xdu1avP/++82+zZrHVNv+/fvRrl07KJVKvZ7Dnj17Ijs7Gw4ODoiMjGxSP/bv348BAwbg//7v/7Rt+ozayP09NPR32Rj6/L3V2L9/P2bNmoWJEycC0ARRKSkpze5DY3h5eSEwMBBHjhzBoEGDAGiSoY8fP26QOjv1sajgJTs7WzvMWCMwMBBFRUW4deuW7LekFStW4JVXXjFVF+Vt2ABMnixNusvM1LSvX88Ahozq9UkxDZ9kQdLS0vDss8/i8ccfx/Hjx/Hee+9JVp3c7cUXX0T//v2xcOFCzJ07Fy1atMD58+exbds2vP/++2jfvj1GjRqFxx9/HB9++CEcHBywePHiekdXpk6din//+9+YMGECVqxYgeDgYJw4cQIhISGIjY1FZGQkkpOTcfLkSYSFhcHDwwPOzs51bmP69OlYtmwZZs6cieXLl+P69et46qmn8Oijj9Z9P9N39OF2gPPCCy9gypQp6NGjB0aMGIFff/0VGzZskKwoMaa5c+di4cKFaNGihfZDsjmee+459OnTB6+99hoeeughHDx4EO+//z7+97//AYBez+GIESMQGxuLCRMm4I033kC7du1w7do1/P7775g4caJe0zNt27bFV199ha1btyIqKgpff/01jhw5gqioqHqvFxkZiT179uDhhx+Gs7Mz/P39G/y7bIzIyEgcOnQIKSkpcHd3r3c6s23bttiwYQPGjRsHQRDw8ssvG3SES19PPfUUVqxYgTZt2qBDhw547733cPPmTYMvL7+b1a82WrJkCQoLC7U/6Q1tXW9oKpVmxEVuGK2mbfFizXlEBACYMWMGbt26hb59+2LBggVYtGiR7PLR2mJiYrB7925cunQJcXFx6NGjB5YuXYqQkBDtOatXr0ZISAgGDx6M+Ph4zJ8/Hy1bttR5m05OTvjzzz/RsmVLjBkzBl27dsXrr7+uHQGaNGkSRo0ahaFDhyIgIADr1q2T3Iabmxu2bt2K/Px89OnTB5MnT8bw4cOlH1wKPd9ub9f/mDBhAlatWoWVK1eic+fO+Pjjj7F69WoMGTJEv9sxgKlTp8LBwQFTp06Fi4tLs2+vZ8+e+OGHH/Ddd9+hS5cuWLp0KV599dU6uTQNPYeCIGDz5s0YNGgQZs+ejXbt2uHhhx9Gamqq5MuvLo8//jji4+Px0EMPoV+/fsjLy6szCqPLq6++ipSUFERHR2trqOjzd6mv559/HkqlEp06dUJAQEC9+Stvv/02fHx8MGDAAIwbNw4jR45Ez549G32fzfXiiy9i6tSpmDFjBmJjY7U5P4b4e6mPIJpo8koQBGzcuLHetd+DBg1Cz54966xLX716NRYvXozCwkK97qeoqAheXl4oLCyEp6dnM3uth127gKFDGz4vIQEYMoR5MWQQ5eXlSE5ORlRUlNHfJAzN0FVErYYoAmfOQKysxE1XT+S7ekKtUMCpugrOqko4V1fBWRDh3L4tHJSW8b2y5oP6yJEjZvlgJOujVqvRsWNHTJkyBa+99prkeH3vXY35/LaoaaPY2Fhs3ry5Ttu2bdsQGxtrph7poVaxngbPY14Mkf26vUdSbs5N5LjfmQ4od3ACUCsZM6sIDgoFnB0UcHZUwNlBCRdHBVwdlSYLaqqqqpCXl4d//OMf6N+/PwMX0ik1NRV//vknBg8ejIqKCrz//vtITk7GtGnTjHq/Rg1eSkpKcOXKFe3lmrljX19ftGrVCkuWLEFmZia++uorAMATTzyB999/H3/729/w2GOPYefOnfjhhx/w+++/G7ObzRMcrN95ly8Dy5czL4bIjhU4t0COe8O5ANVqNaor1Si9K7/XUakJYlwclXB1UsDFUQknpcLg+QX79+/H0KFD0a5dO6xfv96gt022RaFQYM2aNXj++echiiK6dOmC7du3o2PHjka9X6NOG+3atQtDZaZUZs6ciTVr1mDWrFna8se1r/PMM8/g/PnzCAsLw8svv6yz7LUck08bqVRAZKQmCJH7rxQEIDRU8+/aIy53nxMWBiQncwqJ9GLN00b26lZlNZKul0Jt4LdcpSDcDmaUcHNSws3JAY5KwegJk0RNYahpI5PlvJiKyYMX4M5qI6BuAFPz5rF8ObBsWcO3U5MXQ9QABi/WpUqlxpXcElSpTLMaxEGpgJujEm7OSrg5OsDVSQmlgsEMmZ+hghfLyAqzdvHxmmmfmhGWGmFhmnZ9d3zVN3+GiKyGWhSRmlemM3BRGmGEpFqlRlF5FbILy3H1RgnOXyvEpZxiZBXeQrWJAigiY7KohF2rFh8PjB8vv5JIphKkLH3zZxqDq5tsmo0NnNocURSRefMWyiqrZY/7uTsjxMsF1WoRFdVqVFSpNL+r1aioVqGy2jCBhgigvEqF8ioVisur0SbAHQqOxJAZGOo9i8GLISmV8tM+cXGaUZj68mLCwjTnGRJXN9msmpLdZWVlJi1xT41zo6QSN8vkq+q6Ozsg2MtFU6pfKcBRqYC7c923ZLVaRHm1Jui4VaVGeaUKt6pUzcqbKa9SIavwFkJ93Jp8G0RNVbN9QX3VtPXB4MUUlEpNwDB5siZQkcuLefddw46IsOqvTVMqlfD29tZukObm5sYETQtTWlGFrJu3IBdmOCoVaOnmhMpaW5voogDgpgTclALg4gBRVKKqWo3y6jujNOVVaqgaUV31RmElnAUV3F0cGz6ZyEDUajWuX78ONzc3ODg0L/xgwq4pyY2EhIdrAhdDBhI1K6C4usmmiaKI7OzsevfuIfOoUqlxvbgCapl3V4UABHg4w9HANVuqVWpUqtSorBZRqVKjSqWWHeitoRSAlp4uTOQlk1IoFIiKioLT7UrStXG1kaUGL4BpclAaW/WXrJpKpUJVVZW5u0G3Fd+qwsJ1J5Bxs0x6UAD+Ob4LYqP9jd6PiioVrlwvQWJWMVbvT0Z5lXSLkt6RvlgxsSvzX8hknJycoNCxVYbVVti1C7ryYgypMVV/yeoplcpmzx+TYVSr1Hj221M4lFYse/zFUR0wtHOYSfri4gL08miBXq0D4ejkhBd/OiM5J/PMdXSPzMbsgfVvSEhkabhUupH2Xr5usloNTabvqiVjrG4ismP/3XkFey/fkD02sUconhjc2sQ90pjSOxyjOgfJHlvxxwVcyC4ycY+ImofBi57S88swZ80RPPr5YXx1MNXc3alfzeomXQmct/dYMfjqJiI7VlBWiU/2JMke6xbujRXxXc2WVC0IAlbEd0Wgp7PkWGW1Gou/Oyk7rURkqRi8NKC8SoVV2y9jxNu7seOCZmXHO9suIaeo3Mw9q0fN6iZAGsAYa3UTkZ1bdzgd5VXSUdlAT2d88mgvuDia9/Xm08IJbz3YXfbYhexivLHlomk7RNQMDF4asHDtCbyz/RIqahWLKqmoxr83J5qxV3poqOovl0kTGUy1So2vD6bIHvvwkV4I9LSMLRzuaeuPeXHy+S1f7E/G7kvXTdwjoqZh8NKAuTpe6D+fvIYDSfJz2yajUmlWFq1bp/mtumvYNz4eSEnRrCpau1bzOzmZgQuRgW09l4NrhdLR2Hv8FOgZalmrHp8f2R4dg+X79PyPp5BX0nDtGSJzY/DSgP6t/TChe4jssaU/nzNf8u6GDZpaLkOHAtOmaX5HRmraa6tZ3TR1quY3p4qIDG71/mTZ9tkfL5N/XZqRs4MS/324O5wdpG//14sr8OJPZ7jtBFk8Bi96+PvYjvBwlq4qv5Jbgi/2yb9pGVVN9dy7i9DVVM+1oDdKIlt3JqMQR1NvStoj869haNJRi3xdtg30wP8b21H22PbEHKw7nG7iHhE1DoMXPbTcthnP7F8re2zVjsvIKrxlus6oVJoqvXLfjGraFi+WTiERkVGsPiD/BWbm8V+hgGixr8tH+0dgaPsA2WOv/nYOKTdKTdwjIv0xeGnI7VGOGTu/QYdc6ZtUWaUK//zdhMm7e/fqLvsPaN4o09M15xGRUV0vrsBvp6TFHt0ryjD5zPY7DeZ+XcrkxwmCgDcmd4O/u7RMe3mVGkt/OcfpI7JYDF7qU2uUw0FU459//k/2tN9PZ2GfjsJUBsfquUQW49tDqaiUyXt78Mw2eFTKjMia43VZT35cgIcz3pzcTfZqey5dx5az2SbtKpG+GLzU565Rjt6ZiZh8ZpvsqUt/PouKahMMCbN6LpFFqKhW4Zu/0iTtgqjGrGO/yl/J1K9LPfLjhnZoien9Wsle/ZVfz6O0otoEHSVqHAYv9ZH5lvTSrjXwLC+RtF+9UYrP9pogeZfVc4kswu+ns3BDZlnx8CtHEFFw14iFOV6XjciP+9uoDvB3l1bfzS4qx393XDZuP4magMFLfWS+JfmXFeKFPV/Jnv7ezsvILDBy8i6r5xKZnSiKWL0/RfbY7GO/1G0w1+uyEflxXq6O+IeO1Uef70vGxWz5jSaJzIXBS310jHJMO7kFXbKvSE4vr1Lj1V/PGb9frJ5LZFbHUm/iTGahpL29qxoDVHl1G831umxkftz47iHo39pXcrhaLeLlTWeZvEsWhcFLfXSMcihFNV7b9qHsVbaey0HCxVzj943Vc4nMRteoy6zR3SBYyuuykflxgiDgtfFd4KCQTkkfTsnHhuOZhuwdUbMweGmIjlGOHsoyPBwgn6C7/JdzptmhldVziUzuWsEtbDknXYXj7eaICd1DLed12YT8uLaBHpgb11r29BV/JKKwrMoYPSVqNAYv+tAxyvG3J0bB281RcnpqXhk+2XPV9P0kIqP7+q9UqNTSKZSpfVvB1cmCvkA0MT/u6eFtEOIl3UjyRkklVv7JnafJMjB40ZfMtynfFk7428gOsqd/kHAF6fllJu0iERnXrUoV1h2WLo9WKgQ82j/CDD1qQBPy49ycHLDsgc6yN/fNoVSczigwQkeJGofBSzM93Ccc3cK9Je0V1Wos/8UEybtEZDKbTmaiQGbqZFSXIIR4uxr2zhraNV5fTciPu69TIIZ1aClpF0XgH5vOyo48EZkSg5dmUigEvDa+s+y08o4Ludh+Psf0nSIig9Msj5av5fTYwEjD3pm+u8brq5F5OIIgYPm4zrI7T5/OKJQdfSIyJQYvBhAT5q2zQuXyX02UvEtERnUgKQ+XcqQFKmPCvNCzlY/h7shCdo1v5eeGBUPbyB57Y8sF2QJ9RKbC4MVAnr+vPXxbSDc4y7h5C/9LkNaEISLromvUZfbASAi6VvQ0loXtGj9/UGtE+beQtBeVV2PF5gsm6QORHAYvBuLt5oSXRssn7360+yq3lyeyYrnF5dhxQVq/KcDDGWO7hhjujsy5a7xMjo2LoxKv6Eje/el4Bg4n5xu+H0R6YPBiQJN7hqFnK29Je6VKjWXcXp7Iah1NuSk7GPJIvwg4yeSFNJm5do2vJ8dmULsAjI2RL3j3z9/PQ83kXTIDBi8GpFAIeG1CF8gUqMTuS9ex9RyTd4ms0Skdy4Mf6G7AURfAPLvG65Fj8/LYTmghU8PmdEYhfjtj4ECKSA8MXgysc4gXZsRGyh579ddzKKvk9vJE1uZ0unQfIy9XR0T6uRn2jky9a7yeOTZB7o5YPKKd7E28seUCKqq5KIFMi8GLETxzbzvZ7eWvFZbj/Z1M3iWyJmq1KLsJY0yYl+ESdWuYetf4RuTYzBgQgTAfaS2bjJu38PXBVMP0h0hPDF6MwMvVEX8fI5+8++neq7iSK11uSUSW6eqNEpRUSEdMu4V5G+cOTblrfCNybJwdlHhhZHvZw+/tvMJ9j8ikGLwYycQeoegbKd1evkolYjmTd4msximZKSNAM/JiNKbaNb6ROTbjYkJkH3fhrSr8b9ftUWVDVQYmqgeDFyMRBAGvTugMpUz27r4rN/A7k9yIrIKuvXzktgUxKFPsTt3IHBuFQtBZEmL1gRRkrDNwZWAiHRi8GFGHIE/MHhApe+y1387LDkUTkWU5lSEdeQn0dEagp3TnZavThBybAdH+svseVVar8dbaA2avDEz2gcGLkS0a0RYtPaTJuzlFFfjvjstm6JEMDvMSyaqsVuP8tSJJu9HyXcyhCTk2L43uIFsSYmPnoTjbsnXdRjNUBibbx+DFyDxcHPGP+zvJHvtiXzIu5RSbuEd3MfQGcEQ25GJ2MSpVakm70aeMTK2ROTbtAj0wpXe47LEVQx+DJKPPmJWByS4xeDGBcTHBiG3tJ2mvVot4edNZ8yXvWsgGcESWSldxOqMm65pLI3Nsnrm3HVwdpefsj+yO3VE95a9k6MrAZLcYvJiAIAh4dXxnOMiMsx5Kzscvp66ZvlMWtgEckSXSlawbE+pt0n5YokBPF8yLi5I99vqQ2VAJMh8vhqwMTHaNwYuJtA30wBwdL/R//p6IonIT10gw5wZwRFZCbpl0lH8LeLk5mqE3lmf+4Gj4uztJ2i+0jMJPXYbdaTB0ZWCyewxeTOjpYW0R7CVdoXC9uALvbjNx8q65NoAjshJlldW4nCvNSbPJKaMmcnd2wCId2wa8HfcIbjk4y69a4iIBaiYGLybUwtkBL+tI3v3yYAoSs6SrGozGHBvAEVmRs5lFkNswOcaWVhoZwMN9wtHav4WkPdvDH1/0fkC6aomLBMgAGLyY2OguQYhr6y9pV5k6edfUG8ARWRmdxek48lKHo1KBv42SL1z34bCZyDt7sW7gwkUCZAAMXkxMEAS88kBnOCml//VHU2/ip+OZpumIqTeAI7IyJ9MLJG1KhYDOIQxe7jaycyB6R/hI2ktUwHu7rmoucJEAGRCDFzNoHeCO+YNayx5bsTkRhbdMlLxryg3giKzMaZnKuu0CPeDqxID+boIgYMmYjrLH1h1OQ15JBRcJkEExeDGTBUPbINRbur18Xmkl3vrzouk6YqoN4IisyM3SSqTll0naOWWkW68IH4zuEiRpr6hW46uDqVwkQAbF4MVMXJ2UWDZOPnn3m79ScTZTfidbozDFBnBEVuS0jtcfk3Xr99x98iuPvjqYglstpYGNLC4SID0weDGjezsFYmj7AEm7WgT+seks1HJLHYjI6E7J5LsAXCbdkDYtPTBcZtPGm2VV+NElgosEyGAYvJiRIAhY/kBnODlIn4aT6QX48Vi6GXqlA+sykB2RW2nk7KBA+yAP03fGyjw+OFq2/bP9qVC9y0UCZBgMXswswq8FntTxYn/9jwsoKKs0cY9ksC4D2RFRFHFKJlm3c4gnHGVWCVJdfSJ90F1m48q0/DJsaRvLRQJkEHwlWoAnh0Sjla+bpP1mWRXe2GrC5F05rMtAdia7qBzXiysk7cx30Y8gCHhcx2rKT/YkQZw4kYsEqNkYvFgAF0cllj8gn7y77nCazvl3o2NdBrJDul5v3cKZ76Kv+zoHIdJP+oXsVEYh/rqaz0UC1GwMXizEsA6BuLdToKRdFIGXfz4LlTmSd1mXgeyQ3JQRAHTjyIvelAoBc+J0j74QNReDFwuy9P5OcHGUPiWnMwrx3ZE003eIdRnIDskl63q4OCDST7p/D+n2YK8w+LaQ7jidcPE6LuVIN7wkagwGLxYk3NcNC4e2kT325taLyC81cfIuN28kO6NWi7KVdWPCvKBQ6FjiS7JcHJWYGRspe+yTPVdN2xmyOQxeLMy8Qa0RJbNDa0FZFd7cesG0neHmjWRnkvNKUVxeLWlnsm7TPBobITua/PPJTGQXlpuhR2QrGLxYGGcHJZY/0Fn22HdH0nEi7abpOsPNG8nOcCdpw/Jt4YQpvcMl7VUqEav3J5uhR2QrGLxYoMHtAjCqs7SUtigCS38+Z9rkXW7eSHbkVLqOZF2ZuiWkn7n3tIbcjNvaQ2koLjfRJrRkc0wSvHzwwQeIjIyEi4sL+vXrh8OHD+s8d82aNRAEoc6Pi4uLKbppUV4eJ5+8eybTDMm73LyR7ITcyEuAhzOCPO3vPchQWvm5YXQXaV5ccUU11h02w0IEsglGD16+//57PPvss1i2bBmOHz+Obt26YeTIkcjNzdV5HU9PT2RlZWl/UlNTjd1NixPq7YqnhrWVPfbGFjMk77IuA9m4KpUa564VSdq7hXlB0JX3RXqZr6No3Rf7UlBZrTZxb8gWGD14efvttzFv3jzMnj0bnTp1wkcffQQ3Nzd88cUXOq8jCAKCgoK0P4GB0von9mBuXJRs8m7hrSq8scXEybtENu5idjEqZD5ImazbfN3CvdG/ta+kPbuoHL+eumaGHpG1M2rwUllZiWPHjmHEiBF37lChwIgRI3Dw4EGd1yspKUFERATCw8Mxfvx4nDt3Tue5FRUVKCoqqvNjK+pL3v3+qImTd4lsnNwSaYD5Loby+CD5Pdw+2XMVolwVb6J6GDV4uXHjBlQqlWTkJDAwENnZ2bLXad++Pb744gv8/PPP+Oabb6BWqzFgwABk6Kj0umLFCnh5eWl/wsOlme3WzKKSd4lsmK6VRjGhXGlkCEPaB6BdoLuk/WJOMXZdum6GHpE1s7jVRrGxsZgxYwa6d++OwYMHY8OGDQgICMDHH38se/6SJUtQWFio/UlPTzdxj42vvuRdJrwRGcZJmT2NWvm6wUemSiw1niAImKdry4DdLFpHjWPU4MXf3x9KpRI5OTl12nNychAUJB1NkOPo6IgePXrgypUrssednZ3h6elZ58fW1Je8a5bKu0Q25lalCpdzSyTtMazvYlDju4ci0NNZ0n7wah6Sb5SaoUdkrYwavDg5OaFXr17YsWOHtk2tVmPHjh2IjY3V6zZUKhXOnDmDYDsvQT83LgqtmbxLZBTnrhXKTsF2Z76LQTk5KPDYwCjZY5tOZJq4N2TNjD5t9Oyzz+LTTz/Fl19+icTERDz55JMoLS3F7NmzAQAzZszAkiVLtOe/+uqr+PPPP3H16lUcP34cjzzyCFJTUzF37lxjd9WiNVR59ziTd4maTNdO0lxpZHgP9QmHo1K69Pznk5lM3CW9GT14eeihh7By5UosXboU3bt3x8mTJ7FlyxZtEm9aWhqyau1KfPPmTcybNw8dO3bEmDFjUFRUhAMHDqBTp07G7qrFG9QuAKO7yE+3Lf35LJN3iZpILllXIQBdQm1vGtrcvN2cMLhdS0l7Sl6ZziCS6G6CaGOhblFREby8vFBYWGiT+S+ZBbcw4q3duFWlkhx7e0o3xPcMM0OviKzbkDcTkJJXVqetfaAHtj4zyEw9sm2/nb6GhWtPSNpnD4zEsnHyI8xk+xrz+W1xq42ofqHerlg4rI3ssfd3XkG1itUqiepQqYBdu4B16zS/VXUD/8KyKkngAjBZ15hGdAyEu7ODpP3XU1l8DyO9MHixQroq7169UYpfT7NaJZHWhg1AZCQwdCgwbZrmd2Skpv22U7p2kmayrtG4OCoxUqZ+1Y2SChxIyjNDj8jaMHixQs4OSiweIb90+r0dV5j7QgRoApTJk4G7C1xmZmrabwcwOy/I77PWjcm6RjWhR4hs+6aTXHVEDWPwYqXujwlB6wAdoy/cK4TsnUoFLFqkKUV9t5q2xYuhrqrGH2ezJKd4uDigQ7CHkTtp32Jb+8HfXVrzZevZbNyqlOb0EdXG4MVKKRUCntZRuO6/Oy9z9IXs29690hGX2kQRSE/Hsd92I6eoQnL4vk5BcFTy7dGYHJQKjOsmrd9VWqnC9sQcmWsQ3cFXpxUb1y1EtnDd1eul+I25L2TPsqSjKXJ+T5Jfmjs2Rr8K4NQ8E7qHyrb/zKkjagCDFyumVAh4arj8yqP/7uDoC9kxPSpyqyHgj2IXSbuHiwPuaRNgjF7RXWLCvGQXH+y6eB03ue0J1YPBi5UbFxMi++JP4ugL2bO4OCAsDBCklVwBAIKAYz0HI6dCGuDf1ykITg58azQFQRAwvrs0cbdaLeL3M/qNnpF94ivUyjkoFXhKR92X93Zy5RHZKaUSWLVK8++7A5jbl39/ZLHsVe+Pse991ExN19TRLyf55Yt0Y/BiAx7oFoJIPzdJ+5XcEmzmtxeyV/HxwPr1QOhdH45hYVD/uB6by6Qjlp4uDhjYxt9EHSQAiPRvIVtT53BKPjJuSosHEgEMXmyCZvRFx8qjHZeh5ugL2av4eCAlBUhIANau1fxOTsbRnkOQWyyzyqgzp4zMYYLM1BEA/MKyD6QDX6U2Ynx3+dGXy7kl2CxTx4LIbiiVwJAhwNSpmt9KJX7XkQ82llNGZnF/TAiUCpmdpk8weCF5DF5shINSgYUcfSFqkEot4o+z2ZJ2TxcHDIzmlJE5BHg4y07XXcwpRmJWkRl6RJaOwYsNmdA9BBEyoy+Xckpk36yJ7NHRlHzZKaORnDIyK11TR9wugOTwlWpDHJQKLBgqv/Jo1Y5LHH0hAnQuwR3DKSOzuq9zEFwcpR9Jv568xvcukmDwYmMm9ghFK1/50Zct5zj6QvZN15SRl6sjp4zMzN3ZAfd2klY2vlZYjsOf/wjs2qXZs4oIDF5sjqNSgYU6Rl+Y+0L27khKPq7LrTLqFMgpIwswvpv81NHPP+0Bhg4FIiO1u4GTfeOr1QZN7BmKcF9XSfuF7GJs5egL2TFddY+4ysgyDGoXAG83R0n75vb3oFLhAGRmApMnM4AhBi+2qL7Rl//tSoIocvSF7I9KLWLzGR1TRixMZxGcHBQY20U6dVTo6oFdrXtpdgMHgMWLOYVk5xi82Kj4nmEI85GOvpzJLMSBpDwz9IjIvA4n5+NGidwqo0A4KvlWaCkmCNdl23/uPETzD1EE0tOBvXtN1ymyOHzF2ihHpQJPDomWPfbhriQT94bI/HRPGcnnWZB59LqVi9DCHEn79ui+KHaq9YUsi8U37RmDFxs2qWcY/N2dJe37rtzAmYxCM/SIyDx0rTLydnPEgGg/M/TISqlUmlU/69YZbfWPIiQY48/vlrRXODpje5t+dxqCmadkzxi82DAXRyUeuydS9thHuzn6QvZD55RRpyBOGelrwwbNap+hQ4Fp04y3+icuDhPyEmUPbWk3QLMreHg4EBdn2Pslq8JXrY2b3i8C7s4OkvY/zmYh+UapGXpEZHq/n5HfI4eF6fS0YYNmlU9GRt12Y6z+USrR7tWX0OZGmuTQ7ta9UOboDLz7rmbPKrJbDF5snJerI6b3byVpV4vAJ3uumqFHRKalUovYwimjplOpgEWL7qz0qc1Yq3/i4zFaJhep3NEZuz9Yp9ktnOwagxc7MGdgFJxkhsZ/OpaB3KJyM/SIyHQOJefhRkmlpJ1TRnrau1c64lKbkVb/jJw0RLZ9i3tE3QYT5OGQ5eEr1w609HTBpF6hkvZKlRpf7E8xfYeITOj30yxM1yz6ruox8OqfziGessU2dybmoqL6doBiqjwcsjgMXuzEvLjWEARp+7d/paKovMr0HSIygWqVWraqtI+bI2I5ZaQffVf1GHj1jyAIGNVZWrCuuKIaB67kmTYPhywOgxc70TrAHaNlKlcWV1Tj27+kiXFEtkCzykhmyqgzp4z0FhcHhIVB9tsPYNTVP6O6yAdEf5y5Zvo8HLIofPXakScGyxet+2J/Msqr+CIn2yNX2wXglFGjKJXAqlWaf98dwNRcNtLqnx7h3mjpIa1Vte10Jqoz5VeQAWAVXjvA4MWOxIR5Y2Ab6VD59eIKbDieaYYeERmPKIrYdl5aqdXHzRGxrTll1Cjx8cD69UDoXblzYWGadiOt/lEoBIyUmTq6WQUcDu/S8A2wCq/NYvBiZ54cLL9h4yd7kqBSc8NGsh1nMguRLbOabkTHQDhwyqjx4uOBlBQgIQFYu1bzOznZ6MuW5aa7gdsF6xrCKrw2i69gOzOwjR+6hHpK2lPyymRrYRBZq+0yoy4AcG+nQBP3xIYolcCQIcDUqZrfJigU1zfKFz5ujpL2rR3vgVrQ8RHGKrw2j8GLnREEQefoy0e7kyDKJcARWaE/ZYIXZwcF7mnrb4beUFM5KBWyAWeOmzdOhLQzeR4OWQYGL3ZoVJcgRPq5SdrPZBZi/5U8M/SIyLDS88twIbtY0h7X1h9uTtLtMsiyjdIxdbT1+ddNnodDloHBix1SKgTMHyS/8ogbNpItkEvUBThlZK0GtvGX36Ot0gNicrLJ83DI/Bi82Kn4nqHwd5cuQdx35QbOZBSaoUdEd2lG2Xe54EUQgGEdGLxYI2cHJYZ1aClpT8+/hfO5pSbPwyHzY/Bip1wclZhzT5TssQ93XzFxb4ju0oyy7wVllTicki9p79nKBwEyNUPIOuhcdcSFBnaJwYsdm96/FTzkhmLPZiP5RqkZekSEZpd9T7iYK7vsn1NG1m1w+wA4O0g/shi82CcGL3bM08UR0/tHSNpFUVP3hcjkVKpml31nvottcnNywOB2AZL2y7kluJJbYoYekTkxeLFzjw2MhJNMwa6fjmUiV6bAF5FR7d0rHXGprYGy7xXVKuy+eF3S3jqgBaID3A3VSzKT0V11rDqS2XyTbBuDFzvX0tMFk3qFSdorVWp8vj/ZDD0iu6ZvOXcd5x1MykNppXRUhqMutmFYh0A4KqUbRHLqyP4weCE8Pqg1FDIbxq79Kw1F5VWm7xDZL33Lues4T+eUUUcGL7bAy9URA6KlRQbPZBYiPb/MDD0ic2HwQoj0b4HRMlvPF1dU45u/Us3QI7JbcXGaImN3V02tUU/Zd7VaxPZEafDi18IJPVr51H+/zViWTaals2Adp47sCoMXAgA8MVi+aN0X+1JQXsU3cjIRpRJYtUrz70aWfT+TWYicogpJ+/COLaGUG1qs0Yxl2WR693YKlB0p5tSRfWHwQgCArmFeuKeNdDj2RkkFfjpeTwIlkaHFx2vKuzey7LvuVUby39QBNHtZNpmev7sz+kT6StqPpd3kIgM7wuCFtJ4cIj/68smeq7J1M4iMJj4eSElpVNl3ueDFxVEhG5QDMMiybDIPuYJ1oii/GSfZJgYvpDUg2g9dQ70k7al5ZfjjrJ6rQIgMRanUu+x7Wl4ZLubIbcQYAFcnHddr5rJsMp+RrLZr9xi8kJYgCDpHXz7clQRR7hsqkQXYJpOoCzSwRLqZy7LJfIK9XNE93FvSfvBqHgrKKk3fITI5Bi9Ux8jOQYjybyFpP3etCPuu3DBDj4gatu289Bu3QgCGy2zmp9XMZdlkXnKrjlRqUWfuE9kWBi9Uh1IhYP6g1rLHPtzFLQPI8hSUVeJIyk1Je68IH/jJ7Jyu1Yxl2WR+ozrLTx1tPsORMnvA4IUkJvYIld1990BSHk6lF5i+Q0T12HlBfiPGEQ0VpmvGsmwyv0j/FugQ5CFp33flBgpvsbimrWPwQhIujkrMuSdK9thHuxsYfWGxLzKxZm3E2MRl2WQZxnaVTulVqTh1ZA8YvJCsaf1awcPZQdK+5Vw2rl7XsYMri32RiZVXqbD7knQjxuiAFmit70aMTViWTZZhTIx8PhKnjmwfgxeS5eniiEdiIyTtoqip+yLBYl9kBgeT8lAmuxFjPYXp5DRiWTZZjugAd9mpo72Xr3NfNhvH4IV0mj0wEk4O0j+RDcczkVO7kiWLfZGZ6CpKxl2k7ccYHVNH2zl1ZNMYvJBOLT1cMLlXmKS9UqXGF/uS7zSw2BeZgVotYodMfRd/d2f0kKkBQrZJLngBOHVk6xi8UL3mx7WW3QTt20NpKK4ZlmWxLzKD05mFyC2WbsQ4omNLKOrbiJFsSpuW7mgXKM1v2nPpBqeObBiDF6pXpH8LjJb5ZlNSUY3vj6RrLrDYF5mBXGE6gFNG9khu9KVSpZYdmSPbwOCFGvTkYPktA1bvT0G1Ss1iX2Ryoihi8xlp8OLqqMRAXRsxks2SWzINAL+f5l5HtsokwcsHH3yAyMhIuLi4oF+/fjh8+HC95//444/o0KEDXFxc0LVrV2zevNkU3SQduoR6oV+UdAv6zIJb2Houh8W+yOROpBcg+UappD2urT9cHPl3Zm/aBnqgbUuZqaPL1+9Mb5NNMXrw8v333+PZZ5/FsmXLcPz4cXTr1g0jR45Ebm6u7PkHDhzA1KlTMWfOHJw4cQITJkzAhAkTcPbsWWN3leoxN05+y4DP9t1eNs1iX2RCG49nyrY/0D3ExD0hSyE7dVStxo5E+c8asm6CaOStgvv164c+ffrg/fffBwCo1WqEh4fjqaeewksvvSQ5/6GHHkJpaSl+++03bVv//v3RvXt3fPTRRw3eX1FREby8vFBYWAhPT0/DPRA7p1aLGPbWLqTklUmO/fTkAPSK8NFcUKk0q4qysjQ5LnFxHHEhg6qsVqPvv7ejoKzuN2oPZwcc+ccIjrzYqUs5xbjvnT2S9ns7BeLTGb3N0CNqrMZ8fht15KWyshLHjh3DiBEj7tyhQoERI0bg4MGDstc5ePBgnfMBYOTIkTrPr6ioQFFRUZ0fMjyFQtC5ZcDn+2oVrWOxLzKyXRdzJYELAIyNCWbgYsfaBXqgjczU0e5LnDqyRUYNXm7cuAGVSoXAwLrZ/4GBgcjOlk+kys7ObtT5K1asgJeXl/YnPDzcMJ0niUm9wuDl6ihp33I2G+n50hEZImPYeEJ+ymhij1DZdrIfuqaOdl7g1JGtsfrVRkuWLEFhYaH2Jz093dxdslluTg6Y3q+VpF0tAmsOpJi+Q2R3CsuqZHMYQr1d0SdSmlRO9kX3qiPWmLI1Rg1e/P39oVQqkZNTd619Tk4OgoLk9x4JCgpq1PnOzs7w9PSs80PGM3NAJByV0iXR3x9JZ0EoMrrfzlxDpUotaZ/YI5SF6QjtAt0RHdBC0r7r0nWUVFSboUdkLEYNXpycnNCrVy/s2LFD26ZWq7Fjxw7ExsbKXic2NrbO+QCwbds2neeTaQV6uuD+GOmKjpKKavxwhKNeZFy6VhlN7MkpIwIEQZAdfdGsOmLBOlti9GmjZ599Fp9++im+/PJLJCYm4sknn0RpaSlmz54NAJgxYwaWLFmiPX/RokXYsmUL3nrrLVy4cAHLly/H0aNHsXDhQmN3lfSkK3FXW7SOyAjS8spwNPWmpL1buDeiA6SJmmSfxsRwryN7YPTg5aGHHsLKlSuxdOlSdO/eHSdPnsSWLVu0SblpaWnIqrXnzYABA7B27Vp88skn6NatG9avX49NmzahS5cuxu4q6alLqBf6t5YvWrflHCtaknHoStSNZ6Iu1dI+0AOt/WWmji5eRymnjmyG0eu8mBrrvJjG9vM5mPvVUUl793BvbFow0Aw9IlsmiiKGrpTWGXJQCDj8/0bAt4WTmXpGlmjl1ot4P+GKpP2/U3vggW4sZGipLKbOC9muYR1aIkrm283J9AIckxnaJ2qO42kFsgUSh7QPYOBCEnJLpgFgM1cd2QwGL9QkCoWAx/QpWkdkABtPZMi2T+wRZuKekDXoGOwh++Uq4WIup45sBIMXarJJPUPh7caidWRcldVq/CbzjdnDxQHDO7Y0Q4/I0gmCgDFdpeU1KliwzmYweKEmq69o3er9KabvENmkBB3bAdzP7QCoHjqnjrjqyCYweKFmmRGrq2hdGovWkUHorO3CKSOqR6dgT0T6uUnaEy7moqySU0fWjsELNUugpwvGyRStK61U4fvDLFpHzVNQVokdF6TFxcJ8XNG7ZidzIhmaqSPp6Et5FaeObAGDF2o2XYm7q/cns2gdNctvp7NQpZJWc+B2AKQPTh3ZLgYv1GxdQr0Q29pP0n6tsBxbz7EkNzUdd5Cm5ugc4okImamjnRc4dWTtGLyQQcyN0z36QtQUqXmlsjWDuod7o3XNdgAqFbBrF7Bunea3SmXSPpJlq2/qKOHCdTP0iAyFwQsZxND28kXrjqbexJmMQjP0iKydzu0AajZh3LABiIwEhg4Fpk3T/I6M1LQT3Sa3USPAqSNrx+CFDEKhEDAzNkL2GEdfqLFEUZQNXhwUgmZX8w0bgMmTgYy7itdlZmraGcDQbZ3/2oFWxdJRlp3nrnHqyIoxeCGDmdw7HB7ODpL2X09fQ25RuRl6RNbqeNpNpMpuB9ASvi5KYNEiQG5btpq2xYs5hUTAhg0QHpyMMed2SQ7dUgtI+Oo30/eJDILBCxmMu7MDHuwdLmmvUon45lCaGXpE1mqDjtouk3qGAnv3SkdcahNFID1dcx7ZL5VKG+Tef2Gf7Cmbd5xmkGulGLyQQc0aEAlBZgXr2kOpqKjmmwQ1TKUWZfMRPF0cMKxjSyBLz1wFfc8j21QryO2ck4RWN6V/DzuDO+PWrj2m7hkZAIMXMqhWfm4Y0TFQ0n6jpBK/nuKHCTXsYnYxbspsBzA2JgTODkogWD4BU0Lf88g21QpeBQBjLkpHX245uSDh0g0TdooMhcELGdzsgZGy7av3J0OUy1MgquVwcp5s+72dbm/CGBcHhIVBdogP0LSHh2vOI/t1V/A6VsfU0e8VHqboDRkYgxcyuNjWfugQJH1DOHetCEdSpHU7iGo7nJIvaRMEoFeEr+aCUgmsWnXnwN0nAsC772rOI/t1V5DbJScJ4QXZktN25gG3KjmlbW0YvJDBCYJQ7+gLkS6iKOJwsjR46RjkCS9XxzsN8fHA+vVA6F2VdsPCNO3x8UbuKVm8u4JcAcDYC9Ik7ltVKiRc5F5H1obBCxnF+O6h8HFzlLRvPZeNjJvSJbBEAHD1RilulFRK2vtG+UpPjo8HUlKAhARg7VrN7+RkBi50x11Brs6pIxasszoMXsgoXByVmNavlaRdLQJfH0w1Q4/IGsiNugBAP7ngBdB8ux4yBJg6VfObU0V0t1pBbpe3X0O4qzRXamdiLqeOrAyDFzKaR/tHwkFm5991h9NY2ZJk6Qpe+ugKXoj0cTvIFaZNxZi+0n3YOHVkfRi8kNEEeblgtMy+IkXl1fhJRxEysm9ywUt0QAv4uzuboTdki3TtdcSpI+vC4IWMSlfi7ppt56Bey52A6Y6Mm2XILLglae8b5WeG3pCt6hrqhXBfV0k7p46sC4MXMqqerXzQLdxb0p5UKmLvP1ZyJ2DSOiKzRBqoJ9+FqAkEQcAYmdGXW1Uq7OLUkdVg8EJG95iuZdO9HtD8gzsBE3Tnu8iuNCJqBk4dWT8GL2R0o7sEo6WHNGdhV3RvJPmGcidgAgAckglewnxcEeItHeInao6uoV4I85H+Xe3g1JHVYPBCRufkoMCMILXssS97jtP8gzsB27XrxRW4er1U0s5RFzIGQRAwNoZTR9aMwQuZxFSnfDhVS4uPre86HIXOLe40cCdgu8R8FzI1Th1ZNwYvZBJ+4UGYcH6XpL3MyRU/xtx7p4E7Adsl3fkuXGlExqFr6mjnhVyUV3HqyNIxeCHTiIvD7PRDsofW9LwfKoWSOwHbMbl8lwAPZ0T6uZmhN2QPBEGQHX0pq+TUkTVg8EKmoVSi4yt/Q/+005JDGd5B2B7dlzsB26nCsipcyC6StPeN8oVw967RRAYkt2QaAH47zakjS8fghUwnPh6zh3eUPfTFzCXcUM9OHU3N1y44q435LmRsMWGcOrJWDF7IpEbMHo9wmTeLQ8UKnLtWaIYekbnp3M8oksELGRenjqwXgxcyKaVCwMwBkbLH1uxPMWlfyDLI5bt4ujigfaCHGXpD9kbX1NHvZ7JN3BNqDAYvZHIP9g6Hm5M0t+XnU9eQV1Jhhh6RuZRWVONspnTErW+ULxQyO5ITGZquqaMdiTmcOrJgDF7I5LxcHTG5V5ikvbJajbWH0szQIzKXE2kFqFZLE15YnI5MRddeR5w6smwMXsgsdE0dff1XKiqr5avxku05nJwn2876LmRKugvWcerIUjF4IbOIDnDH0PYBkvbc4gr8cZbLFO2FXL6Lm5MSnUM8zdAbslecOrI+DF7IbGYPjJJt/4KJu3aholqFE+kFkvZeET5wVPKtiUxHEASM6RwoaddMHV03Q4+oIXyHILOJa+uPNi3dJe2n0gtwPO2mGXpEpnQ6o1B2irAvl0iTqW3YgDH/eEL2EPc6skwMXshsBEHALB25L6v3XQV27QLWrdP8VnHo1tbo3s+IwQuZ0IYNwOTJ6HZqH0ILcySHd5zJ5NSRBWLwQmYV3zMUni4OkvY/TmYi64HJwLRpwNChQGSk5k2GbIZcvouTUoFu4d6m7wzZJ5UKWLQIEEUIAMZe2Cc5pUwtYFeiNKgh82LwQmbl5uSAqX1bSdqrFUp83WPsnYbMTGDyZAYwNqJapcaxFGnw0j3cGy6O3N+KTGTvXiAjQ3txzMX9sqdtTpDuyUbmxeCFzO7R2AjI1SNb120kyh2cNBdqNr9ZvJhTSDbgfFYRSiulzyOnjMiksurms3TLuiQ/dZRTzakjC8PghcwuzMcNIzsHSdpvunlhU6chdxpEEUhP13xbIqvGfBeyCMF167sIkB99KVULXHVkYRi8kEXQtWx6de8HIKm/msXsf2snF7woFQJ6RviYoTdkt+LigLAwQLgz9DtGJu8FADZz1ZFFYfBCFqFPpA86e0r/HC8GROJgq5i6jcHy1TDJOqjVIo7I5Lt0CfGEu7M0eZvIaJRKYNUqzb9vBzDdsy4htFC6LQAL1lkWBi9kEQRBwGP3dZY99kXvB2pOAsLDNd+WyGpduV6Cm2VVknZOGZFZxMcD69cDoaEAaqaOpKMvpZUq7L7EqSNLweCFLMb93UPh7yjdpG9Hm75I9bk92vLuu5pvS2S15JZIA9zPiMwoPh5ISQESEoC1azHm6Wmyp3HqyHIweCGL4eygxPRB7STtoqDAl4Me1nw7io83Q8/IkHQl6/aJZL4LmZFSCQwZAkydiu7jhyHUW7rX0fbznDqyFAxeyKJM798Kjkrpuukfu41EydgHzNAjMiRRFGV3km4f6AFvNycz9IhIShAEjO4iXQHJqSPLweCFLEpLDxeMiwmRtBdXVGP90XQz9IgMKTWvDDlFFZJ25ruQpRkbI78wgFNHloHBC1kcXcum1xxIgVotzYkh63HwqnTUBQD6MHghC9M93JtTRxaMwQtZnK5hXugtU+8jJa8MCRelSxjJeuy/ckO2PbY1k3XJsnDqyLIxeCGLpLNo3f4U03aEDEYURRxMko68tAt0R4CHsxl6RFS/MZw6slgMXsgijewciBAvF0n7vis3cCmn2Aw9oua6mFOMvNJKSfsAl3LuV0UWqUe4t+z70I7EXE4dmRmDF7JIDkoFHo2NlD3G0RfrdOCKfL7LgLeXAZGR3DGcLI4gCBjTVTr6UlJRjT2cOjIrBi9ksab2DYeLo/RPdOOJDBSUSb/Bk2U7kCTNd1GoVeiXfhbIzAQmT2YAQxaHU0eWicELWSxvNydM7BEmaS+vUmPdYS6btibVKjUOXZUWp+uanQSvilLNjuEAsHgxp5DIouiaOtrOqSOzYvBCFu2xgZGy7V8fTEG1Sm3azlCTncksRHFFtaQ9Nu3UnQuiCKSnA3v3mrBnRPUTBAGjOXVkcRi8kEVrG+iBuLb+kvZrheXYei7HDD2ipjggs8oIAAamnpI2ZnE4niyLXN4LwKkjczJq8JKfn4/p06fD09MT3t7emDNnDkpKSuq9zpAhQyAIQp2fJ554wpjdJAs3W8foy+r9yabtCDWZXL6LU3UVemckSk8Olv+gIDIXTh1ZHqMGL9OnT8e5c+ewbds2/Pbbb9izZw/mz5/f4PXmzZuHrKws7c8bb7xhzG6ShRvSriWi/FtI2o+m3sSZjEIz9Igao7xKhaMpNyXtPa5dgGt1ra0CBAEIDwfi4kzYO6KGKRS6p462nss2Q4/IaMFLYmIitmzZgs8++wz9+vXDPffcg/feew/fffcdrl27Vu913dzcEBQUpP3x9PQ0VjfJCigUAmbGRsgeW73hL2DdOmDXLiZ6WqgTaQWoqJbmJw2oPWUk3N6M8913Nbv7ElmY+3WsOvqBe66ZhdGCl4MHD8Lb2xu9e/fWto0YMQIKhQKHDh2q97rffvst/P390aVLFyxZsgRlZWU6z62oqEBRUVGdH7I9k3uHw8PZQdL+a/ot5M77P2DoUNYKsVByU0bAXfkuYWHA+vVAfLyJekXUON3DvdGmpbukff+VPKTn6/6MIuMwWvCSnZ2Nli1b1mlzcHCAr68vsrN1D7NNmzYN33zzDRISErBkyRJ8/fXXeOSRR3Sev2LFCnh5eWl/wsPDDfYYyHK4Ozvgwd7S57ZK6YhveozRXGCtEIskl6zr5qREzFcfAGvXAgkJQHIyAxeyaIIgYEpvaekGAPjxWIaJe0ONDl5eeuklSULt3T8XLlxocofmz5+PkSNHomvXrpg+fTq++uorbNy4EUlJSbLnL1myBIWFhdqf9HQO4dmqWQMitbMLta3tPhoVSgfWCrFAJRXVOJVeIGnvG+ULp2FDgalTgSFDOFVEVmFijzA4KKRvQuuPpkPFHe9NSjoO34DnnnsOs2bNqvec1q1bIygoCLm5dXcArq6uRn5+PoKCpDt16tKvXz8AwJUrVxAdHS057uzsDGdnbupmD1r5uWF4gBLbc+sGJjda+ODXjoMw+ezOurVChgwxT0dJ60hyPqpl3tQHRHMXabI+AR7OGNahJf48X7dMw7XCchxIuoG4tgFm6pn9aXTwEhAQgICAhp+g2NhYFBQU4NixY+jVqxcAYOfOnVCr1dqARB8nT54EAARz+SQBeMy9CNtzpSuPVvd6AJPO7oT2OxFrhViE/Vfk810GREtr9xBZgym9wyXBCwD8cDSDwYsJGS3npWPHjhg1ahTmzZuHw4cPY//+/Vi4cCEefvhhhISEAAAyMzPRoUMHHD58GACQlJSE1157DceOHUNKSgp++eUXzJgxA4MGDUJMTIyxukpWJLZtANpfT5G0nwtqgyNhne80MNi1CHL5Ll6ujugUzBWEZJ2GtA9AgId0tH/ruWzuuWZCRq3z8u2336JDhw4YPnw4xowZg3vuuQeffPKJ9nhVVRUuXryoXU3k5OSE7du347777kOHDh3w3HPPYdKkSfj111+N2U2yIsKgQZidJF8+/oveD7BWiAXJL63E+Szp6r/Y1n5QyOQNEFkDB6UC8T1DJe2V1Wr8cqr+MiBkOI2eNmoMX19frF27VufxyMhIiOKd+fDw8HDs3r3bmF0ia6dUYsLCKfjPniLcdKv77f3Ptv2R5hWIVqwVYhH+uqpjS4A2zHch6zaldzg+3n1V0v79kXTMiI3ULBjYu1czfR0crPkyxfckg+LeRmR1XCbHY1q0m6RdrVDii6UfccmthdBV3yWW+S5k5aID3NE7wkfSfu5aEc5+vVFTc2roUGDaNNagMhIGL2SVZsweCUeldOrhh5vOKLxVZYYe0d0OXJGOvAR6OiM6QJpwTWRtpsjUnQKA9V9tBTLuqvvCGlQGx+CFrFKgpwvGdQuRtJdVqvDd4TQz9Ihqyyq8has3SiXtA6L9IcgV6yGyMmNiguHmJJ0K2thpCMqVjnUbWYPK4Bi8kNWae09r2fY1B1JQpZLupUOmIzfqArC+C9kOd2cHjJXZrLHQ1QPb28qUA6ldg4qajcELWa1OIZ6yyZ9ZheXYfIZ1XsxJbok0AMQyeCEb8lAf+amj72Pu030l1qAyCAYvZNV0jb58uveqZiWbSqXZcZo7T5uMKIqyyboRfm4I85EmWhNZq14RPmjtL83h2hfZHZkeOgrWsQaVQTB4Ias2uF2A7E6vZzOLcOjLTcz6N4OUvDJkFZZL2llVl2yNIAiyG8aKggI/dR1+98msQWVADF7IqikUAubcEyV77LNfjzPr3wx0bwnAKSOycjIjuZN6hkIpU3Txx64joK7ZsKQmSZ01qAyGwQtZvYk9QuHXwknSvqNNX1z1uWtFErP+je4g813IFm3YIDuS23L7ZgxpJ50iSvcOwl+tumguhIUB69ezBpUBMXghq+fiqMQj/SMk7aKgwBe9x0uvwKx/o1GrRRyUqazbIcgD/u7c/Z2s1IYNmhFbHSO5U1SZslf74clXgIQEIDmZgYuBMXghm/BobAScHKR/zuu7DsdNFw/5KzHr3+AuZBcjv1S6OR3zXchqqVTAokV3Rm1ru9027NXF8JcZ/f2jxAWF/QZyqsgIGLyQTfB3d0Z8D+lmaeWOLvi2x2j5KzHr3+B0bQnAfBeyWnv3SkdcahNFOKalYmKAtLZURbUav3KzRqNg8EI2Q1fi7pc970eFstYepMz6Nxq5+i5KhYB+rX3N0BsiA9BzhHaKc4Fs+49H0w3YGarB4IVsRttADwxpL02cu+7ui187DtJcYNa/0VSp1Dgkk+/SNdQLHi6OMtcgsgJ6jtC2jQpEj1bekvZTGYVIzCoycKeIwQvZFF1F6z7rMxEiwKx/IzqdUYjSSukKLk4ZkVWLi9O8b+jak6vWSK6uzRrXHuJ+a4bG4IVsysA2fugQJE3QvdAyCvt/3M6sfyNKuJAr2z6wDZN1yYoplcCqVZp/3x3A3DWSe39MMFwdZTZrPJGJ0opq4/bTzjB4IZsiCALmxunYMqDIg1NFRrTl4CVJm0t1JXqd3GOG3hAZUHy8ZsQ29K5FAXeN5Hq4OGJ8d+lu9yUV1fiFibsGxeCFbM64bsEI8JDWFNl96Tou5RSboUe278q3G3GlXPp2MvjqUbhMYUVjsgHx8UBKiqZuy9q1Ouu3TO8nrTkFAN/8larZb40MgsEL2RxnByVmDYiUPfb53mTTdsYeqFTY+vVm2UOjLh7Q/IMVjckWKJXAkCHA1Kma3zIjuV3DvBAT5iVpP3etCKcyCo3fRzvB4IVs0rS+reDiKP3z3nAiAxk3y8zQIxu2dy+2BnaSNDuoqjEs6QgrGpPdeUTH6Mu3f6WauCe2i8EL2SSfFk6Y3CtM0l6lEvH+zitm6JHtykzNxungdpL2Aamn4FVReqeBFY3JTtzfLRgeLg6S9l9PX0NhWZUZemR7GLyQzZp7T2v53V6PZSDlRqnMNagptoryS6FHXjpYt4EVjclOuDk5YFJP6Zen8io1Npyop1ov6Y3BC9msSP8WmNRTumWASi1i1Y7LZuiRbdpS3kLSJohq3Hvlr9sXWNGY7M+0fq1k2789lMbEXQNg8EI27alhbeGolI6+bDqZictcedRs14srcCT1pqS9d0YiWpYWsKIx2a12gR7oGyXdFuNKbgkOJeeboUe2hcEL2bRwXzc83Ef6DUgUgXe2S+uSUONsT8yR3Wx35KXbq4xY0Zjs2PR6Rl+oeRi8kM1bOKwNnB2kf+qbz2TjbCaXLjbHlrPZsu0jFz6ssw4Gkb0Y1SUIvi2cJO1bzmbhRkmFGXpkOxi8kM0L9HTBo/3lly6+s42jL01VeKsKB5JuSNq7hHoifObDOutgENkLZwclHuwtv+rxx6NM3G0OBi9kF54cEg03J+kH6Y4LuTieJs3ZoIYlXMhFlUo6ZzSqc5AZekNkmab1lZ86Wns4FWo1E3ebisEL2QU/d2c8NjBK9thbf140cW9sw9Zz8lNGo7oweCGqEeHXAoPaBUja0/NvYc/l62bokW1g8EJ2Y15ca9nCUfuv5MlOf5ButypV2HVR+sYbHdACbVpKd/UmsmdM3DU8Bi9kN7zcHDFfx47Tb/95ibUXGmHP5eu4VSXdq2gkp4yIJIZ3aIlAT+lmsTsSc5BVeMsMPbJ+DF7Irsy+Jwo+bo6S9qOpN7H7UgNDuCoVsGsXsG6d5rclbDRopj5t1bHKiFNGRFIOSoVsyQa1CHx3ON0MPbJ+DF7Irrg7O+DJIdGyx96qb/RlwwYgMhIYOhSYNk3zOzJS024uZupTZbUa2xNzJO0hXi7oGirdTZeIgKl9W8luV/LdkTRUqdRm6JF1Y/BCdufR/pEI8JAO4Z7JLMSfH6+XjmBs2ABMngxk3LW0MTNT026OAMaMffrrah6Kyqsl7SO7BEEQpG/ORAQEeblgeIeWkvacogrsSMw1Q4+sG4MXsjuuTkosHNpG9tjbR3KhHjrszgiGSgUsWgTZMrI1bYsXm3YKycx92qJrlRHzXYjqNV1HvalvD6U2/UYtcTrbBBi8kF16uG84QrxcJO0XAyLxW8e4OyMY//qXdHSjNlEE0tOBvXuN2Nu77N1rtj6p1CL+PCedMvJr4YTekdJ9XIjojrg2/mjl6yZp33v5RtN2urfE6WwTYfBCdsnZQYmnh8rnvvxn8ExkuvtrLqxapd8NZmUZqGcGvC8j9OlE2k3Zsub3dQ6Unc8nojsUCkHnbtMf70lq3I1Z4nS2CTF4Ibs1qSwZkfnXJO2ZXoF48JH/4Kp3MJCv5+6vwcEG7p0B7ssIfdK5lxGnjIj08mCvMNmd7n84mqH/6IslTmebGIMXsluOOdlYvH+t7LFrni0xZfp/cK5lFODrC+hKRBUEIDwciIvTXDbF/HNcnGa3ZhP3SRRF2XwXD2cHDIj2b9JtEtkbP3dnjO8eKmlXqUW8q+9O92acOrYUDF7IfgUHY1ziHvTMTJQ9fKOFDx6eugJHF/5d03B3sFBz+d13NRsQmmr+Wam8M51lqD7pEeCcu1aEjJvSglrDOraEk8yu3UQk7+lhbeEgM83686lruJhd3PANmHHq2FLwHYfsV1wclKEh+GTjv9ApR36+udjFHY+qO2PP5z8BoXd9WwoLA9avB+LjTT//HB+vuW9D9EnPAEfnXkacMiJqlFZ+bnioT7ikXRSBt7fpsdeaGaeOLYUg2lhN9KKiInh5eaGwsBCenp7m7g5Zutsf8IXOLTBn0ss4GtZZ9jRHpYD/TumG0Tcva77NBAdrpmWUSs0oRWSk7mFcQdAEFcnJmvMNSaXSDA03tU9vvw1MmSKdO68ZwakJhADc+/ZuXM4tqXOas4MCJ5beCzcn6Z5RRKRbdmE5Br+ZgIpqaYG6XxYOREyYt+4r17y+MzPl816M+Z5jRI35/ObIC9m32yMYXv7e+OqHpYhLPi57WpVKxILvTuIH92hg6lRgyJA7bwrmnH9WKjV9aWqf/u//9Er6u5xTLAlcAGBwuwAGLkRNEOTlgkd11H1Z+WcDuS+NmTq2UQxeiOLjgZQUuP25BZ890AajA+Vf8GoR+Nv60/hiX3LdA5Y4/6zvfV2vZz+n2wHOxc27MXvNEdlTuJcRUdM9OSQaLZyk7zd7Ll3H4eQGVjrqM3Vswxi8EAHaEQzn6VPx3tP34cFeYTpPffW381i59SLU6tujE5Y4/2yg+0po3RuTDpbJJuo6KAQM7xBokPshskd+7s547J4o2WMrt15seKf721+8kJAArF2r+Z2cbPOBC8DghUjCQanAfybF4LGB8m8qAPB+whXM++ooCm9VNX7psino06eAAJ1XFwF81ns85kx6GSVq+du4PyYYXjI7dBOR/ubGtYani3Tq9XBKPvZcvtHwDeiaOrZxDF6IZCgUAl6+vyOeGdFO5zk7LuRiwgf7cfF6meXNP+szJ/7BB7IBTqXCAX8fuRD/HD4PaoV8n8N9XbF0nHxyMxHpz8vVEY8P1rHT/dYLEBMS7G7fIn0weCHSQRAELBrRFkvv76TznOQbpZj4v/34rU1/y5t/bmhO/MEHJQHOTRcPzJjyKtZ1H6XzZvtG+uLnBffAt4WTsXpOZFdmD4yEv7v09XQ6swhbH/9/lrVvkYVsBMml0kR6+PFoOl7acAYqte6Xy7y4KLx4b1s4HNgvXbpsTrqWU9fYsAFYtAhXyoA5k5ci1SdE501N7hWGf03sAmcH+xiaJjKV1fuT8cqv5yXt7a6n4o/VT0EpqmVLGJjU7feKOisZw8I0X4IM0J/GfH4zeCHS06GreViw9oTsxoQ1Ylv74f1pPeDn7mzCnjXP9eIK7LqQjVd/PoviavlzBAF4aVQHzB/UGoKuPBoiarKKahWGvrkL1wrLJcfe/XUlJpzfpblgrhouNUUv9agJ1VQMXhi8kJFkF5bjyW+P4URagc5zQrxc8OEjvdAt3Ntk/WqMGyUV+Otq3u2ffFyRqd9Sm5uTEqse7oF7O3FlEZExfXc4DS9tOCNpj7h5Dds/exKO6lpTNAkJmgRdUzBRIc7GfH6zuhRRIwR5ueC7+f3x6q/n8e2hNNlzrhWW48GPDuKFke0xvX8rsxZxU6lFpOeX4dy1Im3AIldsTpdQb1d8NrM3OgbziwCRsU3qFYaPfjuJlMq6AUCqTwjWdx2Bqae23mk0Zd2oxhTiNFFAxeCFqJGcHZT418Su6BbmjX/8fBaVMuW9K1Vq/GtzIv636wpmxEZiRmyEUaeSKqvVSM0rxeXcElzJLcHl3BJczinG1Rulsv3TR89W3vj40d4I8LCeKTAia+aoVOCZDm5YdFo6Nf3fAQ9j4tmdcFFVaRpMWTfKAgtxctqIqBlOZxTgyW+OI7NAWsStNhdHBab0Dsfce1qjlZ9bs+6zvEqFc9eKcDK9AKfSC3DuWiFS88pQXU8ycWNN6B6C1yfFwMWx1jfAhhJ/iajZ1FXVGP3UF7joHSo59veEzzH/yCbT57zs2qVZ7dSQZk5lMeeFwQuZUF5JBZ7+7gT2X8lr8FyFAIzpGozHB0Wja5hXg+er1SKu3ijFyfQCnEy/iVPphUjMKjJooFJbqLcrFgxtg6l9w+sm5hp5lQER3bH18014/LK0AKRrZTn+XL0Q4Z9/YNrXnYk2gmTwwuCFTKxapcabf17Ex7uv6n2dvlG+aOnhjMpqNapUalSpRFSqav6tRlW1iGuFt1BcrmMJkAEEejojtrUf+t/+ifBzk64mMsEqAyK6QxRFTPjnbzhVKi3FFuepxldL7jf9qr+a9wFNB++0c7WRYTB4IXPae/k63t52qd7VSObU0sMZsdF3gpVIuWClNhOtMiCiug4n52PKxwdlj618sBsm17P/mtHIjcCGh2sqiLPOS/MweCFzE0URR1Nv4uPdSdiemGuWPjg5KNDavwXaBnqgTYA72ga6o2OwZ8PByt1MNNdNRFJ/33gGa2VWNXq5OmL7s4PNk0xvxNw3LpUmMiNBENAn0hd9In1xOacYn+y5ik0nM1GlMvz3BIUAtAv0QKdgT7QJdEfblh5o29Id4b5uUCoMMKxsgasMiOzFS6M7YEdiDnKK6q4+KrxVhVd+PYf3p/U0fadqNoI0MwYvREbUNtADbz7YDc/d1x5f7E/G2kNpKKloeg5LsJcLuod7o1u4N7qHe6NLqBfcnY34MtZ3OaYpl20S2QlPF0e8Nr4L5n99THLst9NZmNA9ByPstHik0aaN/vWvf+H333/HyZMn4eTkhIKCggavI4oili1bhk8//RQFBQUYOHAgPvzwQ7Rt21bv++W0EVmywltV+PZQKraezUZafhkclAo4KRVwclDAUSnAUamA4+3LTkoFXByVaBvoju63g5VATxfTdthEqwyISLcF3x7H72eko5tBni7Y9uwgeLhIVyZZI4vIeVm2bBm8vb2RkZGBzz//XK/g5T//+Q9WrFiBL7/8ElFRUXj55Zdx5swZnD9/Hi4u+r1pM3ghMjATrDIgIt2uF1dgxNu7UXirSnLskf6t8M8JXc3QK8NrzOe3dB2Wgbzyyit45pln0LWrfv+poiji3XffxT/+8Q+MHz8eMTEx+Oqrr3Dt2jVs2rTJWN0koobEx2sClNC7imaFhTFwITKBAA9n/L+xHWWPffNXGg4n55u4R+ZntOClsZKTk5GdnY0RI0Zo27y8vNCvXz8cPCi/XIyITCQ+HkhJ0awqWrtW8zs5mYELkYk82CsM97Txlz320k+nUV6lkj1mqywmeMnOzgYABAbWTT4KDAzUHpNTUVGBoqKiOj9EZAQ1qwymTtX8Zo4LkckIgoB/T+wKV0fp6+7qjVK8v/OKGXplPo0KXl566SUIglDvz4ULF4zVV1krVqyAl5eX9ic8PNyk909ERGQKrfzc8Nx97WSPfbQ7CYlZ9vPlvVHBy3PPPYfExMR6f1q3bt2kjgQFBQEAcnJy6rTn5ORoj8lZsmQJCgsLtT/p6elNun8iIiJLN2tAJGJk9kWrVot48afTqFY1bRd5a9OoAhEBAQEICAgwSkeioqIQFBSEHTt2oHv37gA0mceHDh3Ck08+qfN6zs7OcHY2Q5VBIiIiE3NQKvCfSTEY994+yQatpzMK8ebWi3hpdAfT731kYkbLeUlLS8PJkyeRlpYGlUqFkydP4uTJkygpKdGe06FDB2zcuBGAZj5v8eLF+Oc//4lffvkFZ86cwYwZMxASEoIJEyYYq5tERERWpWOwJ54YHC177OM9V7Hsl3NQG2nneUthtNKcS5cuxZdffqm93KNHDwBAQkIChtwuLXzx4kUUFhZqz/nb3/6G0tJSzJ8/HwUFBbjnnnuwZcsWvWu8EBERWYVm7hG0cFgbbD6bhavXSyXHvjqYiuLyarw5OQYOSotZl2NQ3JiRiIjIlOR2Zw4LA1atalT5gSMp+Xj4k7+g0jHKcm+nQLw3tQdcZFYoWSKLKFJHREREd6mpWF07cAE0W3BMnqw5rqc+kb5468FuOjdh3XY+B4+tOdKs/dQsFYMXIiIiU1CpNCMuchMeNW2LF2vO09OEHqH46JFecHKQ/zg/kJSHRz47hIKyyiZ02HIxeCEiIjKFvXulIy61iSKQnq45rxHu7RSINbP6wM1JfnroZHoBHvr4L+QWlTfqdi0ZgxciIiJTyJLuDN2s82oZ0MYf387tBy9X+R2mL+YU48GPDyI9v6zRt22JGLwQERGZQnCwYc+7S49WPvjh8VgEeMjXPkvNK8Pkjw7gaIr1b+TI4IWIiMgU4uI0q4p0FZATBCA8XHNeE7UP8sD6J2IR5uMqezynqAKTPzqIZ384idxi651GYvBCZGoqFbBrF7BuneZ3I5LziMiKKZWa5dCANICpufzuu83e9DTCrwXWPzEAbVq66zxnw/FMDF+5G5/vS0ZVzZYCVvTexDovRKZkoPoORGTF5N4HwsM1gYsB3wfySysx84vDOJNZWO957QM98IpPHvq//LRZ35sa8/nN4IXIVGrqO9z9kqv5xrV+PQMYInvRzAq7+iour8K8r47ir6sN57k8cH4X/p6wGkEleZoGE783MXhh8EKWRqUCIiN1L5MUBM23nORko7yBEZH9qlKpsXp/MlZtv4zSyvqnglpUlOHpA99h9tFf4KSuNul7EyvsElmaxtZ3sKK5ZyKybI5KBeYPisbO54dgfPeQes8tdXbDiqGP4b45/8O2Nn0hNrH2jLExeCEyhcbUd9iwQTNKM3QoMG2a5ndkZKPKhhMRad3+MhT4+0asCirEd3P7on2gR71XSfENwbxJS/HIQ/9EYkBkk2rPGBODFyJT0Lduw+XLBtv3hIhI7stQ/6E98Vv4DSy9vxM8HOq/+v7I7hg7axWW5PniRkmFSbqsD+a8EJlCTc5LZqb8viaCAISGav7NvBgiMgQ9FgnkDhuF/8z7N36Kjm3w5tydHbBwWBvMHhgJZwfDvwcx54XI0uhT32HePKPse0JEdkjPTSBbejjjrak9sf7bv6FzTlK9N1lSUY3X/7iAe9/egz/OZMGcYx8MXohMJT5es+SwZoSlRliYpr1tW/1ux8LmnonIAjVmkUB8PHqveg2/7FiJNza/i4CS+pdVp+WX4clvj+OhT/7C2QZqyBgLgxciU4qPB1JSgIQEYO1aze/kZE27kfc9ISI70thNIOPjoUxOxpT//j8k9HfAwtaOcHKoP0Q4nJyPce/vw6+nrjWzs43XQKoOERmcUgkMGSJtr9n3pL68mLCwZu17QkR2oilfhm6/N7kDeB7AQ/ll+M+WC/jttO5AyNvVEYPaBTSrq03BkRciS2GifU+IyA4YYBPIcF83vD+tJ9Y/EYtuYV6y5zx7bzt4uToaoseNwuCFyJI0lBfD7QOISB8G/DLUO9IXG/9vIN6e0g2Bns7a9rYt3TG1bysDdbhxuFSayBKZaN8TIrJxBt4EsqyyGh/tvopP9iThk0d7G3TKiHsbMXghIiLSMMKXobySCvi5Ozd8YiM05vObCbtERES2TNcigWYwdODSWMx5ISIiIqvC4IWIiIisCoMXIiIisioMXoiIiMiqMHghIiIiq8LghYiIiKwKgxciIiKyKgxeiIiIyKoweCEiIiKrwuCFiIiIrIrNbQ9Qs1VTUVGRmXtCRERE+qr53NZny0WbC16Ki4sBAOHh4WbuCRERETVWcXExvLy86j3H5naVVqvVuHbtGjw8PCAIgkFvu6ioCOHh4UhPT7fJHatt/fEBtv8Y+fisn60/Rj4+62esxyiKIoqLixESEgKFov6sFpsbeVEoFAgLCzPqfXh6etrsHyVg+48PsP3HyMdn/Wz9MfLxWT9jPMaGRlxqMGGXiIiIrAqDFyIiIrIqDF4awdnZGcuWLYOzs7O5u2IUtv74ANt/jHx81s/WHyMfn/WzhMdocwm7REREZNs48kJERERWhcELERERWRUGL0RERGRVGLwQERGRVWHwUsu//vUvDBgwAG5ubvD29pY9Jy0tDWPHjoWbmxtatmyJF154AdXV1fXebn5+PqZPnw5PT094e3tjzpw5KCkpMcIjaJxdu3ZBEATZnyNHjui83pAhQyTnP/HEEybsuf4iIyMlfX399dfrvU55eTkWLFgAPz8/uLu7Y9KkScjJyTFRjxsnJSUFc+bMQVRUFFxdXREdHY1ly5ahsrKy3utZ8nP4wQcfIDIyEi4uLujXrx8OHz5c7/k//vgjOnToABcXF3Tt2hWbN282UU8bb8WKFejTpw88PDzQsmVLTJgwARcvXqz3OmvWrJE8Vy4uLibqceMsX75c0tcOHTrUex1rev4A+fcUQRCwYMEC2fMt/fnbs2cPxo0bh5CQEAiCgE2bNtU5Looili5diuDgYLi6umLEiBG4fPlyg7fb2NdxYzF4qaWyshIPPvggnnzySdnjKpUKY8eORWVlJQ4cOIAvv/wSa9aswdKlS+u93enTp+PcuXPYtm0bfvvtN+zZswfz5883xkNolAEDBiArK6vOz9y5cxEVFYXevXvXe9158+bVud4bb7xhol433quvvlqnr0899VS95z/zzDP49ddf8eOPP2L37t24du0a4uPjTdTbxrlw4QLUajU+/vhjnDt3Du+88w4++ugj/P3vf2/wupb4HH7//fd49tlnsWzZMhw/fhzdunXDyJEjkZubK3v+gQMHMHXqVMyZMwcnTpzAhAkTMGHCBJw9e9bEPdfP7t27sWDBAvz111/Ytm0bqqqqcN9996G0tLTe63l6etZ5rlJTU03U48br3Llznb7u27dP57nW9vwBwJEjR+o8vm3btgEAHnzwQZ3XseTnr7S0FN26dcMHH3wge/yNN97Af//7X3z00Uc4dOgQWrRogZEjR6K8vFznbTb2ddwkIkmsXr1a9PLykrRv3rxZVCgUYnZ2trbtww8/FD09PcWKigrZ2zp//rwIQDxy5Ii27Y8//hAFQRAzMzMN3vfmqKysFAMCAsRXX3213vMGDx4sLlq0yDSdaqaIiAjxnXfe0fv8goIC0dHRUfzxxx+1bYmJiSIA8eDBg0booeG98cYbYlRUVL3nWOpz2LdvX3HBggXayyqVSgwJCRFXrFghe/6UKVPEsWPH1mnr16+f+Pjjjxu1n4aSm5srAhB3796t8xxd70eWaNmyZWK3bt30Pt/anz9RFMVFixaJ0dHRolqtlj1uTc8fAHHjxo3ay2q1WgwKChLffPNNbVtBQYHo7Owsrlu3TuftNPZ13BQceWmEgwcPomvXrggMDNS2jRw5EkVFRTh37pzO63h7e9cZyRgxYgQUCgUOHTpk9D43xi+//IK8vDzMnj27wXO//fZb+Pv7o0uXLliyZAnKyspM0MOmef311+Hn54cePXrgzTffrHea79ixY6iqqsKIESO0bR06dECrVq1w8OBBU3S32QoLC+Hr69vgeZb2HFZWVuLYsWN1/u8VCgVGjBih8//+4MGDdc4HNK9Ja3quADT4fJWUlCAiIgLh4eEYP368zvcbS3D58mWEhISgdevWmD59OtLS0nSea+3PX2VlJb755hs89thj9W4EbE3PX23JycnIzs6u8xx5eXmhX79+Op+jpryOm8LmNmY0puzs7DqBCwDt5ezsbJ3XadmyZZ02BwcH+Pr66ryOuXz++ecYOXJkgxtbTps2DREREQgJCcHp06fx4osv4uLFi9iwYYOJeqq/p59+Gj179oSvry8OHDiAJUuWICsrC2+//bbs+dnZ2XBycpLkPAUGBlrc8yXnypUreO+997By5cp6z7PE5/DGjRtQqVSyr7ELFy7IXkfXa9Ianiu1Wo3Fixdj4MCB6NKli87z2rdvjy+++AIxMTEoLCzEypUrMWDAAJw7d87om9A2Vr9+/bBmzRq0b98eWVlZeOWVVxAXF4ezZ8/Cw8NDcr41P38AsGnTJhQUFGDWrFk6z7Gm5+9uNc9DY56jpryOm8Lmg5eXXnoJ//nPf+o9JzExscGkMmvSlMeckZGBrVu34ocffmjw9mvn63Tt2hXBwcEYPnw4kpKSEB0d3fSO66kxj+/ZZ5/VtsXExMDJyQmPP/44VqxYYdHlu5vyHGZmZmLUqFF48MEHMW/evHqva+7nkIAFCxbg7Nmz9eaEAEBsbCxiY2O1lwcMGICOHTvi448/xmuvvWbsbjbK6NGjtf+OiYlBv379EBERgR9++AFz5swxY8+M4/PPP8fo0aMREhKi8xxrev6sic0HL88991y9UTEAtG7dWq/bCgoKkmRM16xCCQoK0nmdu5OUqqurkZ+fr/M6zdWUx7x69Wr4+fnhgQceaPT99evXD4DmW78pPvia85z269cP1dXVSElJQfv27SXHg4KCUFlZiYKCgjqjLzk5OUZ7vuQ09jFeu3YNQ4cOxYABA/DJJ580+v5M/RzK8ff3h1KplKzsqu//PigoqFHnW4qFCxdqk/cb++3b0dERPXr0wJUrV4zUO8Px9vZGu3btdPbVWp8/AEhNTcX27dsbPVppTc9fzfOQk5OD4OBgbXtOTg66d+8ue52mvI6bxGDZMzakoYTdnJwcbdvHH38senp6iuXl5bK3VZOwe/ToUW3b1q1bLSphV61Wi1FRUeJzzz3XpOvv27dPBCCeOnXKwD0zvG+++UZUKBRifn6+7PGahN3169dr2y5cuGDRCbsZGRli27ZtxYcfflisrq5u0m1YynPYt29fceHChdrLKpVKDA0NrTdh9/7776/TFhsba7EJn2q1WlywYIEYEhIiXrp0qUm3UV1dLbZv31585plnDNw7wysuLhZ9fHzEVatWyR63tuevtmXLlolBQUFiVVVVo65nyc8fdCTsrly5UttWWFioV8JuY17HTeqrwW7JBqSmpoonTpwQX3nlFdHd3V08ceKEeOLECbG4uFgURc0fXZcuXcT77rtPPHnypLhlyxYxICBAXLJkifY2Dh06JLZv317MyMjQto0aNUrs0aOHeOjQIXHfvn1i27ZtxalTp5r88emyfft2EYCYmJgoOZaRkSG2b99ePHTokCiKonjlyhXx1VdfFY8ePSomJyeLP//8s9i6dWtx0KBBpu52gw4cOCC+88474smTJ8WkpCTxm2++EQMCAsQZM2Zoz7n78YmiKD7xxBNiq1atxJ07d4pHjx4VY2NjxdjYWHM8hAZlZGSIbdq0EYcPHy5mZGSIWVlZ2p/a51jLc/jdd9+Jzs7O4po1a8Tz58+L8+fPF729vbUr/B599FHxpZde0p6/f/9+0cHBQVy5cqWYmJgoLlu2THR0dBTPnDljrodQryeffFL08vISd+3aVee5Kisr055z92N85ZVXxK1bt4pJSUnisWPHxIcfflh0cXERz507Z46HUK/nnntO3LVrl5icnCzu379fHDFihOjv7y/m5uaKomj9z18NlUoltmrVSnzxxRclx6zt+SsuLtZ+1gEQ3377bfHEiRNiamqqKIqi+Prrr4ve3t7izz//LJ4+fVocP368GBUVJd66dUt7G8OGDRPfe+897eWGXseGwOCllpkzZ4oAJD8JCQnac1JSUsTRo0eLrq6uor+/v/jcc8/VibwTEhJEAGJycrK2LS8vT5w6daro7u4uenp6irNnz9YGRJZg6tSp4oABA2SPJScn1/k/SEtLEwcNGiT6+vqKzs7OYps2bcQXXnhBLCwsNGGP9XPs2DGxX79+opeXl+ji4iJ27NhR/Pe//11nlOzuxyeKonjr1i3x//7v/0QfHx/Rzc1NnDhxYp1gwJKsXr1a9m+29qCqtT2H7733ntiqVSvRyclJ7Nu3r/jXX39pjw0ePFicOXNmnfN/+OEHsV27dqKTk5PYuXNn8ffffzdxj/Wn67lavXq19py7H+PixYu1/x+BgYHimDFjxOPHj5u+83p46KGHxODgYNHJyUkMDQ0VH3roIfHKlSva49b+/NXYunWrCEC8ePGi5Ji1PX81n1l3/9Q8BrVaLb788stiYGCg6OzsLA4fPlzyuCMiIsRly5bVaavvdWwIgiiKouEmoYiIiIiMi3VeiIiIyKoweCEiIiKrwuCFiIiIrAqDFyIiIrIqDF6IiIjIqjB4ISIiIqvC4IWIiIisCoMXIiIisioMXoiIiMiqMHghIiIiq8LghYiIiKwKgxciIiKyKv8fFnj1/RKzZs4AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# let's see how the model looks like!\n",
    "\n",
    "\n",
    "prediction = mymodel(x).detach().cpu().numpy()\n",
    "x = x.cpu()\n",
    "y = y.cpu()\n",
    "plt.plot(x,y,'ro')\n",
    "plt.plot(x,prediction,linewidth = 4)\n",
    "plt.legend(['data','prediction of mymodel after training'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "systems_and_toolchains",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
