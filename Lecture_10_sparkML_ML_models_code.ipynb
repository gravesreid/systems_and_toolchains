{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>SparkML: Machine Learning Models</h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 1. Data Ingestion, Preprocessing, and Tuning for Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession, SQLContext\n",
    "from pyspark.ml import Pipeline,Transformer\n",
    "from pyspark.ml.feature import Imputer,StandardScaler,StringIndexer,OneHotEncoder, VectorAssembler\n",
    "\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "import numpy as np\n",
    "\n",
    "col_names = [\"duration\",\"protocol_type\",\"service\",\"flag\",\"src_bytes\",\n",
    "\"dst_bytes\",\"land\",\"wrong_fragment\",\"urgent\",\"hot\",\"num_failed_logins\",\n",
    "\"logged_in\",\"num_compromised\",\"root_shell\",\"su_attempted\",\"num_root\",\n",
    "\"num_file_creations\",\"num_shells\",\"num_access_files\",\"num_outbound_cmds\",\n",
    "\"is_host_login\",\"is_guest_login\",\"count\",\"srv_count\",\"serror_rate\",\n",
    "\"srv_serror_rate\",\"rerror_rate\",\"srv_rerror_rate\",\"same_srv_rate\",\n",
    "\"diff_srv_rate\",\"srv_diff_host_rate\",\"dst_host_count\",\"dst_host_srv_count\",\n",
    "\"dst_host_same_srv_rate\",\"dst_host_diff_srv_rate\",\"dst_host_same_src_port_rate\",\n",
    "\"dst_host_srv_diff_host_rate\",\"dst_host_serror_rate\",\"dst_host_srv_serror_rate\",\n",
    "\"dst_host_rerror_rate\",\"dst_host_srv_rerror_rate\",\"class\",\"difficulty\"]\n",
    "\n",
    "nominal_cols = ['protocol_type','service','flag']\n",
    "binary_cols = ['land', 'logged_in', 'root_shell', 'su_attempted', 'is_host_login',\n",
    "'is_guest_login']\n",
    "continuous_cols = ['duration' ,'src_bytes', 'dst_bytes', 'wrong_fragment' ,'urgent', 'hot',\n",
    "'num_failed_logins', 'num_compromised', 'num_root' ,'num_file_creations',\n",
    "'num_shells', 'num_access_files', 'num_outbound_cmds', 'count' ,'srv_count',\n",
    "'serror_rate', 'srv_serror_rate' ,'rerror_rate' ,'srv_rerror_rate',\n",
    "'same_srv_rate', 'diff_srv_rate', 'srv_diff_host_rate' ,'dst_host_count',\n",
    "'dst_host_srv_count' ,'dst_host_same_srv_rate' ,'dst_host_diff_srv_rate',\n",
    "'dst_host_same_src_port_rate' ,'dst_host_srv_diff_host_rate',\n",
    "'dst_host_serror_rate' ,'dst_host_srv_serror_rate', 'dst_host_rerror_rate',\n",
    "'dst_host_srv_rerror_rate']\n",
    "\n",
    "class OutcomeCreater(Transformer): # this defines a transformer that creates the outcome column\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def _transform(self, dataset):\n",
    "        label_to_binary = udf(lambda name: 0.0 if name == 'normal' else 1.0)\n",
    "        output_df = dataset.withColumn('outcome', label_to_binary(col('class'))).drop(\"class\")  \n",
    "        output_df = output_df.withColumn('outcome', col('outcome').cast(DoubleType()))\n",
    "        output_df = output_df.drop('difficulty')\n",
    "        return output_df\n",
    "\n",
    "class FeatureTypeCaster(Transformer): # this transformer will cast the columns as appropriate types  \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def _transform(self, dataset):\n",
    "        output_df = dataset\n",
    "        for col_name in binary_cols + continuous_cols:\n",
    "            output_df = output_df.withColumn(col_name,col(col_name).cast(DoubleType()))\n",
    "\n",
    "        return output_df\n",
    "class ColumnDropper(Transformer): # this transformer drops unnecessary columns\n",
    "    def __init__(self, columns_to_drop = None):\n",
    "        super().__init__()\n",
    "        self.columns_to_drop=columns_to_drop\n",
    "    def _transform(self, dataset):\n",
    "        output_df = dataset\n",
    "        for col_name in self.columns_to_drop:\n",
    "            output_df = output_df.drop(col_name)\n",
    "        return output_df\n",
    "\n",
    "def get_preprocess_pipeline():\n",
    "    # Stage where columns are casted as appropriate types\n",
    "    stage_typecaster = FeatureTypeCaster()\n",
    "\n",
    "    # Stage where nominal columns are transformed to index columns using StringIndexer\n",
    "    nominal_id_cols = [x+\"_index\" for x in nominal_cols]\n",
    "    nominal_onehot_cols = [x+\"_encoded\" for x in nominal_cols]\n",
    "    stage_nominal_indexer = StringIndexer(inputCols = nominal_cols, outputCols = nominal_id_cols )\n",
    "\n",
    "    # Stage where the index columns are further transformed using OneHotEncoder\n",
    "    stage_nominal_onehot_encoder = OneHotEncoder(inputCols=nominal_id_cols, outputCols=nominal_onehot_cols)\n",
    "\n",
    "    # Stage where all relevant features are assembled into a vector (and dropping a few)\n",
    "    feature_cols = continuous_cols+binary_cols+nominal_onehot_cols\n",
    "    corelated_cols_to_remove = [\"dst_host_serror_rate\",\"srv_serror_rate\",\"dst_host_srv_serror_rate\",\n",
    "                     \"srv_rerror_rate\",\"dst_host_rerror_rate\",\"dst_host_srv_rerror_rate\"]\n",
    "    for col_name in corelated_cols_to_remove:\n",
    "        feature_cols.remove(col_name)\n",
    "    stage_vector_assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"vectorized_features\")\n",
    "\n",
    "    # Stage where we scale the columns\n",
    "    stage_scaler = StandardScaler(inputCol= 'vectorized_features', outputCol= 'features')\n",
    "    \n",
    "\n",
    "    # Stage for creating the outcome column representing whether there is attack \n",
    "    stage_outcome = OutcomeCreater()\n",
    "\n",
    "    # Removing all unnecessary columbs, only keeping the 'features' and 'outcome' columns\n",
    "    stage_column_dropper = ColumnDropper(columns_to_drop = nominal_cols+nominal_id_cols+\n",
    "        nominal_onehot_cols+ binary_cols + continuous_cols + ['vectorized_features'])\n",
    "    # Connect the columns into a pipeline\n",
    "    pipeline = Pipeline(stages=[stage_typecaster,stage_nominal_indexer,stage_nominal_onehot_encoder,\n",
    "        stage_vector_assembler,stage_scaler,stage_outcome,stage_column_dropper])\n",
    "    return pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/10/06 10:21:52 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/10/06 10:21:53 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "23/10/06 10:22:06 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[features: vector, outcome: double]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if you installed Spark on windows, \n",
    "# you may need findspark and need to initialize it prior to being able to use pyspark\n",
    "# Also, you may need to initialize SparkContext yourself.\n",
    "# Uncomment the following lines if you are using Windows!\n",
    "#import findspark\n",
    "#findspark.init()\n",
    "#findspark.find()\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName(\"GenericAppName\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "nslkdd_raw = spark.read.csv('./NSL-KDD/KDDTrain+.txt',header=False).toDF(*col_names)\n",
    "nslkdd_test_raw = spark.read.csv('./NSL-KDD/KDDTest+.txt',header=False).toDF(*col_names)\n",
    "\n",
    "preprocess_pipeline = get_preprocess_pipeline()\n",
    "preprocess_pipeline_model = preprocess_pipeline.fit(nslkdd_raw)\n",
    "\n",
    "nslkdd_df = preprocess_pipeline_model.transform(nslkdd_raw)\n",
    "nslkdd_df_test = preprocess_pipeline_model.transform(nslkdd_test_raw)\n",
    "\n",
    "\n",
    "nslkdd_df.cache()\n",
    "nslkdd_df_test.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also rerun the tuning for cross validation as we will do comparisons with logistic regression later. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/06 10:22:24 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "import numpy\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Estimator\n",
    "lr = LogisticRegression(featuresCol = 'features', labelCol = 'outcome')\n",
    "\n",
    "# ParameterGrid\n",
    "lr_paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(lr.regParam, [0.01, 0.5, 2.0])\n",
    "             .addGrid(lr.maxIter, [1, 5, 10])\n",
    "             .build())\n",
    "\n",
    "# Evaluator\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol='rawPrediction', \n",
    "    labelCol='outcome', metricName='areaUnderROC')\n",
    "\n",
    "# CrossValidator\n",
    "lr_cv = CrossValidator(estimator=lr, estimatorParamMaps=lr_paramGrid, \n",
    "                    evaluator=evaluator, numFolds=5)\n",
    "\n",
    "# Hyper Parameter Tuning via cross validation\n",
    "lr_cv_model = lr_cv.fit(nslkdd_df)\n",
    "\n",
    "# Make predictions on the test data set and compute the fpr, tpr, and AUC\n",
    "lr_cv_prediction_test = lr_cv_model.transform(nslkdd_df_test)\n",
    "outcome_true = lr_cv_prediction_test.select('outcome').toPandas() # the true outcome label as Pandas df\n",
    "\n",
    "to_array = F.udf(lambda v: v.toArray().tolist(), T.ArrayType(T.FloatType()))\n",
    "\n",
    "lr_cv_pred_prob = (lr_cv_prediction_test.select(\"probability\").\n",
    "        withColumn('probability', to_array('probability')).toPandas())\n",
    "lr_cv_pred_prob = np.array(lr_cv_pred_prob['probability'].values.tolist())\n",
    "\n",
    "lr_cv_fpr, lr_cv_tpr, lr_cv_thresholds = roc_curve(outcome_true, lr_cv_pred_prob[:,1])\n",
    "\n",
    "lr_cv_auc = evaluator.evaluate(lr_cv_prediction_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Support Vector Machine\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "So far we have trained, tuned and evaluated the **logistic regression** model for classification. Logistic regression is perhaps one of the simpliest models for classification and is a good starting point, but their performance is usually not the best because of the linear relationshiop between the feature and the score. \n",
    "\n",
    "We now will go through a range of other modern ML models that are commonly used in the industry.\n",
    "\n",
    "\n",
    "- Support vector machine (SVM)\n",
    "\n",
    "- Tree-like models, including decision tree, random forest. \n",
    "\n",
    "- Naive Bayes\n",
    "\n",
    "Let's start with SVM. The pros and cons of SVM are summarized as follows. \n",
    "\n",
    "**Pros of SVM**\n",
    "\n",
    "- SVM is not sensitive to (some) outliers. Only the points at the boundary will determine the decision boundary. Outlier points, as long as they do not affect the boundary, will be \"ignored\". \n",
    "\n",
    "- SVM also enjoys certain computational/memory benefits as only \"boundary\" points are used to compute the decision boundary. \n",
    "\n",
    "- Another advantage of SVM is the ''kernel trick'' that allows nonlinear decision boundaries. Unfortunately this feature is not supported by SparkML right now. \n",
    "\n",
    "**Cons of SVM**\n",
    "\n",
    "- Does not provide a probability estimate, only rawPredictions. \n",
    "\n",
    "- Works less well when the two classes are \"overlapping\", i.e. the boundary is not clearly defined. \n",
    "\n",
    "\n",
    "Let's implement SVM using SparkML. The process is very similar to logistic regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# The implementation of SVM on spark ML is pretty straightforward - just find the right class from the sparkml library\n",
    "\n",
    "from pyspark.ml.classification import LinearSVC\n",
    "\n",
    "svm = LinearSVC(featuresCol=\"features\",labelCol = \"outcome\")\n",
    "\n",
    "svm_model = svm.fit(nslkdd_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy = 97.5%\n",
      "Test accuracy = 75.39%\n",
      "AUC = 0.82\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# make predictions on training dataset and test data set\n",
    "svm_prediction_train = svm_model.transform(nslkdd_df)\n",
    "svm_prediction_test = svm_model.transform(nslkdd_df_test)\n",
    "\n",
    "# calculate train and test accuracy\n",
    "svm_accuracy_train = (svm_prediction_train.filter(\n",
    "    svm_prediction_train.outcome == svm_prediction_train.prediction).count() / \n",
    "    float(svm_prediction_train.count()))\n",
    "svm_accuracy_test = (svm_prediction_test.filter(\n",
    "    svm_prediction_test.outcome == svm_prediction_test.prediction).count()\n",
    "    / float(svm_prediction_test.count()))\n",
    "    \n",
    "# calculate AUC\n",
    "svm_auc = evaluator.evaluate(svm_prediction_test)\n",
    "\n",
    "print(f\"Train accuracy = {np.round(svm_accuracy_train*100,2)}%\")\n",
    "print(f\"Test accuracy = {np.round(svm_accuracy_test*100,2)}%\")\n",
    "print(f\"AUC = {np.round(svm_auc,2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also tune the hyper-parameters (maxIter, regParam) for SVM. Their meanings are quite similar as in the case of logistic regression. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "svm = LinearSVC(featuresCol=\"features\",labelCol = \"outcome\")\n",
    "\n",
    "svm_paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(svm.regParam, [0.01, 0.5, 2.0])# regularization parameter\n",
    "             .addGrid(svm.maxIter, [10, 50, 100])#Number of iterations\n",
    "             .build())\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol='rawPrediction', \n",
    "    labelCol='outcome', metricName='areaUnderROC')\n",
    "\n",
    "svm_cv = CrossValidator(estimator=svm, estimatorParamMaps=svm_paramGrid, \n",
    "                    evaluator=evaluator, numFolds=5)\n",
    "\n",
    "svm_cv_model = svm_cv.fit(nslkdd_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's evaluate the performance of the tuned SVM and compare it with logistic regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before cross-validation and parameter tuning, AUC=0.82\n",
      "After cross-validation and parameter tuning, AUC=0.83\n"
     ]
    }
   ],
   "source": [
    "svm_cv_prediction_test = svm_cv_model.transform(nslkdd_df_test)\n",
    "\n",
    "svm_cv_auc = evaluator.evaluate(svm_cv_prediction_test)\n",
    "\n",
    "print(f\"Before cross-validation and parameter tuning, AUC={np.round(svm_auc,2)}\")\n",
    "print(f\"After cross-validation and parameter tuning, AUC={np.round(svm_cv_auc,2)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f97003008b0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "svm_cv_prediction_raw = np.array(\n",
    "    svm_cv_prediction_test.select(\"rawPrediction\").toPandas().values.tolist()).squeeze()\n",
    "\n",
    "svm_cv_fpr, svm_cv_tpr,_ = roc_curve(outcome_true,svm_cv_prediction_raw[:,1])\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(lr_cv_fpr,lr_cv_tpr,label='Logistic Regression')\n",
    "plt.plot(svm_cv_fpr,svm_cv_tpr,label='SVM')\n",
    "plt.title('ROC Comparison after Tuning')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Tree Like Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Decision Tree\n",
    "\n",
    "A decision tree builds upon iteratively asking questions to partition data. It is easier to conceptualize the partitioning data with a visual representation of a decision tree.\n",
    "\n",
    "<center><figure><img src=\"http://stat.cmu.edu/~mfarag/14810/l17/decision_tree.png\"/><figcaption>Image taken from <a href=\"https://jakevdp.github.io/PythonDataScienceHandbook/06.00-figure-code.html#Decision-Tree-Example\">here</a></figcaption></figure></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Random Forest\n",
    "\n",
    "One decision tree is prone to overfitting. To reduce the risk of overfitting, models that combine many decision trees are preferred. These combined models also have better performance. Random forests use a method called bagging to combine many decision trees to create an ensemble. Bagging simply means combining in parallel. Random forest also uses other tricks to reduce overfitting, including bootstrap sampling, and feature subsampling. \n",
    "\n",
    "The implementation of random forest in sparkML is very straightforward. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(featuresCol = 'features', labelCol = 'outcome')\n",
    "rf_model = rf.fit(nslkdd_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, `rf_model` is now a Transformer and we now use it to make predictions on both the training dataset and the test dataset. We also calculate the train and test accuracy as well as the AUC. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy = 97.83%, test accuracy = 75.75%, AUC = 0.95\n"
     ]
    }
   ],
   "source": [
    "rf_prediction_train = rf_model.transform(nslkdd_df)\n",
    "rf_prediction_test = rf_model.transform(nslkdd_df_test)\n",
    "\n",
    "rf_accuracy_train = (rf_prediction_train.filter(rf_prediction_train.outcome == rf_prediction_train.prediction)\n",
    "    .count()/ float(rf_prediction_train.count()))\n",
    "rf_accuracy_test = (rf_prediction_test.filter(rf_prediction_test.outcome == rf_prediction_test.prediction)\n",
    "    .count() / float(rf_prediction_test.count()))\n",
    "\n",
    "rf_auc = evaluator.evaluate(rf_prediction_test)\n",
    "\n",
    "print(f\"Train accuracy = {np.round(rf_accuracy_train*100,2)}%, test accuracy = {np.round(rf_accuracy_test*100,2)}%, AUC = {np.round(rf_auc,2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper-Parameter Tuning for Random Forest\n",
    "\n",
    "Two key parameters for random forest is maxDepth (maximum allowed depth in each tree), and numTrees (the number of trees). Let's tune the two parameters with cross-validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/06 10:26:44 WARN DAGScheduler: Broadcasting large task binary with size 1121.4 KiB\n",
      "23/10/06 10:26:44 WARN DAGScheduler: Broadcasting large task binary with size 1390.3 KiB\n",
      "23/10/06 10:26:51 WARN DAGScheduler: Broadcasting large task binary with size 1057.3 KiB\n",
      "23/10/06 10:26:51 WARN DAGScheduler: Broadcasting large task binary with size 1185.8 KiB\n",
      "23/10/06 10:26:52 WARN DAGScheduler: Broadcasting large task binary with size 1301.6 KiB\n",
      "23/10/06 10:26:52 WARN DAGScheduler: Broadcasting large task binary with size 1406.5 KiB\n",
      "23/10/06 10:26:56 WARN DAGScheduler: Broadcasting large task binary with size 1121.4 KiB\n",
      "23/10/06 10:26:56 WARN DAGScheduler: Broadcasting large task binary with size 1390.3 KiB\n",
      "23/10/06 10:26:56 WARN DAGScheduler: Broadcasting large task binary with size 1660.3 KiB\n",
      "23/10/06 10:26:57 WARN DAGScheduler: Broadcasting large task binary with size 1928.2 KiB\n",
      "23/10/06 10:26:57 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "23/10/06 10:26:58 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n",
      "23/10/06 10:26:58 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "23/10/06 10:26:59 WARN DAGScheduler: Broadcasting large task binary with size 1533.7 KiB\n",
      "23/10/06 10:27:16 WARN DAGScheduler: Broadcasting large task binary with size 1110.8 KiB\n",
      "23/10/06 10:27:16 WARN DAGScheduler: Broadcasting large task binary with size 1390.5 KiB\n",
      "23/10/06 10:27:23 WARN DAGScheduler: Broadcasting large task binary with size 1056.9 KiB\n",
      "23/10/06 10:27:23 WARN DAGScheduler: Broadcasting large task binary with size 1183.4 KiB\n",
      "23/10/06 10:27:23 WARN DAGScheduler: Broadcasting large task binary with size 1299.4 KiB\n",
      "23/10/06 10:27:23 WARN DAGScheduler: Broadcasting large task binary with size 1406.5 KiB\n",
      "23/10/06 10:27:27 WARN DAGScheduler: Broadcasting large task binary with size 1110.8 KiB\n",
      "23/10/06 10:27:27 WARN DAGScheduler: Broadcasting large task binary with size 1390.5 KiB\n",
      "23/10/06 10:27:28 WARN DAGScheduler: Broadcasting large task binary with size 1668.6 KiB\n",
      "23/10/06 10:27:28 WARN DAGScheduler: Broadcasting large task binary with size 1942.3 KiB\n",
      "23/10/06 10:27:29 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "23/10/06 10:27:29 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n",
      "23/10/06 10:27:30 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "23/10/06 10:27:31 WARN DAGScheduler: Broadcasting large task binary with size 1536.3 KiB\n",
      "23/10/06 10:27:47 WARN DAGScheduler: Broadcasting large task binary with size 1128.7 KiB\n",
      "23/10/06 10:27:47 WARN DAGScheduler: Broadcasting large task binary with size 1420.9 KiB\n",
      "23/10/06 10:27:54 WARN DAGScheduler: Broadcasting large task binary with size 1063.7 KiB\n",
      "23/10/06 10:27:54 WARN DAGScheduler: Broadcasting large task binary with size 1183.4 KiB\n",
      "23/10/06 10:27:55 WARN DAGScheduler: Broadcasting large task binary with size 1287.5 KiB\n",
      "23/10/06 10:27:55 WARN DAGScheduler: Broadcasting large task binary with size 1376.9 KiB\n",
      "23/10/06 10:28:00 WARN DAGScheduler: Broadcasting large task binary with size 1128.7 KiB\n",
      "23/10/06 10:28:00 WARN DAGScheduler: Broadcasting large task binary with size 1420.9 KiB\n",
      "23/10/06 10:28:01 WARN DAGScheduler: Broadcasting large task binary with size 1721.8 KiB\n",
      "23/10/06 10:28:01 WARN DAGScheduler: Broadcasting large task binary with size 2010.9 KiB\n",
      "23/10/06 10:28:02 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "23/10/06 10:28:02 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n",
      "23/10/06 10:28:03 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "23/10/06 10:28:04 WARN DAGScheduler: Broadcasting large task binary with size 1552.5 KiB\n",
      "23/10/06 10:28:18 WARN DAGScheduler: Broadcasting large task binary with size 1113.7 KiB\n",
      "23/10/06 10:28:19 WARN DAGScheduler: Broadcasting large task binary with size 1395.3 KiB\n",
      "23/10/06 10:28:25 WARN DAGScheduler: Broadcasting large task binary with size 1031.9 KiB\n",
      "23/10/06 10:28:25 WARN DAGScheduler: Broadcasting large task binary with size 1163.7 KiB\n",
      "23/10/06 10:28:25 WARN DAGScheduler: Broadcasting large task binary with size 1284.3 KiB\n",
      "23/10/06 10:28:26 WARN DAGScheduler: Broadcasting large task binary with size 1390.9 KiB\n",
      "23/10/06 10:28:29 WARN DAGScheduler: Broadcasting large task binary with size 1113.7 KiB\n",
      "23/10/06 10:28:30 WARN DAGScheduler: Broadcasting large task binary with size 1395.3 KiB\n",
      "23/10/06 10:28:30 WARN DAGScheduler: Broadcasting large task binary with size 1690.8 KiB\n",
      "23/10/06 10:28:31 WARN DAGScheduler: Broadcasting large task binary with size 1976.2 KiB\n",
      "23/10/06 10:28:31 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "23/10/06 10:28:32 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n",
      "23/10/06 10:28:32 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "23/10/06 10:28:34 WARN DAGScheduler: Broadcasting large task binary with size 1573.1 KiB\n",
      "23/10/06 10:28:48 WARN DAGScheduler: Broadcasting large task binary with size 1106.6 KiB\n",
      "23/10/06 10:28:49 WARN DAGScheduler: Broadcasting large task binary with size 1374.0 KiB\n",
      "23/10/06 10:28:55 WARN DAGScheduler: Broadcasting large task binary with size 1082.7 KiB\n",
      "23/10/06 10:28:55 WARN DAGScheduler: Broadcasting large task binary with size 1211.7 KiB\n",
      "23/10/06 10:28:55 WARN DAGScheduler: Broadcasting large task binary with size 1326.5 KiB\n",
      "23/10/06 10:28:56 WARN DAGScheduler: Broadcasting large task binary with size 1428.3 KiB\n",
      "23/10/06 10:29:00 WARN DAGScheduler: Broadcasting large task binary with size 1106.6 KiB\n",
      "23/10/06 10:29:00 WARN DAGScheduler: Broadcasting large task binary with size 1374.0 KiB\n",
      "23/10/06 10:29:01 WARN DAGScheduler: Broadcasting large task binary with size 1644.4 KiB\n",
      "23/10/06 10:29:01 WARN DAGScheduler: Broadcasting large task binary with size 1914.3 KiB\n",
      "23/10/06 10:29:02 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "23/10/06 10:29:02 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n",
      "23/10/06 10:29:03 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n",
      "23/10/06 10:29:03 WARN DAGScheduler: Broadcasting large task binary with size 1523.7 KiB\n",
      "23/10/06 10:29:07 WARN DAGScheduler: Broadcasting large task binary with size 1160.3 KiB\n",
      "23/10/06 10:29:08 WARN DAGScheduler: Broadcasting large task binary with size 1461.6 KiB\n",
      "23/10/06 10:29:08 WARN DAGScheduler: Broadcasting large task binary with size 1773.0 KiB\n",
      "23/10/06 10:29:09 WARN DAGScheduler: Broadcasting large task binary with size 2.0 MiB\n",
      "23/10/06 10:29:10 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n",
      "23/10/06 10:29:11 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "23/10/06 10:29:12 WARN DAGScheduler: Broadcasting large task binary with size 2.8 MiB\n",
      "23/10/06 10:29:13 WARN DAGScheduler: Broadcasting large task binary with size 1647.5 KiB\n"
     ]
    }
   ],
   "source": [
    "rf_paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(rf.maxDepth, [5, 10, 15])# maximum depth for each tree\n",
    "             .addGrid(rf.numTrees,[10, 20, 40])# number of trues\n",
    "             .build())\n",
    "\n",
    "rf_cv = CrossValidator(estimator=rf, estimatorParamMaps=rf_paramGrid, \n",
    "                    evaluator=evaluator, numFolds=5)\n",
    "\n",
    "rf_cv_model = rf_cv.fit(nslkdd_df)\n",
    "\n",
    "rf_cv_prediction_test = rf_cv_model.transform(nslkdd_df_test)\n",
    "rf_cv_auc = evaluator.evaluate(rf_cv_prediction_test)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before cross-validation and parameter tuning, AUC=0.95\n",
      "After cross-validation and parameter tuning, AUC=0.96\n"
     ]
    }
   ],
   "source": [
    "print(f\"Before cross-validation and parameter tuning, AUC={np.round(rf_auc,2)}\")\n",
    "print(f\"After cross-validation and parameter tuning, AUC={np.round(rf_cv_auc,2)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/06 10:29:14 WARN DAGScheduler: Broadcasting large task binary with size 1639.9 KiB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f96fa896df0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rf_prediction_score = np.array(rf_cv_prediction_test.select(\"rawPrediction\").toPandas().values.tolist()).squeeze()\n",
    "rf_cv_fpr, rf_cv_tpr,_ = roc_curve(outcome_true,rf_prediction_score[:,1])\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(lr_cv_fpr,lr_cv_tpr,label = 'Logistic Regression')\n",
    "plt.plot(svm_cv_fpr,svm_cv_tpr,label='SVM')\n",
    "plt.plot(rf_cv_fpr,rf_cv_tpr,label='Random Forest')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Naive Bayes \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Naive bayes is a generative probability model used for classification problems. It is the prime model used for text classifications, where the number of features is very large. It is extensively used for sentiment analysis, spam filtering etc.\n",
    "\n",
    "This model is based on the Bayes Rule which can be stated as the following:\n",
    "\n",
    "<center><figure><img src=\"http://stat.cmu.edu/~mfarag/14810/l17/bayes_rule.png\"/><figcaption></figcaption></figure></center>\n",
    "<ul>\n",
    "<li>P(A|B) : (posterior probability) probability of event A to happen when event B is true.</li>\n",
    "<li>P(A) ,P(B) : probability of event A and event B to happen.</li>\n",
    "    <li>P(B|A) : (likelihood) probability of event B to happen when event A is true.</li>\n",
    "    </ul>\n",
    "\n",
    "The basic logic is to derive the probability of output label $Y = C_i$ given the input $x$ , from individual probabilities of features($x_i$) given output label as $Y = C_i$ (which can be infered from the training data).\n",
    "\n",
    "<center><figure><img src=\"http://stat.cmu.edu/~mfarag/14810/l17/naive_bayes.png\"/><figcaption></figcaption></figure></center>\n",
    "\n",
    "The major assumption of naive bayes is that all features tend to be mutually independent. It sometimes does not work well as not all data satisfy this assumption. However, it does have several advantages:\n",
    "<ul>\n",
    "    <li>It works well with less training data.</li>\n",
    "    <li>Handles irrelevant features.</li>\n",
    "    <li>Supports binary and multi-class classification problems.</li>\n",
    "    </ul>\n",
    "    \n",
    " Now, let's look at the code. The first step is to create the Estimator `NaiveBayes` and the run the `fit` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "\n",
    "nb = NaiveBayes(featuresCol = 'features', labelCol = 'outcome', modelType = \"gaussian\" )\n",
    "nb_model = nb.fit(nslkdd_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we use the fitted model to transform both the training and the test dataset, and calculate the train/test accuracy and the AUC. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy = 70.98%, test accuracy = 51.23%, AUC = 0.6\n"
     ]
    }
   ],
   "source": [
    "nb_prediction_train = nb_model.transform(nslkdd_df)\n",
    "nb_prediction_test = nb_model.transform(nslkdd_df_test)\n",
    "\n",
    "nb_accuracy_train = (nb_prediction_train.filter(nb_prediction_train.outcome == nb_prediction_train.prediction)\n",
    "    .count() / float(nb_prediction_train.count()))\n",
    "nb_accuracy_test = (nb_prediction_test.filter(nb_prediction_test.outcome == nb_prediction_test.prediction)\n",
    "    .count() / float(nb_prediction_test.count()))\n",
    "nb_auc = evaluator.evaluate(nb_prediction_test)\n",
    "\n",
    "print(f\"Train accuracy = {np.round(nb_accuracy_train*100,2)}%, test accuracy = {np.round(nb_accuracy_test*100,2)}%, AUC = {np.round(nb_auc,2)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's compare the ROC curve of all the tuned models we have tried so far. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f97096276a0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAB7aElEQVR4nO3dd3gUVdvA4d/2Ta+kQAqhg4BIL9KUasMXC4pioSj6Kio2sCE2XhtiAyxA1A8QG9iQYqEoiIKgKEiHUBJCEtKTrfP9MckmIQFSNtls8txeezEzO3Pm2UnMPHvOmXM0iqIoCCGEEEJ4iNbTAQghhBCicZNkRAghhBAeJcmIEEIIITxKkhEhhBBCeJQkI0IIIYTwKElGhBBCCOFRkowIIYQQwqMkGRFCCCGER+k9HUBlOJ1OTpw4QUBAABqNxtPhCCGEEKISFEUhJyeHpk2botWevf7DK5KREydOEBsb6+kwhBBCCFENR48eJSYm5qzve0UyEhAQAKgfJjAw0MPRCCGEEKIysrOziY2Ndd3Hz8YrkpHippnAwEBJRoQQQggvc74uFtKBVQghhBAeJcmIEEIIITxKkhEhhBBCeJQkI0IIIYTwKElGhBBCCOFRkowIIYQQwqMkGRFCCCGER0kyIoQQQgiPkmRECCGEEB5V5WRkw4YNXHnllTRt2hSNRsOKFSvOe8z69evp1q0bZrOZFi1aMH/+/OrEKoQQQogGqMrJSF5eHhdeeCFvvfVWpfY/dOgQl112Gf3792f79u089thjTJkyhc8//7zKwQohhBCi4any3DQjR45k5MiRld5//vz5xMXFMWfOHADat2/P1q1beeWVV7jmmmuqenohhBBCNDC1PlHe5s2bGTZsWJltw4cPZ8GCBdhsNgwGQ7ljLBYLFovFtZ6dnV3bYQpRaxRF4d+Mf0nKSSLXmotWU7kKSQWlSudwe5m1cP6qqkq59eGzVaXcqqi16+DhzyY/39qNodDm4O/jWaTlWvAx6Creyalw9UefoTPrCL7mJi658cFKl+9OtZ6MpKSkEBkZWWZbZGQkdrudtLQ0oqOjyx0za9YsZs6cWduhCVErnIqT9IJ0LA4Le07v4f6f7vd0SEKIxs5WftPQP5xMWu10re/ouLkOAyqr1pMRKD91cHEWeLYphadPn87UqVNd69nZ2cTGxtZegKLeUhSF9MJ07E47iqKgoOBUnOq3AwWcOF3bz3z/QOYB7E67qyyrw8qmE5sINYeW+3ZR/DtZVFKZba59ztheel1B4VT+KTYnn/9/5r5N+2LQlq8RrIiGc0+7fcbObi+zSvueZ4rwuii3KurFZ6uFn2+VY6iFzyY/39ottzJ+O5TBgVN5ABi0GsL8TYT4lfzd6bD7JONW73Ct5/soXDD0MrfGUBW1noxERUWRkpJSZltqaip6vZ6wsLAKjzGZTJhMptoOTdQDPx//mY///ZgNxzYA4GvwLfN+ni3PE2G5VYAhgIsiL+L1wa+j19ZJ/i+EaMScToUWX610re/53+Xl9klPTCSVHQDEDkjHv6kFeo+rqxDLqfW/jH369OHrr78us23NmjV07969wv4iovE4XXiau76/q8y2cyUfRq0RrUbr+rah1WjRFP+nUV9atGW+jWQUZtCvaT/XutVpRYuWiyIvcn0TcX0jcf2jKXlPU3afM7/plN6uQYPdaad9WHsuirgIP4Nfla6HEEK4wyOf/+Vann9zt4p3cqo1u4H9O+PfdBWENAed5+7JVU5GcnNz2b9/v2v90KFD7Nixg9DQUOLi4pg+fTrHjx/nww8/BGDy5Mm89dZbTJ06lUmTJrF582YWLFjA0qVL3fcphNdwKk6W/ruU//32vzLbb+lwC21C2tC5SWf0mrK/lsHmYAKMAXUZphBCeKWHPv2Tz7YdAyAiwMSIjlEV76iofUVcX7CyjtVFeGdV5WRk69atDB482LVe3Lfj1ltvJTExkeTkZJKSklzvJyQksHLlSh544AHefvttmjZtyhtvvCGP9TYyhfZC5v05j4V/Lyz33rD4YTzc42EPRCWEEA3D0Yx8rnzrZzLzS3qqLpnU++wHFPeJ0xT92/KSWozu/KqcjAwaNOicjyElJiaW2zZw4ED++OOPqp5KNBAP/PQA3yd9X277Q90fYkzbMZj1Zg9EJYQQ3s/mcHLNvE38dSyrzPbdz4zAx3iWx3kBpaiZxpWUVLJTfW2R3nSiyvJt+Xx54EuSspM4mX+SbEs26YXpHM46TFP/ptidduyKHbvTTkZhRrnj3770bQbEDPBA5EII0XA8/dU/JG46XGbb2F5xPH3lBRj15x7PyPLvv+pCcc2I9uyJS12QZERUSY41h35L+5114J2knKQKtwP8ecuflR7wSwghvIn12HFyvl+LIzMTe+opFKtVfUMpXQNRaniA4j+hilK5fc7Y93BaLgmncpmJ2vfepNPSMyEE3bcaUr45f3n5W7YAYD96EKLxaOdVkGREVNHLv7/sSkR0Gh3/7fJfmvg2IcAYgF6jx6Q34af3Q6/Vo9Pq0Gv1GLVGmvk3q7XxBIQQwpNsJ05wYMiQOj1neNGrtMITVS8nNOaouhBQfgDSuiTJiKi0AnsBy/cvB6BnVE8WDF/g4YiEEMLzsr/7zrXsN3AAplat0IeGgk5t+nB9EdNoKBlDQFO0XrRJU2r4ANcXt7L7bNqfzld/JbsqOIL9jDw0vB1GnbZceRo0YM2D04cgLxXS90FOCuQUZywKxgAHPqFFHV773OPOS1JlkoyISjmRe4Lhnw93rY/r4LnBcYQQoj4pbpIxd+pE3DvvuLXsQpuDzQfT+fi3JFZn+0HzOACevKIDEy5OKNnRboW9q+C3d+HwxvIFGYDQoldpbUbANe+DybPDJ0gyIlw2Hd/Ej0d/JN+WT6Ylk4NZB4nyi8LutPPnqT9d++k1+jIDiQkhRGNW/ISpuUMHt5S3PzWX73ef5Mfdqfx2uPxDAJ/f1ZdupuPw9f1gyYG/P4ez9OMDwBQEXcepA5v5R0L0hRAcV6oGxvMkGREAfLn/S5745Yly24/nHi+z3j60PYtGLMLg4c5OQghRbxQ/JluNe3uhzcGx0/lsOpBO4qbDZOXbSM+zltvPx6Dj9n7NuWtgCwJmx4Mtv3xhBj+I7wsJ/SGuL0ReAEbf8vvVQ5KMNHIbjm3gvp/uKzOh3I3tbiQ+MB5FUdBpdUT4RmDQGgg0BtK5SWd5IkYIIUornjxToyUjz0qBzUFajoU8q52Dp/LQaCC7wE5aroXfDmVgczjJzLeRkl141iK7x4fQv3UTLmkXQfvoAPS6or+7n9xaNhFp1h3aXQ6th0FEB9B6599nSUYaoQJ7AZ/s+YRFfy8ivTC9zHsfjfyILhFdPBOYEEJ4QL7Vzul8G2k5FnIK7RTaHKTnWci3OrA5nNgcCum5VjILrPgZ9Ww9cppmwWZ+PZhBdJCZ3uv3MBb46NcjzHt2bbViMOq0WB1ObuwZx10DWxIXVkGNxo4lsGtFyfoTqaBvGJPKSjLSCD296WlWHlpZZtsjPR7h5vY3y+O3QgivUmhzkJlvI8+qJhFpuVaSMvJxOhX+Pp5FkI+B3w9nYDLoyMy3Ynco2JxObHblnDUT57M7ORuAfam59ClVM1Is0Kwnu9DOhbHBHMvIZ2CbJoT4GQn1M2JzOGkTGUC7qABCfI0E+xrO/7c3NxVWlJpY9KF9DSYRAUlGGqUTueqjXRG+EczoM4P+zfpLEiKE8DhFUTiZbeFUjoXkrAKsDif5VgcpWYWs33uKPIsdH6OO7UmZNAkwcSrH4tbzh/sbCfY14mfUYTboCPUz4mPQoddp0Ou02OxOtBoNzcP9yLPYaRMVgAZovmIn7IUbesbx4JMjMejc3FSy5ztYekPJ+k2fgX+Ee8/hYZKMNELF/UOe6v2UDMsuhKgTNoeTfIuDApuD1JxCjp0uoNDm4N0NBwnzN3LoVB4nsipfU1FRIhIRYMJk0HIqx0KTABO9E8JIy7XQNS4EBegcE1SUXGgx6DTotVr8TGrSEWCufqf81O+NpAM+Jr37ExFFKZuI9JgErYe69xz1gCQjjZBdUZMRvVZ+/EKI6nE4FbIKbBTYHGTl2yi0O0jNtvDXsUwMOi1ZBTb+PJbJ7uRsDFotORb7+QstJSbEh2OnCxjUtgn+Jj0RAWY0GmgbGUDTYB/MBi3h/iaCfQ0Emg1otR6s3VWcRQu1EEPpppnR70Pn69x/jnpA7kaNUJ4tD5BkRAhxdvlWO8lZhZzKsbDpQDonMgs4mpHPlkMZrs6WlVVIyb46rQZFUXAq4G/SM6BNOBl5Vm7vl4BBp6FTs2CaBHhXXwjXTPbufpJlbl9I/Uddju7SYBMRkGSk0bE5bRzNUeci0Gk8O0ujEMJzLHYH6blW/k3J5nBaPn+fyOJQWh52h8LO41nnPPbMRKS4s2bbyAAcioLF7mDEBVH4GHQE+hiID/MjIdyP+DBf9zdj1AfF44y4s3bmlzdKEhGfEBi/2n1l10OSjDQyWZaSPzIdwtwzWqAQon5wOBUOnMolI8/KwVN55FvtHE7Pw2ZX2LDvFKF+RnItdo6kVzBg1jm0jvAnwKynZ0IYLcL9uKBZIJGBZoJ8DA0zuaiqopoRtz0IYLfA2ifVZZ9QeORgvRottTZIMtLIOIvaNnUaHb4G7xiZTwhRXoHVweItR1i/9xS5FjsHUnPJLjx3v4zks3QQDfUzEhPiQ8sm/gxq24SIADPRQWbiw3zlSbvKKO4z4o4BIZ1OmN+/ZP2hvQ0+EQFJRhqd4mRERlEVon4rHj8jLddCep6VL3cc52R2IWk5VvaczDnrccX9OTrHBJGSVUjflmFoNRp6JoSi02qICfHF16gjItBEVKBZkg03sOzbpy7U9FpacmFWs5L1dldAI5l6Q5KRRiStII2bvr0JkGRECE+xO5xkFdg4kpFPnsXOrhPZHMnIJ6fQztpdKYT5mcjMt5JndVSqvJ7NQ+kaH8KA1uG0aOJPkwATOk8+WdII6cLCAbClJNesoMTLSpZbD4P/zK9ZeV5EkpFG5Oovr3b1GYnwbVgD5ghRV6x2J+l56sBcuRY7qdkWth7JwKjTYXU4sNqdbDtympgQX04VzU9isTlJyS5Er9Vgd55jdlXgeGZBmfXizqGXtotAAbrGBdMuKpDWkf7EhUozSn2g0akPA5hatqp+IZvnQnLR7OhXvgHdbnVDZN5DkpFGIt+W70pEdBodSy9f6uGIhDg/p1MhPc+Kw6lgdzqxOxTsTgWr3UmuxY7N4cTuVLAXzR9y7HQ+vkY9Cuqjo4qi4HSqy05FQVFwvVe87nQqHDtdgI9RvaFsTzpN02AfCm0ONh9Mp0W4P4U2BwfT8qoU+4FT5fc/MxGJC/XFz6QnNsSHUD8jEYFmIgNNdG4WTIifgWbBPpJseIOi5m+Nvpq31LT9sHq6uhzZsdElIiDJSKPgcDr4z5f/ca3/fMPP+Bv9PRiRaAjsDiepORbyLOokY3ank9N5NtLzLGg0GrILbCRnFaBBg9XuZHdKNsG+RjSoo3HmWez8fSKblk38sDvVpMGhKDidYHc6cTghLde9w31X1p/HSp4621U0B8mZgnwMZBXY6B4fQmSgmVM5Fnq3DMOk12LSaym0OWgbFUiIrwGzQYdJr8Vs0OFv0mM26DAbtJJoNBCKswbjjCgKLBxesn7tIvcE5WUkGWngDmYeZNrGaZzIU+ejue2C2yQRESiKgtXhJLvATlaBldQcCw6nwvHTBTgVNVnYezKHQpsTm8PJ8cwCTudZ8Tfr+etYFuH+RtJyrW6JZe/J3PPuo9dq1PlBtFp0Wg16rQaTXkuA2VC0XZ07RKfVsCclh15FnTW1Gg0aDWg1GrQa9dHL0uvq++ryqRwLMSG+hPoZyMy30SYqALNBh8PpJDrIB7NBR6BZT7CvkZDKTGwmGg9nUc1Idfrq/P4+5Kepy/95B5q0cWNg3kOSkQYs35bP5O8nk5yndqqaM2gOl8Zf6uGoRE0pioLNoZBTaMNid1Joc5CRZyUluxCnovZpyCm0cSKzAF+jnl8PpqPVaEjPs5BncXA630qBzVE8NEK1lE5Eivs0hPoZaRbsQ67FToBZT0K4H3qtlgCzniYBJow6LdmFNmJC1Bu7Uad1DeEd5GNwJQ96rca1rD794YOfSf5UiXqsuo/25qXByodK1i+84ez7NnDyf3gDdTT7KA9teMiViEzrOU0SkXosq8DG0Yx8jp0uwO50siclh+/+TkGn0WB1OLHa1doJH4MOi93BefpAVkmgWY+PUcfJbAtdYoM5djqfLrEhBProsdiddGoWRIBZ/VPhZ9QTEWDCx6gj3N9ETIj0aRCiysPBO2xw9LeyT8/c/av7A/Mikow0QL8m/8qkNZMACDGF8MYlb9Alootng2oE7A4nGXlqrUNmvo2MPCupOYXkWRwkZeSj0YAGDZkFVnadyCbY18Cx0wUcO11w/sKLFNjKP+4ZYNaTb3Vg1muxOxV6tQjDrNeioI5V0T46EKdToV+rcIJ9Dfib1KYGk0GLWa/DqJfHvIWokXMNB+90QsFpOPEHHPgRfp1bfp+RL0NE+9qNsZ6TZKQBWn90vWv5o8s+Ij4w3oPReC+L3cHxomShwObg2OkC8opmHj2cnsfu5BzMBi0FVgf/puRU6rHN8/Ez6rA5Ffq1DMPXqKdvqzDaRAZgKJry3KjTEuhjwKzX4WdSp0IXQtQBpwOseeCwqjUbTpv6b2EWnFbn+9Ls+hK++hVO/QunD0PuyXOX2bw/DHgIWgyq9fDrO0lGGpgDmQf4NVmt7hvVcpQkIqU4nAqZ+VaSswpJzipk25HTJGcV8M+JbJr4m8jIU0e2DPZVOzBWVXEi4mfU4WPUE+5vpEmAiWBfI2a9OqV6RKCJcH8TBp0WrUZDu+gA4kN9CfM3EeTTOEZaFMLtFAWcdrAXgjUfbHlgt4LDAvnpgEZ932FTkwlrrrqfw6omFRmHQKuHfWvAFKhuS9urLjus6ks5+yzFyvEQwAcObwD9Web98QkFcxC0vAQiO0DX20Ant+BiciUakMS/E3l126sABBgCuLbNtR6OyHMUReGjX4+w60Q2R0/nsz81l5PZZ39MdH9qyRMdpRMRg05DVJCZk1kWLowNwmp3EhVkpmmwD1a7Ez+Tnv6twzEbdIT4GmkR7ufqlCmEqCK7BQqzSxKAwizIOqp29Mw8onYQPbEdso6DfwQc3li78VgqfqwbjU4dpl1rAL0JjL6AHULiYdDVYPQHv3AIa6XG6dcEDD61G6uXk2Skgfg3419XIhLjH8OiEYuI8ovycFSecSgtj8GvrDvnPn5GHT0SQnE4FVpF+NMs2Ie4UF+Mei1+Jj0hvkbC/Y0Emg2SXAhxNrYCKMhU+0TYCyD3FKCo29P3qzUBTrv6On0EFIeaUKQVzeVyag/kpYLBF2xVm0mYtD3nft8nBHQm9dz5aRB9oZo86IxqImEOUhOJ4vWCTAhpriYSTbuAbyjozWAKKNrHqK7rzeU6qjp33Q6HfkUz6GEYdE3VPocAJBlpEP489Sc3r7zZtf7t6G8b7dwzs9fu5Y0f9pXZ9sTl7WnZxJ+WTfxpGmyWfhaicXM61JoGW75a82DJKekHUXBabcLISyv691RRspGh7qs41STDJ0Td113OTESKb/46g3oeUxDE91ETi4j2aqyBzSC8jVrjEBJflFyY1QSkOoOP1UD+r0VPwmh1dXrehkSSES+XZckqk4hM7zm90SUidoeTjfvTmLpsB6dLNbG8fkMXRnVpdo4jhfBSdqvahFCYBTnJarOFvUBNLPLS4OgWtZnAboWTf6s36YwD1auBqEhFiUhgDBjMarLSvL+aSJw+As26qf0xtDoozISgWAiIUpONkAS130RIghqb3qQmOl72uLjW3x9nbi6mFgmeDsVrSTLi5f5O+9u1/Fivx7ix3Y0ejKZu7T2Zw/jE38s9GtskwMTyu/sSE+LrociEqIGcFPVpjKxjcGwrHN+mJh22fLWmoiZKJyJ6HzD6gU+wuqwrasIozATfcHW7KUDt82AMAP8maidM31C1Y6dPsPqvKUBqBIpGYNWFhno4EO8lyYiX23NabTcNNAY2mkREURTe+nE/r67dW2b7wDZNmNS/BRe3DvdQZEJUQFHUG/zpI2otRto+td9E7kk49rvaGfLoFjUZqE6tRUC0Wm5wHDRpD0HNwC9CrSWJaKcmGopDbdYwB4J/lFpr0tgTCDdyDXrWyGql3UmSES/3b8a/AET6RXo4krqhKAoDXv6JoxkltSF3DGjBQ8PayuBdwnPyMyDpVzi1W31kNPekWqORuqvyZThLPU4eGKN2ptSb1CaOJm0grg8ENlVrI3zD1FoNnTwOXi/UZG4aAUgy4tWcipN9p9XOmoNiBnk2mDpgsTsYMnu9KxHp1yqMj8b3kqddRN1QFLW5JP0A/PuNWquRkwLp+85/bDGNTh1jwm6FFgPBPxJQILSl+hRHQKS6bJLJLL2Ks3huGvlbVF2SjHgpp+Jk6GdDSc1PBeDiZhd7OKLapSgKN7z7qysReXh4W/47uJWHoxINkt0Ce1aqzSl5aWqHzAM/qFXw5xj4ClCTjeYXQ0QHCGupdhyN7qyON2H0q5v4RZ2r8tw0ohxJRrzUy7+/7EpE+kT3oVN4Jw9HVHvScy10e+571/qtfeIlERE1V5AJO5aozSN/fqzWfOSdKpnO/UylE5GmF6mPkCb0h/h+ENVJ7YchGiepGakxSUa80D/p//B/u//Ptf7usHc9GE3tWv1PCnd+tM21flOvOGaO6ujBiIRXyjgEB3+C7GTY8FLljglJgHaXq00p0Z3VPhx+TdRHUOWmI0pz9RmRmpHqkmTECx3IPOBa/vyqzz0YSe3JyrfR84XvsdhLvo0uuq0Hg9tFeDAqUa84bOrQ4fZC9ZWfoQ7elb5fndBsxxK1A+jxrecvq/MYdeyMTtdDs65qR1EZvltUgquJBqSZpgYkGfFC+zP3AzAgZgBtQtp4OBr3yi60cdf/beOX/emubbGhPqy6bwB+Jvl1bfCs+epjqplHIOckHPlFTTKcdrU5JelXNeEAdVtVtbwEmnZV+3JcOEYdgEtqOURNOEs138nvUrXJX3cvFGgMBOBE7gkPR+JeP+w+yYQPyn6L/e/gljw4tK08MdOQKQocWg8fjqp+GaZANTmx5UNUZ3VytVZD1ZE+Ww1RB+aKvECtKRHCnUrVjEgzTfVJMuKFcq3qDLPdIrt5OBL3+edEVplEZGCbJsy7uSu+RvkVbdB2fgafTyi/vXhkz7g+6rwooS3UeUiCYtQEIyBabUYx+stYG8Kj7CdPlqxIzUi1yV96L7Tg7wVASQ2Jt9ufmsPlb/zsWp9/c1dGdIz2YESiVmWfgH+/heN/wJ9Lyr532SvQY6L8URdewXLoEIevuVZd0WrRGCQxri5JRrzMj0k/upb7x/T3YCTuservFO5aXPK0zLOjLpBEpD5SFHW2V8Wh/mvLVzuQOizqWBxOR9HMrxY4uA7MwUXHFE0fv3eVuh+KOjrpma6eB13G1vGHEqJm0ufPx5mvDuEf9eQTaH2k03N1STLiZT745wNArRW5KOIiD0dTPScyC3j087/YuK9kPAeTXsvDw9syrk9zzwVWFxRFffLDVjTDavHN2ukotWxXZ2R12NRX8TZbgdq50xSg3vgtuZBxUG2yKE4SFOcZy051wjWnXZ0NtfQ5nE7IS1VHEQ2IVmd9zUxSmz6KEw/FqS6jnPejVVlYa4jtCR2vgVaXur98IWqZLUVNrP0HDybkxsYxN1htkWTEizgVJ3+k/gF474irK7Yf5/5lO8ptX//wYKKCzHUbjNNZ9A3fqt70bXklj4c6bOrTG4VZ6hMeGo06Muepf9UZTR0WNTk4+Y/aj8FhU4+z5qlTtoe2VI8vLidlZ91+tqqyZJcsF/VJqhS9j5rEADRpV9R/QwMpf0HXW9V1rV59OWzQcjBEd1H7fUhTjPBy+Vu2AOBzkXd+MaxPJBnxIh//+7Fr+eEeD3swkup5be1eXv+hZB6PQW2bcEf/FvRuEVb1p2UURa1ZsOSoHRzz09VmAMVZkjSYAuDEdnWgKmueOrpmYZZ6ozQFlr0Bu1tOcuX39QkpuWFr9epsqnqzWkOh1Rfd0HUlN/TCLPXJEJ1R/byFmepw4xqdup9Gq75cyzr18xt9y55Lo1X/VZzqQF4+IaA3qiOLGsylyqugXL0P6OTPh2i8CneVTILo21WSkZqSvyZewOKw0P3/urvWNWgI9/GeoaftDiednl5Dgc3h2vbdff1pH32ODrjWfHUG1KxjcGKH2qxw5Bd1JlR3KJeIaNTHPk2B6jTrWoN6s9Ua1OHBfUIhOFZNADKPqsOB643qjbowS00GdEb1GI1WTRoCoopu/EVl6UxqLYpPsJpsyFMgQnitnJ9+ci37du9+jj1FZUgy4gX+OvWXa1mn0fHywJc9GE3VTPzgd77fnepaD/Y18POjl+BfPIBZxiE4/LN6wz+2FY5uUWswqqK4lsMcrCYAwfFqopCdrPZJsGRDxAXqRGX+kWqNicEH/CPUY/Tmom/+0mwghKgkh/rlytyhg4cDaRgkGfGwpf8u5ZuD35xzn9LJyM83/Iy/sf5PL348s4B+//uxzLaezUNZdmdvNKm74M+l8Ou8yo2iGdVZTRZieqhNCVGd1JoJnxCZCVUI4RGKQx151adrVw9H0jBIMuJB6QXpvLDlhUrvPzR+qFckIgCTPyrbnLLrmeHqAGYfXq1OWHamwGZq50ZzMLQYrPaJkE6OQoj6yqnWjGh0MuqqO0gy4kFfHvjStfzCxS/gbzh7oqHT6uge6T3tkscz1ScsOjYL5Jt7+6tPriwbVzYRGfa8OraEb6iHohRCiOpRiuek0eo8G0gDIcmIB/18XB11tJl/M65seaWHo3GfBT8fIiNPnczs6SsvgJS/YX6/kh3i+8Ft30qthxDCexU100jNiHtIMuJBxRPdJQQleDgS9/jnRFaZYd1BodsXF0P28ZJNTdrDLV9JIiKE8GpKUTON1Iy4hyQjHmJxWDieq96kb2znnSP3HTyVy87jWXy/O5Wv/yw7g3Br7THWGh+B0k/Q9rsPhj5Tt0EKIYQb2Y4fx3LwELako+oGqRlxC0lGPCTHmuNa7te03zn2rH/K14CUdU17X15JfQXyija0GQljPz7r/kIIUR85cnPJ+vJLsr/+BnQ6CraVH+dIazJ5ILKGp1rJyNy5c3n55ZdJTk7mggsuYM6cOfTvf/ZJ2xYvXsxLL73Evn37CAoKYsSIEbzyyiuEhYVVO3BvV5yM6DV6dF5Szff9rpMs/OUQmw6kl9k+uG0TooLM3Nq3Oe2su+Cj/6jDrAOMfAl63emBaIUQovIUmw3r0aPYkpOx7NuHLekop5csOfsBej2Bw4YSdGXD6e/nSVVORpYtW8b999/P3Llz6devH++88w4jR45k165dxMXFldv/559/5pZbbuG1117jyiuv5Pjx40yePJmJEyeyfPlyt3wIb+NwOrhqxVUAaLyg74SiKEz5eEeZppj20YFc3z2G2/uV6u9SmA3/G16yPulHaNatDiMVQoizUxQF66FDFOz4k+xV36ExGCn4608cp9LOeVzA0KGYO3XCp1NHTO3aoQ8JqaOIG48qJyOzZ89mwoQJTJw4EYA5c+awevVq5s2bx6xZs8rt/+uvv9K8eXOmTJkCQEJCAnfeeScvvfRSDUP3XsWT3QFc3/Z6D0Zyfla7kzZPfOdav6BpII9d1p5+rc4Yjr4gE16ML1m/5UtJRIQQHuXIzSN/y6/k/PAjln37KNxZuQkr9U2j0fn5Y4iPI/Tmm/Hr3buWIxVVSkasVivbtm1j2rRpZbYPGzaMTZs2VXhM3759efzxx1m5ciUjR44kNTWVzz77jMsvv/ys57FYLFgsFtd6dnYtTmhWC5yKk5mbZ7Lv9D4URcGJE0VRUFBwKk72nt7r2ndaz2nnKMmzrHYntyzc4lpvFxXAt1MqaI7buwaWXFeyPuJ/0GJQ7QcohBAVUJxOMhYtIvXlVyreQa8n+Jpr0AUGYGrTBo1ej7l9ewxxcWi00iHVE6qUjKSlpeFwOIiMjCyzPTIykpSUlAqP6du3L4sXL2bMmDEUFhZit9u56qqrePPNN896nlmzZjFz5syqhFavDP98OCl5FV+P0m5qf1MdRFM9+VY7ff/3I5n5NgCu7x7DS9deWH7Hf1bAp7eWrDfvD70m102QQghxBkVR2HdxfxwZGa5t/oMGoQsKwrdnTwIvvwyt2ezBCEVFqtWB9cx+DoqinLXvw65du5gyZQpPPfUUw4cPJzk5mYcffpjJkyezYMGCCo+ZPn06U6dOda1nZ2cTGxtbnVDrXGp+aplE5O1L30aDBo1GgxYtGo26bNaZ6RTeyYORnt3RjHxuXrDFlYg8NKwN91zSuuxOJ3fBR1dD7smSbVfPhy7e+ZiyEKJhOHbvva5EJOzOOwm/a7IkH16gSslIeHg4Op2uXC1IampqudqSYrNmzaJfv348/PDDAHTu3Bk/Pz/69+/Pc889R3R0dLljTCYTJi99XGrbyZJHv7aP245e6z1PT1vtTl5e/S/vbTzk2nb3oJblE5G0/TCvT9ltt6+C+DO2CSFEHbIlJ5P7/Q8AaAMCiHjgfs8GJCqtSndKo9FIt27dWLt2Lf/5z39c29euXcuoUaMqPCY/Px+9vuxpdDr1UVZFUaoab7227/Q+HtnwCACxAbFek4goisKy34/yypo9pOVaXdunjWzH5IEtS3a0W2Dz2/BDqSa0W76CFgPrMFohhCjPkZ3N/sGXuNZbfHvu2dBF/VLlu+XUqVMZN24c3bt3p0+fPrz77rskJSUxebLaT2D69OkcP36cDz/8EIArr7ySSZMmMW/ePFczzf3330/Pnj1p2rSpez+Nh209udW1fGncpR6MpPKcToXhczawLzXXte3uQS25c2BLgnwM6gZLLmx6E9b/r+RAUyDc/DnE9qzjiIUQorzcDRtdy3GLFmKIiPBgNKKqqpyMjBkzhvT0dJ555hmSk5Pp2LEjK1euJD5efawzOTmZpKQk1/633XYbOTk5vPXWWzz44IMEBwdzySWX8OKLL7rvU9QTVodaqzAkbggPdn/Qw9FUzsyv/3ElImN7xfHE5e3xNRb9WigKrLgL/lxa9qDuE+CSJ2S2XSFEvZH99dcAmC/sjF8faTL2NtVqR7j77ru5++67K3wvMTGx3LZ7772Xe++9tzqn8iqHsw8DEGgK9GwglbTrRDYfbD4CwOiuzXjhP6U61B7bBu9fUvaAS56AXneByb8OoxRCiPNTbOqXQZ2f/H3yRt7RqcFLbDi2AQAN9X9U1cx8K5e9oVZrGvVaXr2u6LHdrOPw7VTYu6pk54CmcMdPEBDlgUiFEOL8ivsgBv3nas8GIqpFkhE3sTvtpOanAhAXWH5Y/PqmyzNrXcvL7+6LZv8P6sBlirPsjuNWQMvBdRucEEJUlbPogQgZtMwrSTLiJuuOrnMtj2pZ8ZNF9UXJHDMKj4f/zAWfPg6nD5Xd6dpF0OFq+R9bCOEdnOoXKRlB1TtJMuImO9PUOQ/MOjNhPvV3NmJFUbh36XbiNSnMN8yhfW5SqXc1cMVr0PVWSUKEEN6leKgIjfzt8kaSjLhJni0PgH7N+nk4krNw2ODIL+xbt4QPDbsYoCs1YdRFN8MFo6HFYElChBBeyTVulbb+99kT5Uky4iYHsw4CEOFbz55tP+OpmDZAG13Rin8kXLsQml/skdCEEMJtipppOMvUJKJ+k2TETX5P+R2AZv7NPBxJEacTdn4Ky+8oszlb8eVTx0BuuvUuzC0vBq3uLAUIIYQXkT4jXk2SETfRa/XYnXYubFLBzLZ1zemAt3pAxgF1XWtgT9OrGbF/FApa/ju4JebW7TwboxBCuJEifUa8miQjblBoL8TutAPQPLC5Z4NRFHim1MiozfszJ+J55mw45tr08HBJRIQQDUxxM430GfFKkoy4QVpBmms5yBTkwUiATW+4Fm3NBzEk9T6O/FuSiKx/eJAHghJCiFpWVDOikT4jXkmSETcorh70M/h59n8EWwGsfQoAuymE1v/eARS43v7xwYHEh/l5KDghhKg9SvGAjdJnxCtJMuIGDsUBgBYP/0/wShvX4hXZj7qWn7u6Izf3jvdEREIIUScsu3arC9JnxCtJMuIGTtSMXOuhjFxRFDL+73bCLNkAfO3ozb9KHFoNbHhkMDEhvh6JSwgh6oouNBRHRgaK1erpUEQ1SDLiBvm2fMAzNSM/70vjwf/byBbNcte2e21TmHJpa6YObXOOI4UQouHQmE0A6MPr7wjY4uwkGXGDQnshAKctp+vsnEt/S+J/3/1LVoGNw+bbXNvXjfyBQz27SScuIUTj4pooT8ZO8kaSjLhBoUNNRtqGtK31c+VZ7Ayfs4Fjp9WOqR01B0vebDWUQb2613oMQghR7zjUvnsanfQZ8UaSjLhBjjUHgABjQK2e56PNh3nyy39c6wbsfGN6omSHsZ/U6vmFEKK+UpzyNI03k5+aG6TkpQDQxLdJrZ1jx9FMVyKi1cDrN3RhX/evSna4/Tv5n1AI0XjJcPBeTWpG3GDDsQ0AxAfWzuOzWfk2rn9ns2v9r6eH4+/MhRWfqRvC20J831o5txBCeANXzYhO+ox4I0kha0hRFP7N+BeAS+MurZVz9H/pR6x29X+0Vff3x9+eBS+WSnxu+rRWziuEEF6juM+I1Ix4Jfmp1VB6YTq5tlw0aGgR1MLt5edb7WQXqvPe3DWoJe2CnPByqfP0nQIhMqCZEKJxc+bmqgtSM+KVpJmmhg5nHQagqX9TjDqj28t//lt1VEG9VsMjw9rArGYlb14wGoY96/ZzCiGEN3GWGuhM6+/vwUhEdUnNSA1tOrEJgJiAGLeXbbU7WbwlCYAWTfzQ/DATigZYY+A0uG6R288phBDexp6S4lrWBQZ6MBJRXZKM1FBxfxGD1uD2sj/YdNi1/OI1nSHpV3UlYSAMnu728wkhhDeyHj7sWtZIM41XkmSkBvJt+Ww8vhGA3tG93Vr2qRwLs75Tm2hu7h3HRU194WhRMnLJk249lxBCeDPXkzTCa0kyUgPv7XzPtdwrupfbylUUhVsW/oZTAT+jjmkj28OBn0p2iOrotnMJIYTXK3qSxufCCz0ciKguSUZqIDU/FYB+TfvRLrSd28p9YsXf7E5WZ+B9+boL8TfpYekY9c2AaDD4uO1cQgjh7RS7moxgkGcyvJUkIzWw/th6AC5vcbnbykzPtbg6rZoNWi7rFA25qSU79L3XbecSQogGwaEOf6DRSTLirSQZqYEsSxYAwaZgt5X58/401/K3U/qrC989WrJDn/+67VxCCNEQFPy1E5DOq95MkpFqyijMcC27cxj49zceAqBLbDAtmxQ9L//PF+q/3W5323mEEKKhyPi//1MXNBrPBiKqTZKRalp/dL1rOTYg1m3l7jyu1rb4Gosy/KO/lbzZ/0G3nUcIIRoKrckEQMhNN3k4ElFdkoxU08pDKwFoG9IWjZuy8eL5ZwCmXNpaXUj+s2SHYPclPUII0VAUP9pratPaw5GI6pJkpBpWH17Nr8nqmB8DYga4rdzjmQWu5V4JoerCnx+r/8b0cNt5hBCiQZFJ8rye/OSq4aH1D7mWx7Yf67ZyLcWPp4Fa26IocHyruiHBfUmPEEI0JEpRMiKT5HkvSUaqKL94bhjgqT5PEe4T7raybXYFgOggs7ph14qSN/vd57bzCCFEg1JcMyLJiNeSZKSKvtj3hWv5ujbXubVsW1G7p15X1Afl5znqv+ZgMAe59VxCCNEQlBkKXpIRryXJSBW9+PuLtVb2iaI+IwatFgoyIXmH+sZ/5tfaOYUQwps5Tp92LUufEe8lP7kqahPSBoA7O9/p9rKLh4A/mJYHP71Q8kbr4W4/lxBCNASWPXtcy9rAQA9GImpCkpEqcipqlWCPKPc/3bLvZC4AFzQNhK0L1Y0xPUGyfSGEqJCzsBAAU7t2bhtmQdQ9uctV0f7M/QCYdCa3l138aO/I4GPgtKkb+01x+3mEEKKhyN+iDgyp8/f3cCSiJiQZqYLST9IEGAPcXv4/J9RmmmsyF5ZsbDPS7ecRQoiGIu9Xdcwne+bp8+wp6jNJRqrgeO5x13LzwOa1cg4dDiKy/1ZX2l8FMgulEEJUyHbypKvPiG8PGRjSm0kyUgW2oqaTCJ8IdFr3PkKWmq22e07UrURnL6qBueI1t55DCCEakuNTSsZfajJFmrS9mSQjVVCcjBh0BreXvflgOgD36perG1peCn7uG1BNCCEakpwff6LgT3XurqBrRqMPCfFwRKImJBmpglP5pwAwaN2fjMxbdwAfCvHXqDUk9L3X7ecQQoiG4vTSpQDogoKIfvZZD0cjakqSkSrIL2o+OZZ7zK3lKorCvyk5TNZ/XbKxxSC3nkMIIRoKp8VC3saNAEQ+8YQMdtYAyE+wCnan7wagV1Qvt5Z7MtsCwDU69X8uzEEgz8sLIUQ5mctXsK9PX9e6/+BBHotFuI88qlEFf55S2ydxc57wf78ewYiNaNR+Iwx81L0nEEIIL2Y7fpyMxUvIWbMG27GSmmlTh/YyvkgDIclIFaQXqMlCjH+MW8s9mJbLCO3v6DTqrL30vtut5QshhLfK/Owzkp94stz26Oeexf/SSz0QkagNkoxUQbZVHZSsXWg7t5a7YW8aX+o/V1fajJQmGiGEKFImEdFoiJw+jZAbbkBjNHouKOF2koxUgb/Rn1xbLi2CWri13JgQH1pmJqsrUR3dWrYQQnirk/8rmSU9Zu7bBFxyiQejEbVJOrBWgdVhBcDP4OfWcl2DnAF0ut6tZQshhDdyWixkJCaqK1qtJCINnNSMVEFGYQYARp17qweH5ywv6RQb3tqtZQshRH2nWK04cnNx5ueT/c23nJozp8z7MW+95ZnARJ2RZKSS7E67a9mtk+TZCridLwFI7XQnEdJfRAjRiGR/9x3HH5h61vfNnTrhP3BAHUYkPEGSkUoqbqIBNzfT7P6GAE0BNkWHddAT7itXCCHqsdz16znxxBM4TqW5tmkMBjQ+PqAoBAwbSsTUqejDwjwYpagrkoxUUvGTNAAmnclt5dqPbEYPbHR2oquP2W3lCiFEfWU9epSjd04usy3hyy8xt23joYiEp1WrA+vcuXNJSEjAbDbTrVs3NhYNy3s2FouFxx9/nPj4eEwmEy1btmThwoXVCthTLA6La1mrcV+/X82elQAcVZoQ5OP+OW+EEKI+sR47xoGhw1zrUTNn0u7vnZKINHJVrhlZtmwZ999/P3PnzqVfv3688847jBw5kl27dhEXF1fhMddffz0nT55kwYIFtGrVitTUVOx2e4X71lcOpwOAIFOQW8vV5aqP9B7WxqGR/iJCiAZKURSOT5lCztrvXdtCb72VkDHyBKGoRjIye/ZsJkyYwMSJEwGYM2cOq1evZt68ecyaNavc/qtWrWL9+vUcPHiQ0NBQAJo3b16zqD3AoajJiE6jc1+hWcddi1u0F7mvXCGEqGcOj7mBwr/+cq0HXTOayOnTPBiRqE+q1N5gtVrZtm0bw4YNK7N92LBhbNq0qcJjvvrqK7p3785LL71Es2bNaNOmDQ899BAFBQVnPY/FYiE7O7vMy9OcihNwbxMNu0tm6d1VGOq+coUQwsMcuXnYkpPJXrOG/UOGlklEElYsJ/q55zwYnahvqlQzkpaWhsPhIDIyssz2yMhIUlJSKjzm4MGD/Pzzz5jNZpYvX05aWhp33303GRkZZ+03MmvWLGbOnFmV0Gpdcc2IW5MRi5pkZSu+tI6QyZ6EEA3DyVmzyPjwI1CUMtv9Lr6Y2Hlz0Rikf5woq1pP05zZt0FRlLP2d3A6nWg0GhYvXkxQkNrfYvbs2Vx77bW8/fbb+Pj4lDtm+vTpTJ1a8tx5dnY2sbGx1QnVbYprRtzaTGNXO8X+7OxIod3hvnKFEKKOOXJzyf52JSdffBElv2RUaW1gIDp/f8LuuIOQG8Z4MEJRn1UpGQkPD0en05WrBUlNTS1XW1IsOjqaZs2auRIRgPbt26MoCseOHaN16/IjjppMJkwm9z0+6w55tjzAzcnI3lUAJCmRhPrKpE9CCO+iOJ1kf/cd6e++h2XPnjLvBQwfTrM5r0nHfFEpVWpzMBqNdOvWjbVr15bZvnbtWvr27VvhMf369ePEiRPk5ua6tu3duxetVktMTEw1QvaMQnshAMdyj7mv0JN/q2Uq4cSFuXe+GyGEqE3206fZ1+9iTjz4UJlExLdHD1p8t5KY1+dIIiIqrcodIKZOncr777/PwoUL2b17Nw888ABJSUlMnqwOYDN9+nRuueUW1/5jx44lLCyM22+/nV27drFhwwYefvhhxo8fX2ETTX2loLZ9JgQluKdAh821+IuzI3kW73rUWQjRODktFrJXr2Ffn744Tp8GIPDyy4l69hna/b2T+I8+xJTgpr+TotGocp+RMWPGkJ6ezjPPPENycjIdO3Zk5cqVxMfHA5CcnExSUpJrf39/f9auXcu9995L9+7dCQsL4/rrr+c5L+tJXTw3TbAp2D0F5pQ0dR1WIrm5Vbh7yhVCiFqQu2ED6e++R/7WrWW2h02cQMRDD3koKtFQVKsD6913383dd99d4XuJxVM+l9KuXbtyTTvexuZUazL0WjeNoJ++z7WooMXucLqnXCGEqCJFUcBmw2mx4MzOJn/7Dpw52VgPH8aRk0vWF1+UPUCjQR8RQfjkOwm58UbPBC0aFJmbppK2JG8BQK9x0yU7uB6ANCUQgPbRge4pVwjhtRRFQbFYcGRl4czPB4cDe0YGitUGTgeKwwFOJ4rdUbTuBKcDZ0EhSmEBis2GYrNhPX4cFAWNwYBitVH499/oIyPVY61WbMnJKE4HitWGUliIs1SfvnMxtW5FxCOP4ndxP+kPItxKkpFK8tGr/VtS81PdU+AvcwA4qEQD0L15iHvKFUJ4jDMvD/vpTByZmSiFBTgtFuwnU3EW5GM9cgRb0lF0QUEoNiuWAwcBsKek4LRa0ZrNrj4YtcGyd2/ldtRoXOODBF55JUphIeZOnQi8bCRGL3roQHgXSUYqqXjQsyHxQ2peWH6Ga/ErR18Swv3wNcqPQoj6RFEUHBkZ2FNTcebl4bRYUCwWrElJWA8dxnJgP1o/PzXZyM/HVqqvXHU4KhiVWhcSAnodjlNpmDt0AJ0OjVZb9l+dFrQ6tL6+aH190RgMaAwGnHm5aAOD0IeHozEZcWRmYoxvjtZkRGM0gk6HoWlTNAZ1Xevni9bPTz1eaj1EHZM7YCVtOLYBAJ3WDeOM/P25a/H/HEOItsmAZ0LUJUdWFtajx7CdOE7epk2ggD0tDUdWJoV/7USxWmtUvi4kBMfp0xhbtUTr64ct+QSm5gloAwLQhQRjbtsWjcmMYrOhDw9D6+ODPioarZ8fugB/tAEBarIhRCMhyUglWR3qH6cC+9nn1Km0wz+XWtHQXMYYEaJCisOBUliIIy8PJT8fxWbDabXizM5W+0fY7Tjz8rClpKA1mbEeOwpOBY1Oi9NioWDHn+j8/bEeOYIuJATLgQPgqF7yb2rdGo3ZjEarxZGTg6llS4ytWuLTqTO64CC0vr4YoqPRBbl3Zm8hGgNJRirpVMEpADqFd6p5YbtWALDQPgKA3i3Cal6mEF5EURScefk4MjNxnM7AlpKC7cgRLPsPkPXtt+iDg7GfOuXWc55ZntbfH2duLgFDh6AoCn49eqALDUVjNKH1MWNo2hRDTAxas9mtcQghypNkpJICjAHkWHOID4yvWUEntrsWlzguAeCWPjUsU4h6ypGbR+HOv8hdvwHLvn1o9HpyN24E57kfZT9bIqILCUFjVPs42I4exdSuHbqAABSnE2dBPua27XDm5qILDVX7ShiNOPPzMbVIQOPriz4sDI3RhDEuFl2gPMEmRH0hyUglKUW9y826Gn5LWv8yAAW+TdlfqPZMD/GTeWlEw5Kzbh3J06bjyMw87766sDD0ERGgAa3JTNDo/2BKSEAXFqb2oQgMRGMySadKIRowSUYqqXjW3hr9QXTYYM+3AMzKuwqATs2kfVnUT4rdjjM3F0dODo70dJyFFqxJR9Do9ChWC9YjSWgMegr/2YUuPAzFYsVZWIBlz17sZ0ymaYiLw9SqFcbmzfHp3AljQgsMzZqh85f+UkIISUYqrXhuGq2mBj3cj/7mWlxs6QfApe0jahSXEJWl9tPIw37qFPbkZOynT2PZtw/rocPYU1LQ+PqQv3Ub2GznL6wSfHv1IvCyywi+/jqp1RBCnJMkI5XkcKo98LVVn1uwxPGSOR0cqI8I/3dwqxrFVVucVitKYaE6+JGiqM1UZ7wUpwJUZpsTNZdTcBYUgM3mavYq3q4uK67BllznLH67eJnq7aPYbDgyTqP18yt6r/w51c9IyXbXvxWd78x9lTLHKWU+y9nLq+i8lr17MTSNVq+bUwHFWbLsdKIoxdtL3nOczsSekoIuPBzFYiH/998xtmiBYrViTUqqcYKhCwvDkZ6OuXNnbElJ+PbogcZkUseuaJGAUmjB1LYNWpMJrX8APl0vwhAhibYQonIkGakkJ25opknZCcAJUwsohHZRARh09WcsAUVRSHvzLdLmzgWdrtqPQIr6wbJ79znf1wYEYGrTBsViwRAbg7ltW4wJLdD6+mBo2hRdaKg6kJbJVEcRCyEaK0lGKqn4G7FOU4NBz3Z+CsDW/EgAxtWjp2iOP/gQ2d9+W7LhfImIVqsOG1300lRhmyMrC0OzZup7UPRe0SJF+7q2a8rvo9FQauUs+xeVVWq7IzMTnE4M8XHnKYOS5erGVFE8rkT2jDLOPK/Die1kCub2HdBoNaDRglZbZhkN6qBYGi1oNWi0WpxWKxq9HkOzZmiNRhSHE31EBFqTEXR69OFh6AID1dohIYSoRyQZqaQad2DNPOpa/MFxEQBD2kfWOC53OP7Qw2USEUNsLM1efQVzu3YlN9SipELa/oUQQribJCOVoChKzTuw7lvjWvzS2Y8mASYiA+vHYErZ33yjLmg0tP1jG1ofH88GJIQQolGpPx0W6rHiWhGoQQfWzW8B8KvmQkDDA0PauCGymsteudK13HLVd5KICCGEqHOSjFTC8dzjrmWzvpq1GRnqdOE/W9ug1cCoLk3dEVqNOK1Wjk99EFCfljDG158+LEIIIRoPSUYqodBRCIBJZ6peMuIoeaxyk/MCYkJ88TN5voVs/6DBruWoJ5/0YCRCCCEaM0lGKqG4mSbQWM25LE7+41rcobRi+AWe77ia+upsHBkZAIROGE/giOEejkgIIURjJclIJWQUqDdt16OiVXXqXwCSlVCcaLljQEt3hVYtiqKQ/t57AGj9/Ih46CGPxiOEEKJxk2SkEhyKOuZGakFqtY5X9nwHwEklmFYR/jQJ8OwgUinPPONajpk7Vx7XFUII4VGSjFTCrvRdAHSN6Fqt43dnFI/1rWH+zd3cFFXVKYrC8UceIXPpxwD49uyJX6+eHotHCCGEABlnpFLWHlkLQK4tt1rHFyb/CxpYr+3BfRH+7gyt0pwWC3su7OJaN7VuRcwbr3skFiGEEKI0qRk5jwJ7AXtO7wFgVMtRVT5eURS6atTj2yd47tHZ5MefcC2HjBtHi6+/Rhcc7LF4hBBCiGJSM3IeybnJruWb2t9U5eNTj+6j+NmZ/pde4aaoKs+Rnc3enr1c68b4eKIef6zO4xBCCCHORmpGzuPDXR8CEOkbiU5b9Unyjv3+lWvZJ6az2+KqjPTExDKJCBoN8UsW12kMQgghxPlIMnIOiqLw+b7PAQj3Ca9WGX/s3g9AMmFui6sy0ubNI/V/L7rWfbt3p92uf9CH1W0cQgghxPlIM8052J121/ITvZ84x55n51uYCnrICOlCtLsCO4+8zZs59fobrvW4RQvx69Onjs4uhBBCVI0kI+dgV0qSkRZBLap8vKIoWIsucXRYsLvCOuf59nTthlJQ4NrW5rct6AKrOXKsEEIIUQekmeYcHE6Ha1mvrXreZrE7uVT7BwB+Tdu6La6KKE4n+wcMdCUipvbtaf3Lz5KICCGEqPekZuQcSjfT6DTV6Lx6uoBW2lMA6LW1N8rpmWOIGGJiaLH8i1o7nxBCCOFOUjNyDsXNNBo01XqS5uCpkkHSdDHVG731fJwFBWUTkaZNabl6Va2cSwghhKgNkoycwxt/qJ1AFZTz7Fmx7EI7VqUoiWnS3l1hueR8/z17LipJcrSBgbT68Qc0uqonTkIIIYSnSDJSAYfTwfVfX8/y/ctrVM7qnccxaor6nRh83BCZSlEUjt13P8fuude1LfiGMbTZ8qvbziGEEELUFekzUoGfjv7E7ozdrvXPrvysWuXsPHAEiisp3JSMKIpC8mOPk7N6tWtb7Lvv4D9ggFvKF0IIIeqaJCMVKJ6LBmDDmA2EmEOqVU6MLqtkxU3JSNJtt5O/ZQsAWn9/Wm/cgNbHfbUuQgghRF2TZKSUAnsBY74Zw6GsQwDc3vH2aiciAK1IcldoAOwbMBB7aioAvr16EbdwgfQPEUII4fWkz0gpn+z5xJWIALQJaVOj8i6y/wWANbDms/Vmr1njSkR04eGSiAghhGgwpGaklM0nNruWv7/2eyL9Is+x97kpisLFup3qcmirGseW/MSTruXWGzeg0dTeuCVCCCFEXZKakVIK7OropYNiB9UoEQGwOpwEkq+uRNdstl7LoUM4s7MBiJw+TRIRIYQQDYokI6VoNerluCzhshqXlZ2ZToBGTW40F42tUVknHnzItRwyblyNyhJCCCHqG0lGKuCOmocnZs91LRsjqt/3RFEUCnftAiBk7Fg0WvmRCSGEaFjkzlbKjtQdbinHWZDFO8bXADitDa1RWcWP8QI0mfpAjcoSQggh6iNJRkrx0avjdRg0hhqVY/3l7ZIyr36tRmUl3Xa7uqDVovP3r1FZQgghRH0kyUiRozlHybHlANAyuGW1y8kutGH++UUADjijMXQcVe2ybMePu5aDr7+u2uUIIYQQ9ZkkI0US/050LUf5RVW7nMD/hbuWvzdegk5b/f4nyc88UxLTjBnVLkcIIYSozyQZQe0k+sneTwC4JPYSzHpztcr56q2Hyqzf/tArNYopb/0GAHy6dpXHeYUQQjRYMugZ8OneT13LQ+KHVPn4vOS9pHw0gavy/yrZ+FQGRm31R0g98eCDruWYN16vdjlCCCFEfSc1I8Dx3JK+GVe0uKLyByoKx1bPwe+dHrQslYhk3fkH1CARAche+R0AGpMJfXj4efYWQgghvJfUjAA2pw2A8R3HV645JC8dXm4BQEypzVt8BhAz9g2aRSfULJ5SHVfjFy+uUVlCCCFEfSfJCGB32gEwaM/zSK+iwFf3wvaPymw+pQSyb8Cb9L30arfEk/X1165ln44XuKVMIYQQor5q9M00dqedpf8uBUCvPU9u9tcnZRKRtY6u/DfuK7QP73dbIgKQ9ZWajJhat3ZbmUIIIUR91ehrRn45/otrOcI34uw7Ouyw/A7X6ijLM7S8aCBvX9/F7TFZDx4EwO/ii91ethBCCFHfNPpk5FDWIdfy1a2uPut+OZsXEFC0PM46jTvHXs9lnaLdHo/99GnXcsiNN7i9fCGEEKK+adTNNMdzj/PqtlcBGNl8pGvW3jN9svUoAd8/4lrvNOA/tZKIAOT+tM61bIiNrZVzCCGEEPVJo05GDmQecC0Paz6swn3e33iQtV8sdK3/1PpxHhnRrtZiOvnccwAEXjZSBjoTQgjRKFQrGZk7dy4JCQmYzWa6devGxo0bK3XcL7/8gl6vp0uXLtU5rdspigJAx7COZQY7y7PY+enfVFo9tpKPVv7Ee8bZ6v4aHYNveqTCstzFmZ8PgCFGakWEEEI0DlVORpYtW8b999/P448/zvbt2+nfvz8jR44kKSnpnMdlZWVxyy23cOmll1Y7WHdzKA4AtNqyl+Gqt37m9sTf0TktrDdNdW3XTFhTu/Hk5rqWQ28ZV6vnEkIIIeqLKicjs2fPZsKECUycOJH27dszZ84cYmNjmTdv3jmPu/POOxk7dix9+vSpdrDu5lScAOg0ZUdLPZFZCMB1uvUlG6+YAzHdazWegu3bXcsy6qoQQojGokrJiNVqZdu2bQwbVrZ/xbBhw9i0adNZj1u0aBEHDhxgRiVnnrVYLGRnZ5d51YbimhENJX0zCm0OCmwONDh5zrBI3RjRAbrfXisxlGbZf+D8OwkhhBANTJWSkbS0NBwOB5GRkWW2R0ZGkpKSUuEx+/btY9q0aSxevBi9vnJPEs+aNYugoCDXK7aWniop7jOiKzWPzD///MUNuh85ZL65ZMcr36iV858p98cfAQgYVnFnWiGEEKIhqlYH1jOf8lAUpcInPxwOB2PHjmXmzJm0adOm0uVPnz6drKws1+vo0aPVCfO8XH1Gih/pdTrptmIQ/zO8X3bH2B61cv7SFEUh//ffAdAYzjMsvRBCCNGAVGnQs/DwcHQ6XblakNTU1HK1JQA5OTls3bqV7du3c8899wDgdDpRFAW9Xs+aNWu45JJLyh1nMpkwmUxVCa1a8mx5AGiLc7JT/7reO2ZuQ0xCW7hmYUWHut3JZ59zLTd54P46OacQQghRH1SpZsRoNNKtWzfWrl1bZvvatWvp27dvuf0DAwPZuXMnO3bscL0mT55M27Zt2bFjB7169apZ9DW09/ReAAodaodVkne43lvRcwmM+T/QG2s9DsXh4PSSJeqKVosxJubcBwghhBANSJWHg586dSrjxo2je/fu9OnTh3fffZekpCQmT54MqE0sx48f58MPP0Sr1dKxY8cyx0dERGA2m8tt94RgUzBQqpnm+DYAUpVgWjbxr7M40t9f4Fpu9dOPdXZeIYQQoj6ocjIyZswY0tPTeeaZZ0hOTqZjx46sXLmS+Ph4AJKTk8875kh90yZE7c/icNjRAQeVaDrFBNXZ+dMXqMmIvkkTDBU0dwkhhBANWbUmyrv77ru5++67K3wvMTHxnMc+/fTTPP3009U5ba3T/ZEIwGZHB+4P9qmTcybPnImz6NHl6Beer5NzCiGEEPVJo56b5mw0moqfDnI3Z0EBmUs/BsDUuhX+/fvX+jmFEEKI+kaSkWIOW8lipzF1csrD15ecJ+7DD+vknEIIIUR9I8lIEUveadfyiH61P66IIzcXy759AJjatEEfElLr5xRCCCHqI0lGimzZqg44lq340ja69hODvd1LEp6YN16v9fMJIYQQ9ZUkI0VS/1Xn1jlFMHpd7V6WlOdfcC37dOmCsXnzWj2fEEIIUZ9JMlIk/OQvAOgM5lo9j/XYMbK++MK13vzjpbV6PiGEEKK+k2SkSC/+ASA3slutneP0x8s4MGQozjx1GPqEL7+stXMJIYQQ3qJa44w0NE6ngo/GCkCTCwbXyjksBw+SUmp8lZZr12CspdmIhRBCCG8iNSNAvtWBVdEB0KRN71o5R+E//7iWW/34gyQiQgghRBFJRoDcQhtGjQMArU9wrZwjb8sWAHy7d8fQtGmtnEMIIYTwRpKMAKdz8kpW9KZaOYcjMxMArX/dTcAnhBBCeANJRgCDYi1ZMdVOsmDZ/S8Avr171Ur5QgghhLeSZATQOQoAyNaF1to5bMePA6APC6+1cwghhBDeSJIRQOtUa0ZyDGG1Ur4zP9+1bGrdqlbOIYQQQngrSUYAnGrnVavWp1aKz9+61bVsatu2Vs4hhBBCeKtGnYwczTkKgEZxAuDUGmrlPKfefhsA3z690Wg0tXIOIYQQwls16mQky5oFgMV2CgBFo3P/Ob79lsI//wIgcPhwt5cvhBBCeLtGnYwEGgMBiLCpSUiAI9Pt50hfsMC1HDR6tNvLF0IIIbxdo05Givk71KaTXP/mbi/bsms3ALHvvYvWaHR7+UIIIYS3k2QEcBR1YC30jXJvuTk5rmVzx45uLVsIIYRoKCQZAUKsKQAUmpq4tdycH34AQBcaij4kxK1lCyGEEA2FJCOAXacOAa/RuvdyFA905sjIcGu5QgghREMiyQigUdRmGn2T1m4tN+3NtwAIuvYat5YrhBBCNCSSjAARzjQAdAaz28q0Hj7sWg4cPsJt5QohhBANjSQjQI6ijrxqMrkvGTm97BPXsn//i91WrhBCCNHQSDICmFDnpgls0tRtZWp9fdWyO7R3W5lCCCFEQyTJCGDUqH1GAv0D3FamYrUA4Nejp9vKFEIIIRoiSUZK0foGu60s28mTAGh8a2fyPSGEEKKhkGSkFIPR5Laysr/6Wi0zKtptZQohhBANkSQjpWjcNGtv5uefu5bN7dq6pUwhhBCioZJkpDRtzWftVRSF5MefAMC3Rw98LrywxmUKIYQQDZkkI0XsihY0mhqXk71ypWu56Usv1rg8IYQQoqGTZKSIQs0TEYATjzwKgCEmBkO09BcRQgghzkeSkSKGosd7a+L4gw+BQy0n+oXna1yeEEII0RhIMlIkzRRXo+Oz164l+9tvATBf2Bm/njK+iBBCCFEZkowU8bPXbGbd4/dOcS3Hzp9f03CEEEKIRkOSkSInmg6v9rF5mze7lmPffx99SIg7QhJCCCEaBUlGiuQEtqn2scdK1Yr4X9zPHeEIIYQQjYYkI0XsPmHVOk5RFJy5uQA0ffF/7gxJCCGEaBQkGSli9W9WreNSX34FAI3BgP+lQ9wZkhBCCNEo6D0dQH1hq+KTvYqikPbmW2QsXAhA2KSJ6Pz9aiEyIYQQomGTZKRIsG/l5qWxnzpF6iuvkL1qNYrFAoBvz56E33tvbYYnhBBCNFiSjBQ7x1Dw9tOnyVrxJac/XortSFKZ93y6dSNu4QI0bhhKXgghhGiMJBk5j/w/tnNk7NiyGzUafLp1JeqppzC3qf5TOEIIIYSQZMRFc8bcNNZjxzkx7VEKtm5zbQseM4bQW8ZhatmyrsMTQgghGixJRoppQLHZyPt1C1nLl5eZfVdjNhM7fz5+vXt5MEAhhBCiYZJkRFEI2a9Ht+41/t17T5m3tL6+NLn/PkLGjZM+IUIIIUQtafTJyBMfO2lx2Ac44NqmCw0lePR/CL/3XrQmk+eCE0IIIRqBRp+MRGYqACgGA9FPPEHg5Zeh8/f3cFRCiIbM4XBgs9k8HYYQNWYwGNDpdDUup1EnIxqnQmSmuuyYfh8hY673aDxCiIZNURRSUlLIzMz0dChCuE1wcDBRUVE16s7QqJORiAMZrmVNePXmphFCiMoqTkQiIiLw9fWVvmjCqymKQn5+PqmpqQBER0dXu6xGnYzE/5EMgFOnoAkJ9mwwQogGzeFwuBKRsDD58iMaBh8fHwBSU1OJiIiodpNNo54oT29RJ6Sx+Sgo8g1FCFGLivuI+Pr6ejgSIdyr+He6Jv2gGnUyUiytnQ1JRYQQdUGaZkRD447faUlGADRIMiKEEEJ4iCQjxeTbihBCeETz5s2ZM2dOtY9PTEwkODjYbfE0JIMGDeL+++/3dBjnVa1kZO7cuSQkJGA2m+nWrRsbN248675ffPEFQ4cOpUmTJgQGBtKnTx9Wr15d7YCFEELUndtuu42rr766Vs/x+++/c8cdd1Rq34oSlzFjxrB3795qnz8xMRGNRuN6RUZGcuWVV/LPP/9Uu8z64osvvuDZZ5/1dBjnVeVkZNmyZdx///08/vjjbN++nf79+zNy5EiSkpIq3H/Dhg0MHTqUlStXsm3bNgYPHsyVV17J9u3baxy8W0nNiBBCeESTJk1q1LHXx8eHiIiIGsUQGBhIcnIyJ06c4NtvvyUvL4/LL78cq9Vao3LPp7YHvwsNDSUgIKBWz+EOVU5GZs+ezYQJE5g4cSLt27dnzpw5xMbGMm/evAr3nzNnDo888gg9evSgdevWvPDCC7Ru3Zqvv/66xsHXlKQfQghRM+vXr6dnz56YTCaio6OZNm0adrvd9X5OTg433XQTfn5+REdH89prr5VrOjiztuPpp58mLi4Ok8lE06ZNmTJlCqA2ORw5coQHHnjAVYsBFTfTfPXVV3Tv3h2z2Ux4eDijR48+5+fQaDRERUURHR1N9+7deeCBBzhy5Ah79uxx7bNp0yYGDBiAj48PsbGxTJkyhby8PNf7ycnJXH755fj4+JCQkMCSJUvKfTaNRsP8+fMZNWoUfn5+PPfccwB8/fXXdOvWDbPZTIsWLZg5c2aZ63i2awJqa0Xr1q0xm81ERkZy7bXXut4781qfPn2aW265hZCQEHx9fRk5ciT79u1zvV98LVevXk379u3x9/dnxIgRJCcnn/P61VSVkhGr1cq2bdsYNmxYme3Dhg1j06ZNlSrD6XSSk5NDaGjoWfexWCxkZ2eXedU2qRgRQtQlRVHIt9o98lIUxS2f4fjx41x22WX06NGDP//8k3nz5rFgwQLXDRZg6tSp/PLLL3z11VesXbuWjRs38scff5y1zM8++4zXXnuNd955h3379rFixQo6deoEqE0OMTExPPPMMyQnJ5/1Bvntt98yevRoLr/8crZv384PP/xA9+7dK/25MjMzWbJkCaAOdw6wc+dOhg8fzujRo/nrr79YtmwZP//8M/fcUzLB6i233MKJEydYt24dn3/+Oe+++65rQLDSZsyYwahRo9i5cyfjx49n9erV3HzzzUyZMoVdu3bxzjvvkJiYyPPPP3/ea7J161amTJnCM888w549e1i1ahUDBgw462e77bbb2Lp1K1999RWbN29GURQuu+yyMjU0+fn5vPLKK3z00Uds2LCBpKQkHnrooUpfv+qo0qBnaWlpOBwOIiMjy2yPjIwkJSWlUmW8+uqr5OXlcf31Zx96fdasWcycObMqodWYRupJhBB1qMDmoMNTnuk/t+uZ4fgaaz7m5dy5c4mNjeWtt95Co9HQrl07Tpw4waOPPspTTz1FXl4eH3zwAUuWLOHSSy8FYNGiRTRt2vSsZSYlJREVFcWQIUMwGAzExcXRs2dPQG1y0Ol0BAQEEBUVddYynn/+eW644YYy95ELL7zwnJ8lKysLf39/16iiAFdddRXt2rUD4OWXX2bs2LGuWobWrVvzxhtvMHDgQObNm8fhw4f5/vvv+f33312Jz/vvv0/r1q3LnWvs2LGMHz/etT5u3DimTZvGrbfeCkCLFi149tlneeSRR5gxY8Y5r0lSUhJ+fn5cccUVBAQEEB8fz0UXXVThZ9y3bx9fffUVv/zyC3379gVg8eLFxMbGsmLFCq677jpAbTqaP38+LVu2BOCee+7hmWeeOef1q6lqdWA985liRVEq9Zzx0qVLefrpp1m2bNk52/emT59OVlaW63X06NHqhCmEEKIW7d69mz59+pT5+9+vXz9yc3M5duwYBw8exGazuW6cAEFBQbRt2/asZV533XUUFBTQokULJk2axPLly8s0V1TGjh07XMlPZQUEBLBjxw62bdvmuhHPnz/f9f62bdtITEzE39/f9Ro+fDhOp5NDhw6xZ88e9Ho9Xbt2dR3TqlUrQkJCyp3rzFqabdu28cwzz5Qpe9KkSSQnJ5Ofn3/OazJ06FDi4+Np0aIF48aNY/Hixa5k6ky7d+9Gr9fTq1cv17awsDDatm3L7t27Xdt8fX1diQiow7xXVMPjTlVKjcPDw9HpdOVqQVJTU8vVlpxp2bJlTJgwgU8//ZQhQ4acc1+TyYTJZKpKaDUmAxEJIeqSj0HHrmeGe+zc7lDRF9HiJiCNRlNmuaJ9KhIbG8uePXtYu3Yt33//PXfffTcvv/wy69evdzWZnE/xEOVVodVqadWqFQDt2rUjJSWFMWPGsGHDBkDtYnDnnXeW6atRLC4urkzfktIq+qx+fn5l1p1OJzNnzqywX4vZbD7nNQkICOCPP/5g3bp1rFmzhqeeeoqnn36a33//vVw/mrNd9zN/jmde59I/y9pSpZoRo9FIt27dWLt2bZnta9eudVX5VGTp0qXcdtttLFmyhMsvv7x6kdYyRZpphBB1SKPR4GvUe+Tlri9fHTp0YNOmTWVuVJs2bSIgIIBmzZrRsmVLDAYDv/32m+v97OzsMh0mK+Lj48NVV13FG2+8wbp169i8eTM7d+4E1PuQw+E45/GdO3fmhx9+qMEngwceeIA///yT5cuXA9C1a1f++ecfWrVqVe5lNBpp164ddru9zJOi+/fvr9QMzV27dmXPnj0Vlq3Vqrfpc10TvV7PkCFDeOmll/jrr784fPgwP/74Y7nzdOjQAbvdzpYtW1zb0tPT2bt3L+3bt6/J5aqxKjcaTp06lXHjxtG9e3f69OnDu+++S1JSEpMnTwbUJpbjx4/z4YcfAmoicsstt/D666/Tu3dvV62Kj48PQUFBbvwo1VDqfyBJRYQQomJZWVns2LGjzLbQ0FDuvvtu5syZw7333ss999zDnj17mDFjBlOnTkWr1RIQEMCtt97Kww8/TGhoKBEREcyYMQOtVnvWhCgxMRGHw0GvXr3w9fXlo48+wsfHh/j4eEB98mbDhg3ccMMNmEwmwsPDy5UxY8YMLr30Ulq2bMkNN9yA3W7nu+++45FHHqn0Zw4MDGTixInMmDGDq6++mkcffZTevXvz3//+l0mTJuHn58fu3btZu3Ytb775Ju3atWPIkCHccccdzJs3D4PBwIMPPoiPj895k7+nnnqKK664gtjYWK677jq0Wi1//fUXO3fu5LnnnjvnNfnmm284ePAgAwYMICQkhJUrV+J0OitsCmvdujWjRo1i0qRJvPPOOwQEBDBt2jSaNWvGqFGjKn1taoVSDW+//bYSHx+vGI1GpWvXrsr69etd7916663KwIEDXesDBw5UgHKvW2+9tdLny8rKUgAlKyurOuGe1YrxQ5Vdbdspa8YlKHt2bHJr2UIIUVpBQYGya9cupaCgwNOhVMmtt956zr/h69atU3r06KEYjUYlKipKefTRRxWbzeY6Pjs7Wxk7dqzi6+urREVFKbNnz1Z69uypTJs2zbVPfHy88tprrymKoijLly9XevXqpQQGBip+fn5K7969le+//9617+bNm5XOnTsrJpNJKb6FLVq0SAkKCioT9+eff6506dJFMRqNSnh4uDJ69OizfsaKjlcURTly5Iii1+uVZcuWKYqiKL/99psydOhQxd/fX/Hz81M6d+6sPP/88679T5w4oYwcOVIxmUxKfHy8smTJEiUiIkKZP3++ax9AWb58eblzrVq1Sunbt6/i4+OjBAYGKj179lTefffd816TjRs3KgMHDlRCQkIUHx8fpXPnzq54FUW9B993332u9YyMDGXcuHFKUFCQ4uPjowwfPlzZu3fvOa/F8uXLlXOlC+f63a7s/VtTdHHqtezsbIKCgsjKyiIwMNBt5X45YRhtfjnKsZ4W4h9cTJsL+7itbCGEKK2wsJBDhw65Rq9urPLy8mjWrBmvvvoqEyZM8HQ4terYsWPExsby/fffV7lDrTc51+92Ze/fNX+2q4GQR3uFEML9tm/fzr///kvPnj3JyspyPSLq8WaBWvDjjz+Sm5tLp06dSE5O5pFHHqF58+bnHPdDqCQZKaaVZEQIIWrDK6+8wp49e1wPQWzcuLHCvh7ezmaz8dhjj3Hw4EECAgLo27cvixcvrvRTQI2ZJCNCCCFqzUUXXcS2bds8HUadGD58OMOHe+ZxbW9XrUHPhBBCCCHcpXEnI6W67sqgZ0IIIYRnNO5kRAghhBAeJ8lIEXmaRgghhPAMSUaKSS4ihBBCeIQkI0IIIYTwKElGishEeUIIIYRnNOpkpHT6YXbTlNpCCNHQpKamcueddxIXF4fJZCIqKorhw4ezfv16wsPDee655yo8btasWYSHh2O1WklMTESj0VQ4O+wnn3yCRqOhefPmtfxJRH3VqJOR0vRyJYQQokLXXHMNf/75Jx988AF79+7lq6++YtCgQeTm5nLzzTeTmJhIRdOcLVq0iHHjxmE0GgHw8/MjNTWVzZs3l9lv4cKFxMXF1clnEfWTjMBaRKOVbEQIIc6UmZnJzz//zLp16xg4cCAA8fHx9OzZE4C4uDhef/11NmzY4HofYOPGjezbt6/MZHh6vZ6xY8eycOFC+vRRJyY9duwY69at44EHHmDp0qV1+MlEfSJ34CLSY0QIUacUBax5nnlVYbJ2f39//P39WbFiBRaLpdz7nTp1okePHixatKjM9oULF9KzZ086duxYZvuECRNYtmwZ+fn5ACQmJjJixAgiIyOrcRFFQyE1I8VkBFYhRF2y5cMLTT1z7sdOgNGvUrvq9XoSExOZNGkS8+fPp2vXrgwcOJAbbriBzp07AzB+/Hgeeugh3nrrLfz9/cnNzeXTTz9l9uzZ5crr0qULLVu25LPPPmPcuHEkJiYye/ZsDh486NaPKLyL1IwUkUHPhBCiYtdccw0nTpzgq6++Yvjw4axbt46uXbuSmJgIwI033ojT6WTZsmUALFu2DEVRuOGGGyosb/z48SxatIj169eTm5vLZZddVlcfRdRTjbtmpFRVpVSMCCHqlMFXraHw1LmryGw2M3ToUIYOHcpTTz3FxIkTmTFjBrfddhtBQUFce+21LFq0iAkTJrBo0SKuvfZaAgMDKyzrpptu4pFHHuHpp5/mlltuQa9v3Lci0diTkWIaBek1IoSoUxpNpZtK6qMOHTqwYsUK1/qECRMYNGgQ33zzDb/88gsvvPDCWY8NDQ3lqquu4pNPPmH+/Pl1EK2o76SZpoikIkIIUV56ejqXXHIJ//d//8dff/3FoUOH+PTTT3nppZcYNWqUa7+BAwfSqlUrbrnlFlq1asWAAQPOWW5iYiJpaWm0a9eutj+C8AJSM1JMshEhhCjH39+fXr168dprr3HgwAFsNhuxsbFMmjSJxx57rMy+48eP57HHHuPhhx8+b7k+Pj74+PjUVtjCy2iUikaqqWeys7MJCgoiKyvrrG2Q1fHV7UNpvfkYx3oV0u2ZbwmN7+C2soUQorTCwkIOHTpEQkICZrPZ0+EI4Tbn+t2u7P1bmmmKSc2IEEII4RGSjBTRyOM0QgghhEc07mSkVAOV5CJCCCGEZzTuZKQUyUWEEEIIz5BkpIg00wghhBCeIclIERkOXgghhPAMSUaKSc2IEEII4RGSjBSTXEQIIYTwiMadjJSeKM+DYQghhBCNWeNORoooGtBo5FIIIUR907x5c+bMmePpMEQtkztwEakZEUKI8m677TY0Gg0ajQa9Xk9cXBx33XUXp0+f9nRoterpp592fe7Sr++//96jMXXp0sVj569NMlFeEem/KoQQFRsxYgSLFi3Cbreza9cuxo8fT2ZmJkuXLvV0aLXqggsuKJd8hIaGVqssq9WK0Wh0R1gNUqOuGXGWGoHVoNN5LhAhhKjHTCYTUVFRxMTEMGzYMMaMGcOaNWtc7zscDiZMmEBCQgI+Pj60bduW119/vUwZt912G1dffTWvvPIK0dHRhIWF8d///hebzebaJzU1lSuvvBIfHx8SEhJYvHhxuViSkpIYNWoU/v7+BAYGcv3113Py5EnX+8W1BwsXLiQuLg5/f3/uuusuHA4HL730ElFRUURERPD888+f93Pr9XqioqLKvIoTip07d3LJJZfg4+NDWFgYd9xxB7m5ueU+76xZs2jatClt2rQB4Pjx44wZM4aQkBDCwsIYNWoUhw8fdh23bt06evbsiZ+fH8HBwfTr148jR46QmJjIzJkz+fPPP121NImJief9DN5CakaK6Bt1WiaEqGuKolBgL/DIuX30PtUe6PHgwYOsWrUKg8Hg2uZ0OomJieGTTz4hPDycTZs2cccddxAdHc3111/v2u+nn34iOjqan376if379zNmzBi6dOnCpEmTAPUGfvToUX788UeMRiNTpkwhNTXVdbyiKFx99dX4+fmxfv167HY7d999N2PGjGHdunWu/Q4cOMB3333HqlWrOHDgANdeey2HDh2iTZs2rF+/nk2bNjF+/HguvfRSevfuXeVrkJ+fz4gRI+jduze///47qampTJw4kXvuuadMgvDDDz8QGBjI2rVrURSF/Px8Bg8eTP/+/dmwYQN6vZ7nnnuOESNG8Ndff6HVarn66quZNGkSS5cuxWq18ttvv6HRaBgzZgx///03q1atctXWBAUFVTn2+kqSkWJGf09HIIRoRArsBfRa0ssj594ydgu+Bt9K7//NN9/g7++Pw+GgsLAQgNmzZ7veNxgMzJw507WekJDApk2b+OSTT8okIyEhIbz11lvodDratWvH5Zdfzg8//MCkSZPYu3cv3333Hb/++iu9eqnXZcGCBbRv3951/Pfff89ff/3FoUOHiI2NBeCjjz7iggsu4Pfff6dHjx6AmhwtXLiQgIAAOnTowODBg9mzZw8rV65Eq9XStm1bXnzxRdatW3fOZGTnzp34+5fcGzp06MBvv/3G4sWLKSgo4MMPP8TPzw+At956iyuvvJIXX3yRyMhIAPz8/Hj//fddtSkLFy5Eq9Xy/vvvu5LBRYsWERwczLp16+jevTtZWVlcccUVtGzZEqDM5/f393fV1jQ0jTsZKfVoL1ppphFCiIoMHjyYefPmkZ+fz/vvv8/evXu59957y+wzf/583n//fY4cOUJBQQFWq7VcZ8sLLrgAXakm8ejoaHbu3AnA7t270ev1dO/e3fV+u3btCA4Odq3v3r2b2NhYVyICaoIQHBzM7t27XclI8+bNCQgIcO0TGRmJTqdDq9WW2Va61qUibdu25auvvnKtm0wmVxwXXnihKxEB6NevH06nkz179riSkU6dOpXpJ7Jt2zb2799fJjaAwsJCDhw4wLBhw7jtttsYPnw4Q4cOZciQIVx//fVER0efM86GoHEnI6XJo71CiDrko/dhy9gtHjt3Vfj5+dGqVSsA3njjDQYPHszMmTN59tlnAfjkk0944IEHePXVV+nTpw8BAQG8/PLLbNlS9vOVbtoBdU4wp9MJqE0wxdvORlGUCt8/c3tF5znXuc/GaDS6Pndl4jgz/tLJCqg1Nt26dauwL0yTJk0AtaZkypQprFq1imXLlvHEE0+wdu3aajUneRNJRopJMiKEqEMajaZKTSX1yYwZMxg5ciR33XUXTZs2ZePGjfTt25e7777btc+BAweqVGb79u2x2+1s3bqVnj17ArBnzx4yMzNd+3To0IGkpCSOHj3qqh3ZtWsXWVlZZZozaluHDh344IMPyMvLcyUcv/zyC1qt1tVRtSJdu3Zl2bJlREREEBgYeNb9LrroIi666CKmT59Onz59WLJkCb1798ZoNOJwONz+eeqDRn4HLtVMI8mIEEJUyqBBg7jgggt44YUXAGjVqhVbt25l9erV7N27lyeffJLff/+9SmW2bduWESNGMGnSJLZs2cK2bduYOHEiPj4ltThDhgyhc+fO3HTTTfzxxx/89ttv3HLLLQwcOLBM805tu+mmmzCbzdx66638/fff/PTTT9x7772MGzfO1URztuPCw8MZNWoUGzdu5NChQ6xfv5777ruPY8eOcejQIaZPn87mzZs5cuQIa9asYe/eva5Eq3nz5hw6dIgdO3aQlpaGxWKpq49c6xr3HbhULiLJiBBCVN7UqVN57733OHr0KJMnT2b06NGMGTOGXr16kZ6eXqaWpLIWLVpEbGwsAwcOZPTo0dxxxx1ERES43tdoNKxYsYKQkBAGDBjAkCFDaNGiBcuWLXPnRzsvX19fVq9eTUZGBj169ODaa6/l0ksv5a233jrvcRs2bCAuLo7Ro0fTvn17xo8fT0FBAYGBgfj6+vLvv/9yzTXX0KZNG+644w7uuece7rzzTgCuueYaRowYweDBg2nSpEmDGudFoyile3HWT9nZ2QQFBZGVlXXOqq2qWnHzJbTdmszR3oUMe283GMxuK1sIIUorLCzk0KFDJCQkYDbL3xrRcJzrd7uy9+9GXR2gUaSZRgghhPA0uQMXk2RECCGE8Ai5AxeTZEQIIYTwiEZ9By7TWUZmyhNCCCE8olEnIyilBryRZEQIIYTwiMadjAghhBDC4xp1MlL8NI1dBqIVQgghPKZRJyPFFGmhEUIIITxGkhHO6MgqhBBCiDrVyJOR4jREqkaEEKK2DRo0iPvvv9/TYYh6qJEnIyqpGRFCiIrddtttaDQa/ve//5XZvmLFCjRVfArxiy++4Nlnn3VneOUUx1v8CgsLY8SIEfz111+1el5RM5KMCCGEOCez2cyLL77I6dOna1ROaGgoAQEBborq7EaMGEFycjLJycn88MMP6PV6rrjiilo/r6i+xp2MuKpEpJlGCCHOZsiQIURFRTFr1qyz7pOens6NN95ITEwMvr6+dOrUqdyssqWbaaZPn07v3r3LldO5c2dmzJjhWl+0aBHt27fHbDbTrl075s6de954TSYTUVFRREVF0aVLFx599FGOHj3KqVOnXPs8+uijtGnTBl9fX1q0aMGTTz6JzWYD4PDhw2i1WrZu3Vqm3DfffJP4+HiK55fdtWsXl112Gf7+/kRGRjJu3DjS0tJc+3/22Wd06tQJHx8fwsLCGDJkCHl5eeeNvzFq3MlIUTYizTRCiLqmKArO/HyPvKo6WbtOp+OFF17gzTff5NixYxXuU1hYSLdu3fjmm2/4+++/ueOOOxg3bhxbtmypcP+bbrqJLVu2cODAAde2f/75h507d3LTTTcB8N577/H444/z/PPPs3v3bl544QWefPJJPvjgg0rHnpuby+LFi2nVqhVhYWGu7QEBASQmJrJr1y5ef/113nvvPV577TUAmjdvzpAhQ1i0aFGZshYtWuRqBkpOTmbgwIF06dKFrVu3smrVKk6ePMn1118PQHJyMjfeeCPjx49n9+7drFu3jtGjR1f52jcW1RpgY+7cubz88sskJydzwQUXMGfOHPr373/W/devX8/UqVP5559/aNq0KY888giTJ0+udtBCCOHtlIIC9nTt5pFzt/1jGxpf3yod85///IcuXbowY8YMFixYUO79Zs2a8dBDD7nW7733XlatWsWnn35Kr169yu3fsWNHOnfuzJIlS3jyyScBWLx4MT169KBNmzYAPPvss7z66quMHj0agISEBHbt2sU777zDrbfeetZYv/nmG/z9/QHIy8sjOjqab775Bq225Pv3E0884Vpu3rw5Dz74IMuWLeORRx4BYOLEiUyePJnZs2djMpn4888/2bFjB1988QUA8+bNo2vXrrzwwguuchYuXEhsbCx79+4lNzcXu93O6NGjiY+PB6BTp07nusSNWpVrRpYtW8b999/P448/zvbt2+nfvz8jR44kKSmpwv0PHTrEZZddRv/+/dm+fTuPPfYYU6ZM4fPPP69x8O6iSDONEEKc14svvsgHH3zArl27yr3ncDh4/vnn6dy5M2FhYfj7+7NmzZqz3htArR1ZvHgxoNYULV261FUrcurUKY4ePcqECRPw9/d3vZ577rkytSkVGTx4MDt27GDHjh1s2bKFYcOGMXLkSI4cOeLa57PPPuPiiy8mKioKf39/nnzyyTKxXn311ej1epYvXw6oicbgwYNp3rw5ANu2beOnn34qE1u7du0AOHDgABdeeCGXXnopnTp14rrrruO9996rcZ+bhqzKNSOzZ89mwoQJTJw4EYA5c+awevVq5s2bV2F74vz584mLi2POnDkAtG/fnq1bt/LKK69wzTXX1Cx6t5FkRAhRtzQ+PrT9Y5vHzl0dAwYMYPjw4Tz22GPcdtttZd579dVXee2115gzZw6dOnXCz8+P+++/H6vVetbyxo4dy7Rp0/jjjz8oKCjg6NGj3HDDDQA4nercYe+99165mhWdTnfOOP38/GjVqpVrvVu3bgQFBfHee+/x3HPP8euvv3LDDTcwc+ZMhg8fTlBQEB9//DGvvvqq6xij0ci4ceNYtGgRo0ePZsmSJa77WHF8V155JS+++GK580dHR6PT6Vi7di2bNm1izZo1vPnmmzz++ONs2bKFhISEc8bfGFUpGbFarWzbto1p06aV2T5s2DA2bdpU4TGbN29m2LBhZbYNHz6cBQsWYLPZMBgM5Y6xWCxYLBbXenZ2dlXCrDSnRe1IJC14Qoi6ptFoqtxUUh/873//o0uXLq6mlGIbN25k1KhR3HzzzYB6s963bx/t27c/a1kxMTEMGDCAxYsXU1BQwJAhQ4iMjAQgMjKSZs2acfDgQVdtSXVpNBq0Wi0FBQUA/PLLL8THx/P444+79ilda1Js4sSJdOzYkblz52Kz2VzNRQBdu3bl888/p3nz5uj1Fd9KNRoN/fr1o1+/fjz11FPEx8ezfPlypk6dWqPP0xBVqZkmLS0Nh8Ph+mUpFhkZSUpKSoXHpKSkVLi/3W4v0+u4tFmzZhEUFOR6xcbGViXMynOqPacdmnNn2UIIIVSdOnXipptu4s033yyzvVWrVq6agN27d3PnnXee9b5Q2k033cTHH3/Mp59+6kpkij399NPMmjWL119/nb1797Jz504WLVrE7Nmzz1mmxWIhJSWFlJQUdu/ezb333ktubi5XXnmlK9akpCQ+/vhjDhw4wBtvvOFqjimtffv29O7dm0cffZQbb7wRn1I1Sv/973/JyMjgxhtv5LfffuPgwYOsWbOG8ePH43A42LJlCy+88AJbt24lKSmJL774glOnTp0zOWvMqvU0zZkD3SiKcs7Bbyrav6LtxaZPn05WVpbrdfTo0eqEeV6Oi7rwZ+8Qgi69rVbKF0KIhujZZ58t91TIk08+SdeuXRk+fDiDBg0iKiqKq6+++rxlXXfddaSnp5Ofn19u/4kTJ/L++++TmJhIp06dGDhwIImJiedt5li1ahXR0dFER0fTq1cvfv/9dz799FMGDRoEwKhRo3jggQe455576NKlC5s2bXJ1oj3ThAkTsFqtjB8/vsz2pk2b8ssvv+BwOBg+fDgdO3bkvvvuIygoCK1WS2BgIBs2bOCyyy6jTZs2PPHEE7z66quMHDnyvNekMdIoVXjOyGq14uvry6effsp//vMf1/b77ruPHTt2sH79+nLHDBgwgIsuuojXX3/dtW358uVcf/315OfnV9hMc6bs7GyCgoLIysoiMDCwsuEKIUS9UVhYyKFDh0hISMBsNns6HFFJzz//PB9//DE7d+70dCj11rl+tyt7/65SzYjRaKRbt26sXbu2zPa1a9fSt2/fCo/p06dPuf3XrFlD9+7dK5WICCGEEHUtNzeX33//nTfffJMpU6Z4OpwGr8rNNFOnTuX9999n4cKF7N69mwceeICkpCTXuCHTp0/nlltuce0/efJkjhw5wtSpU9m9ezcLFy5kwYIFZZ5HF0IIIeqTe+65h4svvpiBAweWa6IR7lflR3vHjBlDeno6zzzzDMnJyXTs2JGVK1e6BnVJTk4u86x2QkICK1eu5IEHHuDtt9+madOmvPHGG/XosV4hhBCirMTERBITEz0dRqNRpT4jniJ9RoQQ3k76jIiGqs77jAghhBBCuJskI0IIUYeKRxYVoqFwx+90tSbKE0IIUTVGoxGtVsuJEydo0qQJRqPxnOMzCVHfKYqC1Wrl1KlTaLVajEZjtcuSZEQIIeqAVqslISGB5ORkTpw44elwhHAbX19f4uLiysyKXFWSjAghRB0xGo3ExcVht9txOByeDkeIGtPpdOj1+hrX8kkyIoQQdUij0WAwGGTQRyFKkQ6sQgghhPAoSUaEEEII4VGSjAghhBDCo7yiz0jxILHZ2dkejkQIIYQQlVV83z7fYO9ekYzk5OQAEBsb6+FIhBBCCFFVOTk5BAUFnfV9r5ibxul0cuLECQICAtw6SFB2djaxsbEcPXpU5rypZXKt64Zc57oh17luyHWuG7V5nRVFIScnh6ZNm55zHBKvqBnRarXExMTUWvmBgYHyi15H5FrXDbnOdUOuc92Q61w3aus6n6tGpJh0YBVCCCGER0kyIoQQQgiPatTJiMlkYsaMGZhMJk+H0uDJta4bcp3rhlznuiHXuW7Uh+vsFR1YhRBCCNFwNeqaESGEEEJ4niQjQgghhPAoSUaEEEII4VGSjAghhBDCoxp8MjJ37lwSEhIwm81069aNjRs3nnP/9evX061bN8xmMy1atGD+/Pl1FKl3q8p1/uKLLxg6dChNmjQhMDCQPn36sHr16jqM1rtV9Xe62C+//IJer6dLly61G2ADUdXrbLFYePzxx4mPj8dkMtGyZUsWLlxYR9F6r6pe58WLF3PhhRfi6+tLdHQ0t99+O+np6XUUrXfasGEDV155JU2bNkWj0bBixYrzHlPn90KlAfv4448Vg8GgvPfee8quXbuU++67T/Hz81OOHDlS4f4HDx5UfH19lfvuu0/ZtWuX8t577ykGg0H57LPP6jhy71LV63zfffcpL774ovLbb78pe/fuVaZPn64YDAbljz/+qOPIvU9Vr3WxzMxMpUWLFsqwYcOUCy+8sG6C9WLVuc5XXXWV0qtXL2Xt2rXKoUOHlC1btii//PJLHUbtfap6nTdu3KhotVrl9ddfVw4ePKhs3LhRueCCC5Srr766jiP3LitXrlQef/xx5fPPP1cAZfny5efc3xP3wgadjPTs2VOZPHlymW3t2rVTpk2bVuH+jzzyiNKuXbsy2+68806ld+/etRZjQ1DV61yRDh06KDNnznR3aA1Oda/1mDFjlCeeeEKZMWOGJCOVUNXr/N133ylBQUFKenp6XYTXYFT1Or/88stKixYtymx74403lJiYmFqLsaGpTDLiiXthg22msVqtbNu2jWHDhpXZPmzYMDZt2lThMZs3by63//Dhw9m6dSs2m63WYvVm1bnOZ3I6neTk5BAaGlobITYY1b3WixYt4sCBA8yYMaO2Q2wQqnOdv/rqK7p3785LL71Es2bNaNOmDQ899BAFBQV1EbJXqs517tu3L8eOHWPlypUoisLJkyf57LPPuPzyy+si5EbDE/dCr5gorzrS0tJwOBxERkaW2R4ZGUlKSkqFx6SkpFS4v91uJy0tjejo6FqL11tV5zqf6dVXXyUvL4/rr7++NkJsMKpzrfft28e0adPYuHEjen2D/d/drapznQ8ePMjPP/+M2Wxm+fLlpKWlcffdd5ORkSH9Rs6iOte5b9++LF68mDFjxlBYWIjdbueqq67izTffrIuQGw1P3AsbbM1IMY1GU2ZdUZRy2863f0XbRVlVvc7Fli5dytNPP82yZcuIiIiorfAalMpea4fDwdixY5k5cyZt2rSpq/AajKr8TjudTjQaDYsXL6Znz55cdtllzJ49m8TERKkdOY+qXOddu3YxZcoUnnrqKbZt28aqVas4dOgQkydProtQG5W6vhc22K9K4eHh6HS6chl2ampquYyvWFRUVIX76/V6wsLCai1Wb1ad61xs2bJlTJgwgU8//ZQhQ4bUZpgNQlWvdU5ODlu3bmX79u3cc889gHrTVBQFvV7PmjVruOSSS+okdm9Snd/p6OhomjVrVmaq9Pbt26MoCseOHaN169a1GrM3qs51njVrFv369ePhhx8GoHPnzvj5+dG/f3+ee+45qb12E0/cCxtszYjRaKRbt26sXbu2zPa1a9fSt2/fCo/p06dPuf3XrFlD9+7dMRgMtRarN6vOdQa1RuS2225jyZIl0t5bSVW91oGBgezcuZMdO3a4XpMnT6Zt27bs2LGDXr161VXoXqU6v9P9+vXjxIkT5Obmurbt3bsXrVZLTExMrcbrrapznfPz89Fqy962dDodUPLNXdScR+6FtdY1th4ofmxswYIFyq5du5T7779f8fPzUw4fPqwoiqJMmzZNGTdunGv/4seZHnjgAWXXrl3KggUL5NHeSqjqdV6yZImi1+uVt99+W0lOTna9MjMzPfURvEZVr/WZ5Gmayqnqdc7JyVFiYmKUa6+9Vvnnn3+U9evXK61bt1YmTpzoqY/gFap6nRctWqTo9Xpl7ty5yoEDB5Sff/5Z6d69u9KzZ09PfQSvkJOTo2zfvl3Zvn27AiizZ89Wtm/f7nqEuj7cCxt0MqIoivL2228r8fHxitFoVLp27aqsX7/e9d6tt96qDBw4sMz+69atUy666CLFaDQqzZs3V+bNm1fHEXunqlzngQMHKkC516233lr3gXuhqv5OlybJSOVV9Trv3r1bGTJkiOLj46PExMQoU6dOVfLz8+s4au9T1ev8xhtvKB06dFB8fHyU6Oho5aabblKOHTtWx1F7l59++umcf3Prw71QoyhStyWEEEIIz2mwfUaEEEII4R0kGRFCCCGER0kyIoQQQgiPkmRECCGEEB4lyYgQQgghPEqSESGEEEJ4lCQjQgghhPAoSUaEEEII4VGSjAghhBDCoyQZEUIIIYRHSTIihBBCCI+SZEQIIYQQHvX/fRp0CgK6cI8AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/06 13:27:47 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 390497 ms exceeds timeout 120000 ms\n",
      "23/10/06 13:27:47 WARN SparkContext: Killing executors is not supported by current scheduler.\n",
      "23/10/06 13:28:01 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@coolqs-air.lan:56539\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/06 13:28:01 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@coolqs-air.lan:56539\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/06 13:28:16 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@coolqs-air.lan:56539\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/06 13:28:16 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@coolqs-air.lan:56539\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/06 13:49:32 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@coolqs-air.lan:56539\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/06 13:49:32 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@coolqs-air.lan:56539\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/06 13:49:42 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@coolqs-air.lan:56539\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/06 13:49:42 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@coolqs-air.lan:56539\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/06 14:08:32 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@coolqs-air.lan:56539\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/06 14:08:32 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@coolqs-air.lan:56539\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/06 14:08:42 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@coolqs-air.lan:56539\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/06 14:08:42 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@coolqs-air.lan:56539\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/06 14:11:34 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@coolqs-air.lan:56539\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/06 14:11:34 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@coolqs-air.lan:56539\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/06 14:11:48 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@coolqs-air.lan:56539\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/06 14:11:48 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@coolqs-air.lan:56539\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/06 14:11:58 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@coolqs-air.lan:56539\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/06 14:11:58 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@coolqs-air.lan:56539\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/06 14:12:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@coolqs-air.lan:56539\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/06 14:12:09 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@coolqs-air.lan:56539\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/06 14:20:09 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@coolqs-air.lan:56539\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/06 14:20:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@coolqs-air.lan:56539\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/06 14:45:35 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@coolqs-air.lan:56539\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/06 14:45:35 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@coolqs-air.lan:56539\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/06 15:01:15 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@coolqs-air.lan:56539\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/06 15:01:15 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@coolqs-air.lan:56539\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/06 15:21:40 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@coolqs-air.lan:56539\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/06 15:21:40 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@coolqs-air.lan:56539\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/06 15:27:21 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@coolqs-air.lan:56539\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/06 15:27:21 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@coolqs-air.lan:56539\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/06 15:45:51 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@coolqs-air.lan:56539\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/06 15:45:51 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@coolqs-air.lan:56539\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/06 16:19:11 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@coolqs-air.lan:56539\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/06 16:19:11 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@coolqs-air.lan:56539\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/06 16:22:32 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@coolqs-air.lan:56539\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/06 16:22:32 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@coolqs-air.lan:56539\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/06 16:34:04 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@coolqs-air.lan:56539\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/06 16:34:04 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@coolqs-air.lan:56539\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/06 16:34:14 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@coolqs-air.lan:56539\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/06 16:34:14 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@coolqs-air.lan:56539\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/06 16:45:07 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@coolqs-air.lan:56539\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/06 16:45:07 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@coolqs-air.lan:56539\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/06 16:45:17 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@coolqs-air.lan:56539\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/06 16:45:17 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@coolqs-air.lan:56539\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/06 16:45:27 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@coolqs-air.lan:56539\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/06 16:45:27 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@coolqs-air.lan:56539\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/06 16:45:37 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@coolqs-air.lan:56539\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/06 16:45:37 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@coolqs-air.lan:56539\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    }
   ],
   "source": [
    "nb_prediction_score = np.array(nb_prediction_test.select(\"rawPrediction\").toPandas().values.tolist()).squeeze()\n",
    "\n",
    "nb_cv_fpr, nb_cv_tpr,_ = roc_curve(outcome_true,nb_prediction_score[:,1])\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(lr_cv_fpr,lr_cv_tpr,label = 'Logistic Regression')\n",
    "plt.plot(svm_cv_fpr,svm_cv_tpr,label='SVM')\n",
    "plt.plot(rf_cv_fpr,rf_cv_tpr,label='Random Forest')\n",
    "plt.plot(nb_cv_fpr,nb_cv_tpr,label='Naive Bayes')\n",
    "\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "8276d678390595138ef1424ae828a970263a6f746980760e1cfd17345ae3e994"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
